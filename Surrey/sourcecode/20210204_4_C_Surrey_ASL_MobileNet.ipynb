{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzgBL5UW-XLu",
    "outputId": "7b98f5e6-7986-470c-ed7e-e2c1b165be3f"
   },
   "outputs": [],
   "source": [
    "# ls -l| tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7JeSMCPNgrF",
    "outputId": "b05de98a-7bda-416f-c72d-bd4d02f58723"
   },
   "outputs": [],
   "source": [
    "# #G4\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vl8a81P8NkSE"
   },
   "outputs": [],
   "source": [
    "# cp fingerspelling5.tar.bz2 /media/datastorage/Phong/fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WFdjWyY5NwwL"
   },
   "outputs": [],
   "source": [
    "!tar xjf fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4Vsvp9W5fJu",
    "outputId": "216cb050-377d-4584-efc9-2958cd03145b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong/dataset5\n"
     ]
    }
   ],
   "source": [
    "cd dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir surrey/C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv dataset5/* surrey/C/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlybdoQz5VnW",
    "outputId": "ae0e937a-6dfa-463d-af5b-a0dd7d0c1be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying 512 files\n",
      "ignor: A/o/depth_14_0001.png\n",
      "copying 527 files\n",
      "ignor: A/m/depth_12_0001.png\n",
      "copying 516 files\n",
      "ignor: A/l/depth_11_0001.png\n",
      "copying 524 files\n",
      "ignor: A/t/depth_19_0001.png\n",
      "copying 528 files\n",
      "ignor: A/r/depth_17_0001.png\n",
      "copying 515 files\n",
      "ignor: A/i/depth_8_0001.png\n",
      "copying 518 files\n",
      "ignor: A/k/depth_10_0001.png\n",
      "copying 530 files\n",
      "ignor: A/n/depth_13_0001.png\n",
      "copying 524 files\n",
      "ignor: A/u/depth_20_0001.png\n",
      "copying 557 files\n",
      "ignor: A/c/depth_2_0001.png\n",
      "copying 516 files\n",
      "ignor: A/b/depth_1_0001.png\n",
      "copying 524 files\n",
      "ignor: A/e/depth_4_0001.png\n",
      "copying 516 files\n",
      "ignor: A/q/depth_16_0001.png\n",
      "copying 471 files\n",
      "copying 519 files\n",
      "ignor: A/f/depth_5_0001.png\n",
      "copying 533 files\n",
      "ignor: A/y/depth_24_0001.png\n",
      "copying 522 files\n",
      "ignor: A/x/depth_23_0001.png\n",
      "copying 525 files\n",
      "ignor: A/w/depth_22_0001.png\n",
      "copying 523 files\n",
      "ignor: A/h/depth_7_0001.png\n",
      "copying 536 files\n",
      "ignor: A/d/depth_3_0001.png\n",
      "copying 528 files\n",
      "ignor: A/g/depth_6_0001.png\n",
      "copying 572 files\n",
      "ignor: A/p/depth_15_0001.png\n",
      "copying 528 files\n",
      "ignor: A/a/depth_0_0001.png\n",
      "copying 507 files\n",
      "ignor: A/v/depth_21_0001.png\n",
      "copying 511 files\n",
      "copying 526 files\n",
      "copying 515 files\n",
      "copying 523 files\n",
      "copying 527 files\n",
      "copying 514 files\n",
      "copying 517 files\n",
      "copying 529 files\n",
      "copying 523 files\n",
      "copying 556 files\n",
      "copying 515 files\n",
      "copying 523 files\n",
      "copying 515 files\n",
      "copying 470 files\n",
      "copying 518 files\n",
      "copying 532 files\n",
      "copying 521 files\n",
      "copying 524 files\n",
      "copying 522 files\n",
      "copying 535 files\n",
      "copying 527 files\n",
      "copying 571 files\n",
      "copying 527 files\n",
      "copying 506 files\n",
      "copying 529 files\n",
      "ignor: B/o/depth_14_0001.png\n",
      "copying 582 files\n",
      "ignor: B/m/depth_12_0001.png\n",
      "copying 577 files\n",
      "ignor: B/l/depth_11_0001.png\n",
      "copying 514 files\n",
      "ignor: B/t/depth_19_0001.png\n",
      "copying 550 files\n",
      "ignor: B/r/depth_17_0001.png\n",
      "copying 543 files\n",
      "ignor: B/i/depth_8_0001.png\n",
      "copying 777 files\n",
      "ignor: B/k/depth_10_0001.png\n",
      "copying 544 files\n",
      "ignor: B/n/depth_13_0001.png\n",
      "copying 542 files\n",
      "ignor: B/u/depth_20_0001.png\n",
      "copying 549 files\n",
      "ignor: B/c/depth_2_0001.png\n",
      "copying 577 files\n",
      "ignor: B/b/depth_1_0001.png\n",
      "copying 565 files\n",
      "ignor: B/e/depth_4_0001.png\n",
      "copying 540 files\n",
      "ignor: B/q/depth_16_0001.png\n",
      "copying 749 files\n",
      "ignor: B/s/depth_18_0001.png\n",
      "copying 530 files\n",
      "ignor: B/f/depth_5_0001.png\n",
      "copying 537 files\n",
      "ignor: B/y/depth_24_0001.png\n",
      "copying 622 files\n",
      "ignor: B/x/depth_23_0001.png\n",
      "copying 648 files\n",
      "ignor: B/w/depth_22_0001.png\n",
      "copying 545 files\n",
      "ignor: B/h/depth_7_0001.png\n",
      "copying 552 files\n",
      "ignor: B/d/depth_3_0001.png\n",
      "copying 544 files\n",
      "ignor: B/g/depth_6_0001.png\n",
      "copying 642 files\n",
      "ignor: B/p/depth_15_0001.png\n",
      "copying 536 files\n",
      "ignor: B/a/depth_0_0001.png\n",
      "copying 628 files\n",
      "ignor: B/v/depth_21_0001.png\n",
      "copying 528 files\n",
      "copying 581 files\n",
      "copying 576 files\n",
      "copying 513 files\n",
      "copying 549 files\n",
      "copying 542 files\n",
      "copying 776 files\n",
      "copying 543 files\n",
      "copying 541 files\n",
      "copying 548 files\n",
      "copying 576 files\n",
      "copying 564 files\n",
      "copying 539 files\n",
      "copying 748 files\n",
      "copying 529 files\n",
      "copying 536 files\n",
      "copying 621 files\n",
      "copying 647 files\n",
      "copying 544 files\n",
      "copying 551 files\n",
      "copying 543 files\n",
      "copying 641 files\n",
      "copying 535 files\n",
      "copying 627 files\n",
      "copying 539 files\n",
      "ignor: D/o/depth_14_0001.png\n",
      "copying 542 files\n",
      "ignor: D/m/depth_12_0001.png\n",
      "copying 565 files\n",
      "ignor: D/l/depth_11_0001.png\n",
      "copying 530 files\n",
      "ignor: D/t/depth_19_0001.png\n",
      "copying 774 files\n",
      "ignor: D/r/depth_17_0001.png\n",
      "copying 522 files\n",
      "ignor: D/i/depth_8_0001.png\n",
      "copying 540 files\n",
      "ignor: D/k/depth_10_0001.png\n",
      "copying 530 files\n",
      "ignor: D/n/depth_13_0001.png\n",
      "copying 532 files\n",
      "ignor: D/u/depth_20_0001.png\n",
      "copying 531 files\n",
      "ignor: D/c/depth_2_0001.png\n",
      "copying 572 files\n",
      "ignor: D/b/depth_1_0001.png\n",
      "copying 528 files\n",
      "ignor: D/e/depth_4_0001.png\n",
      "copying 550 files\n",
      "ignor: D/q/depth_16_0001.png\n",
      "copying 535 files\n",
      "ignor: D/s/depth_18_0001.png\n",
      "copying 525 files\n",
      "ignor: D/f/depth_5_0001.png\n",
      "copying 536 files\n",
      "ignor: D/y/depth_24_0001.png\n",
      "copying 538 files\n",
      "ignor: D/x/depth_23_0001.png\n",
      "copying 536 files\n",
      "ignor: D/w/depth_22_0001.png\n",
      "copying 562 files\n",
      "ignor: D/h/depth_7_0001.png\n",
      "copying 526 files\n",
      "ignor: D/d/depth_3_0001.png\n",
      "copying 542 files\n",
      "ignor: D/g/depth_6_0001.png\n",
      "copying 532 files\n",
      "ignor: D/p/depth_15_0001.png\n",
      "copying 547 files\n",
      "ignor: D/a/depth_0_0001.png\n",
      "copying 544 files\n",
      "ignor: D/v/depth_21_0001.png\n",
      "copying 538 files\n",
      "copying 541 files\n",
      "copying 564 files\n",
      "copying 529 files\n",
      "copying 773 files\n",
      "copying 521 files\n",
      "copying 539 files\n",
      "copying 529 files\n",
      "copying 531 files\n",
      "copying 530 files\n",
      "copying 571 files\n",
      "copying 527 files\n",
      "copying 549 files\n",
      "copying 534 files\n",
      "copying 524 files\n",
      "copying 535 files\n",
      "copying 537 files\n",
      "copying 535 files\n",
      "copying 561 files\n",
      "copying 525 files\n",
      "copying 541 files\n",
      "copying 531 files\n",
      "copying 546 files\n",
      "copying 543 files\n",
      "copying 533 files\n",
      "ignor: E/o/depth_14_0001.png\n",
      "copying 526 files\n",
      "ignor: E/m/depth_12_0001.png\n",
      "copying 515 files\n",
      "ignor: E/l/depth_11_0001.png\n",
      "copying 532 files\n",
      "ignor: E/t/depth_19_0001.png\n",
      "copying 563 files\n",
      "ignor: E/r/depth_17_0001.png\n",
      "copying 526 files\n",
      "ignor: E/i/depth_8_0001.png\n",
      "copying 570 files\n",
      "ignor: E/k/depth_10_0001.png\n",
      "copying 531 files\n",
      "ignor: E/n/depth_13_0001.png\n",
      "copying 530 files\n",
      "ignor: E/u/depth_20_0001.png\n",
      "copying 541 files\n",
      "ignor: E/c/depth_2_0001.png\n",
      "copying 535 files\n",
      "ignor: E/b/depth_1_0001.png\n",
      "copying 540 files\n",
      "ignor: E/e/depth_4_0001.png\n",
      "copying 530 files\n",
      "ignor: E/q/depth_16_0001.png\n",
      "copying 527 files\n",
      "ignor: E/s/depth_18_0001.png\n",
      "copying 528 files\n",
      "ignor: E/f/depth_5_0001.png\n",
      "copying 522 files\n",
      "ignor: E/y/depth_24_0001.png\n",
      "copying 523 files\n",
      "ignor: E/x/depth_23_0001.png\n",
      "copying 514 files\n",
      "ignor: E/w/depth_22_0001.png\n",
      "copying 535 files\n",
      "ignor: E/h/depth_7_0001.png\n",
      "copying 545 files\n",
      "ignor: E/d/depth_3_0001.png\n",
      "copying 538 files\n",
      "ignor: E/g/depth_6_0001.png\n",
      "copying 528 files\n",
      "ignor: E/p/depth_15_0001.png\n",
      "copying 546 files\n",
      "ignor: E/a/depth_0_0001.png\n",
      "copying 528 files\n",
      "ignor: E/v/depth_21_0001.png\n",
      "copying 532 files\n",
      "copying 525 files\n",
      "copying 514 files\n",
      "copying 531 files\n",
      "copying 562 files\n",
      "copying 525 files\n",
      "copying 569 files\n",
      "copying 530 files\n",
      "copying 529 files\n",
      "copying 540 files\n",
      "copying 534 files\n",
      "copying 539 files\n",
      "copying 529 files\n",
      "copying 526 files\n",
      "copying 527 files\n",
      "copying 521 files\n",
      "copying 522 files\n",
      "copying 513 files\n",
      "copying 534 files\n",
      "copying 544 files\n",
      "copying 537 files\n",
      "copying 527 files\n",
      "copying 545 files\n",
      "copying 527 files\n",
      "copying 548 files\n",
      "ignor: C/o/depth_14_0001.png\n",
      "copying 538 files\n",
      "ignor: C/m/depth_12_0001.png\n",
      "copying 586 files\n",
      "ignor: C/l/depth_11_0001.png\n",
      "copying 529 files\n",
      "ignor: C/t/depth_19_0001.png\n",
      "copying 530 files\n",
      "ignor: C/r/depth_17_0001.png\n",
      "copying 530 files\n",
      "ignor: C/i/depth_8_0001.png\n",
      "copying 539 files\n",
      "ignor: C/k/depth_10_0001.png\n",
      "copying 564 files\n",
      "ignor: C/n/depth_13_0001.png\n",
      "copying 530 files\n",
      "ignor: C/u/depth_20_0001.png\n",
      "copying 743 files\n",
      "ignor: C/c/depth_2_0001.png\n",
      "copying 533 files\n",
      "ignor: C/b/depth_1_0001.png\n",
      "copying 529 files\n",
      "ignor: C/e/depth_4_0001.png\n",
      "copying 541 files\n",
      "ignor: C/q/depth_16_0001.png\n",
      "copying 507 files\n",
      "ignor: C/s/depth_18_0001.png\n",
      "copying 518 files\n",
      "ignor: C/f/depth_5_0001.png\n",
      "copying 543 files\n",
      "ignor: C/y/depth_24_0001.png\n",
      "copying 531 files\n",
      "ignor: C/x/depth_23_0001.png\n",
      "copying 890 files\n",
      "ignor: C/w/depth_22_0001.png\n",
      "copying 536 files\n",
      "ignor: C/h/depth_7_0001.png\n",
      "copying 526 files\n",
      "ignor: C/d/depth_3_0001.png\n",
      "copying 532 files\n",
      "ignor: C/g/depth_6_0001.png\n",
      "copying 534 files\n",
      "ignor: C/p/depth_15_0001.png\n",
      "copying 524 files\n",
      "ignor: C/a/depth_0_0001.png\n",
      "copying 536 files\n",
      "ignor: C/v/depth_21_0001.png\n",
      "copying 547 files\n",
      "copying 537 files\n",
      "copying 585 files\n",
      "copying 528 files\n",
      "copying 529 files\n",
      "copying 529 files\n",
      "copying 538 files\n",
      "copying 563 files\n",
      "copying 529 files\n",
      "copying 742 files\n",
      "copying 532 files\n",
      "copying 528 files\n",
      "copying 540 files\n",
      "copying 506 files\n",
      "copying 517 files\n",
      "copying 542 files\n",
      "copying 530 files\n",
      "copying 889 files\n",
      "copying 535 files\n",
      "copying 525 files\n",
      "copying 531 files\n",
      "copying 533 files\n",
      "copying 523 files\n",
      "copying 535 files\n"
     ]
    }
   ],
   "source": [
    "#remove depth files\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# get parts of image's path\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "\n",
    "#del_folders = ['A','B','C','D','E']  \n",
    "move_folders_1 = ['A','B','D','E']  \n",
    "move_folders_2 = ['C']\n",
    "\n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders_1:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            if \"0001\" not in src: \n",
    "                train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "                dst = os.path.join('train_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "                # image directory\n",
    "                img_directory = os.path.join('train_depth', classname)\n",
    "\n",
    "                # create folder if not existed\n",
    "                if not os.path.exists(img_directory):\n",
    "                    os.makedirs(img_directory)\n",
    "\n",
    "                #copying\n",
    "                shutil.copy(src, dst)\n",
    "            else:\n",
    "                print('ignor: %s' %src)\n",
    "            \n",
    "        #move color files    \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "            dst = os.path.join('train_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "            # image directory\n",
    "            img_directory = os.path.join('train_color', classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "            \n",
    "            #copying\n",
    "            shutil.copy(src, dst)\n",
    "            \n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders_2:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            if \"0001\" not in src: \n",
    "                train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "                dst = os.path.join('test_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "                # image directory\n",
    "                img_directory = os.path.join('test_depth', classname)\n",
    "\n",
    "                # create folder if not existed\n",
    "                if not os.path.exists(img_directory):\n",
    "                    os.makedirs(img_directory)\n",
    "\n",
    "                #copying\n",
    "                shutil.copy(src, dst)\n",
    "            else:\n",
    "                print('ignor: %s' %src)\n",
    "            \n",
    "        #move color files    \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "            dst = os.path.join('test_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "            # image directory\n",
    "            img_directory = os.path.join('test_color', classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "            \n",
    "            #copying\n",
    "            shutil.copy(src, dst)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySsSuGu17Tmx",
    "outputId": "ee889c7c-b780-4168-f408-6fe8706b159e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "# #/content\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXV9cPR2m9oU",
    "outputId": "9407012b-69e5-452d-f1e2-d0ea19fe507a"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WIMPsCOjGdJe"
   },
   "outputs": [],
   "source": [
    "mkdir surrey/C/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kCE27WuwJNf",
    "outputId": "b2af0348-523a-4773-91b9-7b70c596745a"
   },
   "outputs": [],
   "source": [
    "cd surrey/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def get_adv_model():\n",
    "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "#                     input_shape=(299, 299, 3), \n",
    "#                     pooling='avg')\n",
    "#     f1_x = f1_base.output\n",
    "\n",
    "\n",
    "    f1_base = MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3))  \n",
    "    f1_x = f1_base.output\n",
    "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
    "\n",
    "# f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1280])(f1_x)  \n",
    "# f1_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1280])(f1_x)\n",
    "   \n",
    "    #Regularization with noise\n",
    "    f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "    f1_x = Dense(24, activation='softmax')(f1_x)\n",
    "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "    model_1.summary()\n",
    "    \n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52381 images belonging to 24 classes.\n",
      "Found 13393 images belonging to 24 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                24600     \n",
      "=================================================================\n",
      "Total params: 4,303,064\n",
      "Trainable params: 4,281,176\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 64\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/C/train_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('surrey/C/test_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52381 images belonging to 24 classes.\n",
      "Found 13393 images belonging to 24 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                24600     \n",
      "=================================================================\n",
      "Total params: 4,303,064\n",
      "Trainable params: 4,281,176\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-4-cce01b03f26d>:102: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "  2/819 [..............................] - ETA: 1:40 - loss: 3.7841 - accuracy: 0.0391WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0596s vs `on_train_batch_end` time: 0.1851s). Check your callbacks.\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9140\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86508, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 600s 733ms/step - loss: 0.2787 - accuracy: 0.9140 - val_loss: 0.5307 - val_accuracy: 0.8651\n",
      "Epoch 2/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9719\n",
      "Epoch 00002: val_accuracy did not improve from 0.86508\n",
      "819/819 [==============================] - 576s 704ms/step - loss: 0.0901 - accuracy: 0.9719 - val_loss: 0.7129 - val_accuracy: 0.8456\n",
      "Epoch 3/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9785\n",
      "Epoch 00003: val_accuracy improved from 0.86508 to 0.86948, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0695 - accuracy: 0.9785 - val_loss: 0.5825 - val_accuracy: 0.8695\n",
      "Epoch 4/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9821\n",
      "Epoch 00004: val_accuracy improved from 0.86948 to 0.89636, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 579s 707ms/step - loss: 0.0586 - accuracy: 0.9821 - val_loss: 0.4674 - val_accuracy: 0.8964\n",
      "Epoch 5/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9847\n",
      "Epoch 00005: val_accuracy did not improve from 0.89636\n",
      "819/819 [==============================] - 576s 703ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 0.7739 - val_accuracy: 0.8342\n",
      "Epoch 6/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9862\n",
      "Epoch 00006: val_accuracy improved from 0.89636 to 0.90480, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 581s 709ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.3983 - val_accuracy: 0.9048\n",
      "Epoch 7/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9872\n",
      "Epoch 00007: val_accuracy improved from 0.90480 to 0.91085, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 576s 703ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.3936 - val_accuracy: 0.9108\n",
      "Epoch 8/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9883\n",
      "Epoch 00008: val_accuracy did not improve from 0.91085\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.5413 - val_accuracy: 0.8837\n",
      "Epoch 9/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9898\n",
      "Epoch 00009: val_accuracy improved from 0.91085 to 0.93556, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 577s 704ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.2646 - val_accuracy: 0.9356\n",
      "Epoch 10/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9898\n",
      "Epoch 00010: val_accuracy did not improve from 0.93556\n",
      "819/819 [==============================] - 577s 705ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.6552 - val_accuracy: 0.8767\n",
      "Epoch 11/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 00011: val_accuracy did not improve from 0.93556\n",
      "819/819 [==============================] - 555s 677ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.5429 - val_accuracy: 0.8650\n",
      "Epoch 12/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9930\n",
      "Epoch 00012: val_accuracy did not improve from 0.93556\n",
      "819/819 [==============================] - 527s 644ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.3374 - val_accuracy: 0.9187\n",
      "Epoch 13/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9921\n",
      "Epoch 00013: val_accuracy did not improve from 0.93556\n",
      "819/819 [==============================] - 528s 645ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.7020 - val_accuracy: 0.8943\n",
      "Epoch 14/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9925\n",
      "Epoch 00014: val_accuracy did not improve from 0.93556\n",
      "819/819 [==============================] - 527s 644ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.3048 - val_accuracy: 0.9321\n",
      "Epoch 15/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 00015: val_accuracy improved from 0.93556 to 0.94086, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 529s 646ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.3017 - val_accuracy: 0.9409\n",
      "Epoch 16/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 00016: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 527s 644ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.3504 - val_accuracy: 0.9262\n",
      "Epoch 17/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 00017: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 529s 646ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.3686 - val_accuracy: 0.9206\n",
      "Epoch 18/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9943\n",
      "Epoch 00018: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 526s 642ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.5990 - val_accuracy: 0.8804\n",
      "Epoch 19/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 00019: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 529s 646ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.4039 - val_accuracy: 0.9244\n",
      "Epoch 20/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 00020: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 526s 642ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.3952 - val_accuracy: 0.9161\n",
      "Epoch 21/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9954\n",
      "Epoch 00021: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 518s 632ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.3519 - val_accuracy: 0.9311\n",
      "Epoch 22/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955\n",
      "Epoch 00022: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 501s 612ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.3974 - val_accuracy: 0.9093\n",
      "Epoch 23/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9952\n",
      "Epoch 00023: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 502s 613ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.3429 - val_accuracy: 0.9271\n",
      "Epoch 24/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 00024: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 502s 613ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.3418 - val_accuracy: 0.9306\n",
      "Epoch 25/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962\n",
      "Epoch 00025: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 501s 612ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.3889 - val_accuracy: 0.9246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9953\n",
      "Epoch 00026: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 502s 613ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.3376 - val_accuracy: 0.9299\n",
      "Epoch 27/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 00027: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 501s 611ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.4112 - val_accuracy: 0.9164\n",
      "Epoch 28/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 00028: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 501s 612ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.4914 - val_accuracy: 0.9165\n",
      "Epoch 29/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9965\n",
      "Epoch 00029: val_accuracy did not improve from 0.94086\n",
      "819/819 [==============================] - 501s 612ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.3087 - val_accuracy: 0.9329\n",
      "Epoch 30/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 00030: val_accuracy improved from 0.94086 to 0.95393, saving model to surrey/C/checkpoints/Surrey_MobileNet_C.hdf5\n",
      "819/819 [==============================] - 502s 613ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.2138 - val_accuracy: 0.9539\n",
      "Epoch 31/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 00031: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 514s 627ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.3154 - val_accuracy: 0.9415\n",
      "Epoch 32/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 00032: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 517s 631ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.3936 - val_accuracy: 0.9241\n",
      "Epoch 33/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 00033: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 516s 630ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.5704 - val_accuracy: 0.9233\n",
      "Epoch 34/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 00034: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 518s 632ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.2885 - val_accuracy: 0.9316\n",
      "Epoch 35/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 00035: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 515s 629ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.4533 - val_accuracy: 0.9226\n",
      "Epoch 36/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9968\n",
      "Epoch 00036: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 518s 632ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.3364 - val_accuracy: 0.9374\n",
      "Epoch 37/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 00037: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 516s 630ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.2621 - val_accuracy: 0.9461\n",
      "Epoch 38/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 00038: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 518s 632ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.5883 - val_accuracy: 0.9120\n",
      "Epoch 39/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9975\n",
      "Epoch 00039: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 517s 632ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.2883 - val_accuracy: 0.9454\n",
      "Epoch 40/40\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00040: val_accuracy did not improve from 0.95393\n",
      "819/819 [==============================] - 563s 687ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5471 - val_accuracy: 0.9044\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 64\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/C/train_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('surrey/C/test_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbbwOFVGwVvM",
    "outputId": "8a52a0c4-259e-4793-a2ea-fd8b107d1c59"
   },
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "210/210 [==============================] - 29s 137ms/step - loss: 0.2138 - accuracy: 0.9539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21384544670581818, 0.9539311528205872]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-c916a63cd94e>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "  2/819 [..............................] - ETA: 1:50 - loss: 0.0308 - accuracy: 0.9922  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0615s vs `on_train_batch_end` time: 0.2087s). Check your callbacks.\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96312, saving model to surrey/C/checkpoints/Surrey_MobileNet_C_L2.hdf5\n",
      "819/819 [==============================] - 549s 670ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.2058 - val_accuracy: 0.9631\n",
      "Epoch 2/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00002: val_accuracy did not improve from 0.96312\n",
      "819/819 [==============================] - 529s 646ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2748 - val_accuracy: 0.9509\n",
      "Epoch 3/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00003: val_accuracy did not improve from 0.96312\n",
      "819/819 [==============================] - 532s 650ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.2477 - val_accuracy: 0.9586\n",
      "Epoch 4/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00004: val_accuracy improved from 0.96312 to 0.96341, saving model to surrey/C/checkpoints/Surrey_MobileNet_C_L2.hdf5\n",
      "819/819 [==============================] - 578s 706ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2168 - val_accuracy: 0.9634\n",
      "Epoch 5/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00005: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2144 - val_accuracy: 0.9615\n",
      "Epoch 6/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00006: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 579s 707ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2466 - val_accuracy: 0.9583\n",
      "Epoch 7/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 00007: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2650 - val_accuracy: 0.9495\n",
      "Epoch 8/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 00008: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 592s 723ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.3037 - val_accuracy: 0.9501\n",
      "Epoch 9/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00009: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 576s 703ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.2965 - val_accuracy: 0.9516\n",
      "Epoch 10/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 00010: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 576s 704ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.2989 - val_accuracy: 0.9486\n",
      "Epoch 11/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00011: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 582s 710ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3311 - val_accuracy: 0.9447\n",
      "Epoch 12/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00012: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3106 - val_accuracy: 0.9497\n",
      "Epoch 13/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00013: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 584s 713ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3235 - val_accuracy: 0.9471\n",
      "Epoch 14/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00014: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 578s 706ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2989 - val_accuracy: 0.9476\n",
      "Epoch 15/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00015: val_accuracy did not improve from 0.96341\n",
      "819/819 [==============================] - 582s 711ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2809 - val_accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C_L2.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D7gHbA9f_iRK"
   },
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "210/210 [==============================] - 29s 136ms/step - loss: 0.2168 - accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21678029000759125, 0.9634137153625488]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RtpZyKMykDJA",
    "outputId": "9dae8e08-2bc5-4a42-9633-3fef46900dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-c62987120d58>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "  2/819 [..............................] - ETA: 1:43 - loss: 9.7508e-07 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0596s vs `on_train_batch_end` time: 0.1941s). Check your callbacks.\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96222, saving model to surrey/C/checkpoints/Surrey_MobileNet_C_L3.hdf5\n",
      "819/819 [==============================] - 607s 741ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2222 - val_accuracy: 0.9622\n",
      "Epoch 2/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00002: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 581s 709ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2196 - val_accuracy: 0.9618\n",
      "Epoch 3/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00003: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 576s 703ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2211 - val_accuracy: 0.9621\n",
      "Epoch 4/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 00004: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 577s 705ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2259 - val_accuracy: 0.9621\n",
      "Epoch 5/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00005: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 580s 708ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2323 - val_accuracy: 0.9616\n",
      "Epoch 6/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 00006: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 579s 707ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2277 - val_accuracy: 0.9618\n",
      "Epoch 7/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00007: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 577s 705ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2266 - val_accuracy: 0.9621\n",
      "Epoch 8/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00008: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 582s 710ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2300 - val_accuracy: 0.9609\n",
      "Epoch 9/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00009: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 582s 711ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2306 - val_accuracy: 0.9615\n",
      "Epoch 10/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00010: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 585s 715ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2271 - val_accuracy: 0.9618\n",
      "Epoch 11/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00011: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 579s 707ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.2341 - val_accuracy: 0.9606\n",
      "Epoch 12/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00012: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 580s 709ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2320 - val_accuracy: 0.9604\n",
      "Epoch 13/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00013: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 585s 715ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2272 - val_accuracy: 0.9618\n",
      "Epoch 14/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00014: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 577s 705ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2389 - val_accuracy: 0.9605\n",
      "Epoch 15/15\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00015: val_accuracy did not improve from 0.96222\n",
      "819/819 [==============================] - 578s 706ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2328 - val_accuracy: 0.9609\n"
     ]
    }
   ],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C_L3.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'C', 'checkpoints', 'Surrey_MobileNet_C_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "210/210 [==============================] - 29s 136ms/step - loss: 0.2222 - accuracy: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2221999168395996, 0.9622190594673157]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52381 images belonging to 24 classes.\n",
      "Found 13393 images belonging to 24 classes.\n",
      "WARNING:tensorflow:From <ipython-input-7-b51f79b620a2>:48: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "419/419 [==============================] - 17s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a/C_color_0_0002.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a/C_color_0_0003.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a/C_color_0_0004.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a/C_color_0_0005.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/C_color_0_0006.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name predicted1\n",
       "0  a/C_color_0_0002.png          a\n",
       "1  a/C_color_0_0003.png          a\n",
       "2  a/C_color_0_0004.png          a\n",
       "3  a/C_color_0_0005.png          a\n",
       "4  a/C_color_0_0006.png          a"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/C/train_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('surrey/C/test_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "# if NUM_GPU != 1:\n",
    "predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Surrey_MobileNet_C_L3_0902.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Surrey_MobileNet_C_L3_0902.csv /home/bribeiro/Phong/Nat19/Surrey_MobileNet_C_L3_0902.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('surrey', 'C', 'npy', 'Surrey_MobileNet_C_L3_0902.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QZY19H9TkLKZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13393 images belonging to 24 classes.\n",
      "[[439  26   1   0   0   0   0   1   0   0   0   0   0   0   0  51   4   0\n",
      "    0   0   1   0   0   0]\n",
      " [  0 531   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  1  81  11 230   0   0   0   0   0   0   8   0   0  28   0 231  54   0\n",
      "    0   1  97   0   0   0]\n",
      " [  0   0   0 485   0   0   0   0   0   0   0   0   0   0   0  17  17   0\n",
      "    0   0   6   0   0   0]\n",
      " [  0 116   0  22 229   0   0   0   0   0   1   0   0   0   0 113  22   1\n",
      "    0   1  23   0   0   0]\n",
      " [  0 226   0   0   0 150   1   0   0  33   0   0   0   0   0  96   4   0\n",
      "    0   0   7   0   0   0]\n",
      " [  3   3   0   0   0   0 388   6   0  91   0   0   0   0   1  27   0   0\n",
      "    0   0  12   0   0   0]\n",
      " [  0  37   0   0   0   0  14 417   0   4   0   0   0   0   9  47   0   0\n",
      "    0   0   7   0   0   0]\n",
      " [ 10  62   1   3   0   5   0   0 142  51   3   0   0   0   7  33 115   0\n",
      "    0   0  17   0   0  80]\n",
      " [  0  19   0  14   0   0   0   0   0  27  28   0   0   0  33 141 176   0\n",
      "    0   9  91   0   0   0]\n",
      " [  0   6   0   1   0   0   0   0   0  10 487   0   0   0   0   3  74   0\n",
      "    0   0   4   0   0   0]\n",
      " [ 54   0   3   4   1   0   0   0   0   0   0  18   0   0   0 388  55   0\n",
      "    0   1   2   0   0  11]\n",
      " [ 27  63   5   2   0   0   0   0   0   0   3   0  30   0   0 285 130   0\n",
      "    0   0  18   0   0   0]\n",
      " [  0   1   4 362   0   0   1   0   0   0   0   0   0  86   8  72   7   0\n",
      "    0   0   5   0   0   1]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0 421 104   0   0\n",
      "    0   0   7   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0  74 434   6   0\n",
      "    0   0  23   0   0   0]\n",
      " [  0  77   3   9   0   2   0   0   0   5   0   0   0   0   0  10 358   0\n",
      "    0   0  65   0   0   0]\n",
      " [215  34  42   1   0   0   1   2   0   3   0   0   1   0   6 111   1  82\n",
      "    0   0   7   0   0   0]\n",
      " [110  14   3  18   0   0   0   0   0   0  12   0   0   1   1 302  63   0\n",
      "    0   0   4   0   0   0]\n",
      " [  0 223   0   0   0   0   0   0   0   1   0   0   0   0   0 215   6   0\n",
      "    0  29  55   0   0   0]\n",
      " [  0  40   0  29   0   2   0   0   0   8   1   0   0   0   0  45  73   0\n",
      "    0  19 318   0   0   0]\n",
      " [  0 382   8   0   0  85   1   0   0   0   0   0   0   0   0  64   6   0\n",
      "    0   0 165 178   0   0]\n",
      " [  0  28   0   0   0 104   9   0   0  55  31   1   1   6  40  65  81  17\n",
      "    0   0  89   0   3   0]\n",
      " [  3  31   3  26   0  18   2   0   1  76   7   0   0   0   2  29  48   0\n",
      "    0   1  32   0   0 263]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory('surrey/C/test_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 seed=7,\n",
    "                                                 shuffle=False\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "y_pred = model_mul.predict_generator(testing_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true = testing_set.classes\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# print(model.evaluate_generator(testing_set,\n",
    "#                                steps = testing_set.n//testing_set.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "as5-kZJZeOYi",
    "outputId": "cb8faea6-53d2-4407-f598-74a70c496891"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1413
    },
    "id": "jGCKo7UImjLo",
    "outputId": "6159d98c-b68c-4446-8b95-01049cf84965"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xMLFBZEK4Rt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DBewr1xLpKq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le4SgbXkK7Fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkv4WXdmLOZG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do2PnIyXfwgc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxkumxw1YGNy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpYe5AaVp9OH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP-OnVj5LSDH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kf9FmkAVHkf0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juICyuElcBb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7Qvh9qdXCbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7xkHd_ehyXa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcLnd3hib_Eu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-T2S3-ixzqs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "R4JkwCKkvkFW",
    "outputId": "99a51a96-b686-498b-feb4-3e8606154346"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20210204 4_D_0.9045_Surrey_ASL_1Frame_MobileNetV1_total_CUDNN_128_4_1_weights_best.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
