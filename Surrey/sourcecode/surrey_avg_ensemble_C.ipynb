{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKpp0P-44ESe",
    "outputId": "aabdf4f1-0005-438c-a4c2-864741939ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWQhJPgb4Z1M",
    "outputId": "06fe40a7-9d78-4986-f149-25578de9f52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# #G4\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M9Fg-Nm66vnn"
   },
   "outputs": [],
   "source": [
    "# cp gdrive/My\\ Drive/fingerspelling5.tar.bz2 fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JuIEser36xFJ"
   },
   "outputs": [],
   "source": [
    "# !tar xjf fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfxAS1Rz6zjx",
    "outputId": "4bdeb17d-1ae3-4597-c791-75c9950b04c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/dataset5\n"
     ]
    }
   ],
   "source": [
    "# cd dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddLqeJf563Dr",
    "outputId": "ffb439e1-05e5-470d-e418-6cb98aea3950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying 528 files\n",
      "ignor: A/r/depth_17_0001.png\n",
      "copying 524 files\n",
      "ignor: A/t/depth_19_0001.png\n",
      "copying 536 files\n",
      "ignor: A/d/depth_3_0001.png\n",
      "copying 523 files\n",
      "ignor: A/h/depth_7_0001.png\n",
      "copying 572 files\n",
      "ignor: A/p/depth_15_0001.png\n",
      "copying 533 files\n",
      "ignor: A/y/depth_24_0001.png\n",
      "copying 524 files\n",
      "ignor: A/u/depth_20_0001.png\n",
      "copying 512 files\n",
      "ignor: A/o/depth_14_0001.png\n",
      "copying 522 files\n",
      "ignor: A/x/depth_23_0001.png\n",
      "copying 519 files\n",
      "ignor: A/f/depth_5_0001.png\n",
      "copying 530 files\n",
      "ignor: A/n/depth_13_0001.png\n",
      "copying 516 files\n",
      "ignor: A/l/depth_11_0001.png\n",
      "copying 471 files\n",
      "copying 524 files\n",
      "ignor: A/e/depth_4_0001.png\n",
      "copying 528 files\n",
      "ignor: A/g/depth_6_0001.png\n",
      "copying 528 files\n",
      "ignor: A/a/depth_0_0001.png\n",
      "copying 525 files\n",
      "ignor: A/w/depth_22_0001.png\n",
      "copying 557 files\n",
      "ignor: A/c/depth_2_0001.png\n",
      "copying 516 files\n",
      "ignor: A/b/depth_1_0001.png\n",
      "copying 507 files\n",
      "ignor: A/v/depth_21_0001.png\n",
      "copying 527 files\n",
      "ignor: A/m/depth_12_0001.png\n",
      "copying 518 files\n",
      "ignor: A/k/depth_10_0001.png\n",
      "copying 516 files\n",
      "ignor: A/q/depth_16_0001.png\n",
      "copying 515 files\n",
      "ignor: A/i/depth_8_0001.png\n",
      "copying 527 files\n",
      "copying 523 files\n",
      "copying 535 files\n",
      "copying 522 files\n",
      "copying 571 files\n",
      "copying 532 files\n",
      "copying 523 files\n",
      "copying 511 files\n",
      "copying 521 files\n",
      "copying 518 files\n",
      "copying 529 files\n",
      "copying 515 files\n",
      "copying 470 files\n",
      "copying 523 files\n",
      "copying 527 files\n",
      "copying 527 files\n",
      "copying 524 files\n",
      "copying 556 files\n",
      "copying 515 files\n",
      "copying 506 files\n",
      "copying 526 files\n",
      "copying 517 files\n",
      "copying 515 files\n",
      "copying 514 files\n",
      "copying 550 files\n",
      "ignor: B/r/depth_17_0001.png\n",
      "copying 514 files\n",
      "ignor: B/t/depth_19_0001.png\n",
      "copying 552 files\n",
      "ignor: B/d/depth_3_0001.png\n",
      "copying 545 files\n",
      "ignor: B/h/depth_7_0001.png\n",
      "copying 642 files\n",
      "ignor: B/p/depth_15_0001.png\n",
      "copying 537 files\n",
      "ignor: B/y/depth_24_0001.png\n",
      "copying 542 files\n",
      "ignor: B/u/depth_20_0001.png\n",
      "copying 529 files\n",
      "ignor: B/o/depth_14_0001.png\n",
      "copying 622 files\n",
      "ignor: B/x/depth_23_0001.png\n",
      "copying 530 files\n",
      "ignor: B/f/depth_5_0001.png\n",
      "copying 544 files\n",
      "ignor: B/n/depth_13_0001.png\n",
      "copying 577 files\n",
      "ignor: B/l/depth_11_0001.png\n",
      "copying 749 files\n",
      "ignor: B/s/depth_18_0001.png\n",
      "copying 565 files\n",
      "ignor: B/e/depth_4_0001.png\n",
      "copying 544 files\n",
      "ignor: B/g/depth_6_0001.png\n",
      "copying 536 files\n",
      "ignor: B/a/depth_0_0001.png\n",
      "copying 648 files\n",
      "ignor: B/w/depth_22_0001.png\n",
      "copying 549 files\n",
      "ignor: B/c/depth_2_0001.png\n",
      "copying 577 files\n",
      "ignor: B/b/depth_1_0001.png\n",
      "copying 628 files\n",
      "ignor: B/v/depth_21_0001.png\n",
      "copying 582 files\n",
      "ignor: B/m/depth_12_0001.png\n",
      "copying 777 files\n",
      "ignor: B/k/depth_10_0001.png\n",
      "copying 540 files\n",
      "ignor: B/q/depth_16_0001.png\n",
      "copying 543 files\n",
      "ignor: B/i/depth_8_0001.png\n",
      "copying 549 files\n",
      "copying 513 files\n",
      "copying 551 files\n",
      "copying 544 files\n",
      "copying 641 files\n",
      "copying 536 files\n",
      "copying 541 files\n",
      "copying 528 files\n",
      "copying 621 files\n",
      "copying 529 files\n",
      "copying 543 files\n",
      "copying 576 files\n",
      "copying 748 files\n",
      "copying 564 files\n",
      "copying 543 files\n",
      "copying 535 files\n",
      "copying 647 files\n",
      "copying 548 files\n",
      "copying 576 files\n",
      "copying 627 files\n",
      "copying 581 files\n",
      "copying 776 files\n",
      "copying 539 files\n",
      "copying 542 files\n",
      "copying 530 files\n",
      "ignor: C/r/depth_17_0001.png\n",
      "copying 529 files\n",
      "ignor: C/t/depth_19_0001.png\n",
      "copying 526 files\n",
      "ignor: C/d/depth_3_0001.png\n",
      "copying 536 files\n",
      "ignor: C/h/depth_7_0001.png\n",
      "copying 534 files\n",
      "ignor: C/p/depth_15_0001.png\n",
      "copying 543 files\n",
      "ignor: C/y/depth_24_0001.png\n",
      "copying 530 files\n",
      "ignor: C/u/depth_20_0001.png\n",
      "copying 548 files\n",
      "ignor: C/o/depth_14_0001.png\n",
      "copying 531 files\n",
      "ignor: C/x/depth_23_0001.png\n",
      "copying 518 files\n",
      "ignor: C/f/depth_5_0001.png\n",
      "copying 564 files\n",
      "ignor: C/n/depth_13_0001.png\n",
      "copying 586 files\n",
      "ignor: C/l/depth_11_0001.png\n",
      "copying 507 files\n",
      "ignor: C/s/depth_18_0001.png\n",
      "copying 529 files\n",
      "ignor: C/e/depth_4_0001.png\n",
      "copying 532 files\n",
      "ignor: C/g/depth_6_0001.png\n",
      "copying 524 files\n",
      "ignor: C/a/depth_0_0001.png\n",
      "copying 890 files\n",
      "ignor: C/w/depth_22_0001.png\n",
      "copying 743 files\n",
      "ignor: C/c/depth_2_0001.png\n",
      "copying 533 files\n",
      "ignor: C/b/depth_1_0001.png\n",
      "copying 536 files\n",
      "ignor: C/v/depth_21_0001.png\n",
      "copying 538 files\n",
      "ignor: C/m/depth_12_0001.png\n",
      "copying 539 files\n",
      "ignor: C/k/depth_10_0001.png\n",
      "copying 541 files\n",
      "ignor: C/q/depth_16_0001.png\n",
      "copying 530 files\n",
      "ignor: C/i/depth_8_0001.png\n",
      "copying 529 files\n",
      "copying 528 files\n",
      "copying 525 files\n",
      "copying 535 files\n",
      "copying 533 files\n",
      "copying 542 files\n",
      "copying 529 files\n",
      "copying 547 files\n",
      "copying 530 files\n",
      "copying 517 files\n",
      "copying 563 files\n",
      "copying 585 files\n",
      "copying 506 files\n",
      "copying 528 files\n",
      "copying 531 files\n",
      "copying 523 files\n",
      "copying 889 files\n",
      "copying 742 files\n",
      "copying 532 files\n",
      "copying 535 files\n",
      "copying 537 files\n",
      "copying 538 files\n",
      "copying 540 files\n",
      "copying 529 files\n",
      "copying 774 files\n",
      "ignor: D/r/depth_17_0001.png\n",
      "copying 530 files\n",
      "ignor: D/t/depth_19_0001.png\n",
      "copying 526 files\n",
      "ignor: D/d/depth_3_0001.png\n",
      "copying 562 files\n",
      "ignor: D/h/depth_7_0001.png\n",
      "copying 532 files\n",
      "ignor: D/p/depth_15_0001.png\n",
      "copying 536 files\n",
      "ignor: D/y/depth_24_0001.png\n",
      "copying 532 files\n",
      "ignor: D/u/depth_20_0001.png\n",
      "copying 539 files\n",
      "ignor: D/o/depth_14_0001.png\n",
      "copying 538 files\n",
      "ignor: D/x/depth_23_0001.png\n",
      "copying 525 files\n",
      "ignor: D/f/depth_5_0001.png\n",
      "copying 530 files\n",
      "ignor: D/n/depth_13_0001.png\n",
      "copying 565 files\n",
      "ignor: D/l/depth_11_0001.png\n",
      "copying 535 files\n",
      "ignor: D/s/depth_18_0001.png\n",
      "copying 528 files\n",
      "ignor: D/e/depth_4_0001.png\n",
      "copying 542 files\n",
      "ignor: D/g/depth_6_0001.png\n",
      "copying 547 files\n",
      "ignor: D/a/depth_0_0001.png\n",
      "copying 536 files\n",
      "ignor: D/w/depth_22_0001.png\n",
      "copying 531 files\n",
      "ignor: D/c/depth_2_0001.png\n",
      "copying 572 files\n",
      "ignor: D/b/depth_1_0001.png\n",
      "copying 544 files\n",
      "ignor: D/v/depth_21_0001.png\n",
      "copying 542 files\n",
      "ignor: D/m/depth_12_0001.png\n",
      "copying 540 files\n",
      "ignor: D/k/depth_10_0001.png\n",
      "copying 550 files\n",
      "ignor: D/q/depth_16_0001.png\n",
      "copying 522 files\n",
      "ignor: D/i/depth_8_0001.png\n",
      "copying 773 files\n",
      "copying 529 files\n",
      "copying 525 files\n",
      "copying 561 files\n",
      "copying 531 files\n",
      "copying 535 files\n",
      "copying 531 files\n",
      "copying 538 files\n",
      "copying 537 files\n",
      "copying 524 files\n",
      "copying 529 files\n",
      "copying 564 files\n",
      "copying 534 files\n",
      "copying 527 files\n",
      "copying 541 files\n",
      "copying 546 files\n",
      "copying 535 files\n",
      "copying 530 files\n",
      "copying 571 files\n",
      "copying 543 files\n",
      "copying 541 files\n",
      "copying 539 files\n",
      "copying 549 files\n",
      "copying 521 files\n",
      "copying 563 files\n",
      "ignor: E/r/depth_17_0001.png\n",
      "copying 532 files\n",
      "ignor: E/t/depth_19_0001.png\n",
      "copying 545 files\n",
      "ignor: E/d/depth_3_0001.png\n",
      "copying 535 files\n",
      "ignor: E/h/depth_7_0001.png\n",
      "copying 528 files\n",
      "ignor: E/p/depth_15_0001.png\n",
      "copying 522 files\n",
      "ignor: E/y/depth_24_0001.png\n",
      "copying 530 files\n",
      "ignor: E/u/depth_20_0001.png\n",
      "copying 533 files\n",
      "ignor: E/o/depth_14_0001.png\n",
      "copying 523 files\n",
      "ignor: E/x/depth_23_0001.png\n",
      "copying 528 files\n",
      "ignor: E/f/depth_5_0001.png\n",
      "copying 531 files\n",
      "ignor: E/n/depth_13_0001.png\n",
      "copying 515 files\n",
      "ignor: E/l/depth_11_0001.png\n",
      "copying 527 files\n",
      "ignor: E/s/depth_18_0001.png\n",
      "copying 540 files\n",
      "ignor: E/e/depth_4_0001.png\n",
      "copying 538 files\n",
      "ignor: E/g/depth_6_0001.png\n",
      "copying 546 files\n",
      "ignor: E/a/depth_0_0001.png\n",
      "copying 514 files\n",
      "ignor: E/w/depth_22_0001.png\n",
      "copying 541 files\n",
      "ignor: E/c/depth_2_0001.png\n",
      "copying 535 files\n",
      "ignor: E/b/depth_1_0001.png\n",
      "copying 528 files\n",
      "ignor: E/v/depth_21_0001.png\n",
      "copying 526 files\n",
      "ignor: E/m/depth_12_0001.png\n",
      "copying 570 files\n",
      "ignor: E/k/depth_10_0001.png\n",
      "copying 530 files\n",
      "ignor: E/q/depth_16_0001.png\n",
      "copying 526 files\n",
      "ignor: E/i/depth_8_0001.png\n",
      "copying 562 files\n",
      "copying 531 files\n",
      "copying 544 files\n",
      "copying 534 files\n",
      "copying 527 files\n",
      "copying 521 files\n",
      "copying 529 files\n",
      "copying 532 files\n",
      "copying 522 files\n",
      "copying 527 files\n",
      "copying 530 files\n",
      "copying 514 files\n",
      "copying 526 files\n",
      "copying 539 files\n",
      "copying 537 files\n",
      "copying 545 files\n",
      "copying 513 files\n",
      "copying 540 files\n",
      "copying 534 files\n",
      "copying 527 files\n",
      "copying 525 files\n",
      "copying 569 files\n",
      "copying 529 files\n",
      "copying 525 files\n"
     ]
    }
   ],
   "source": [
    "# #remove depth files\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # get parts of image's path\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "\n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "\n",
    "# #del_folders = ['A','B','C','D','E']  \n",
    "# move_folders_1 = ['A','B','C','D']  \n",
    "# move_folders_2 = ['E']\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders_1:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         #move depth files\n",
    "#         class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "#         print('copying %d files' %(len(class_files)))\n",
    "#         for idx in range(len(class_files)):        \n",
    "#             src = class_files[idx]\n",
    "#             if \"0001\" not in src: \n",
    "#                 train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "#                 dst = os.path.join('train_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "#                 # image directory\n",
    "#                 img_directory = os.path.join('train_depth', classname)\n",
    "\n",
    "#                 # create folder if not existed\n",
    "#                 if not os.path.exists(img_directory):\n",
    "#                     os.makedirs(img_directory)\n",
    "\n",
    "#                 #copying\n",
    "#                 shutil.copy(src, dst)\n",
    "#             else:\n",
    "#                 print('ignor: %s' %src)\n",
    "            \n",
    "#         #move color files    \n",
    "#     for iid_class in class_folders:\n",
    "#         #move depth files\n",
    "#         class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "#         print('copying %d files' %(len(class_files)))\n",
    "#         for idx in range(len(class_files)):        \n",
    "#             src = class_files[idx]\n",
    "#             train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "#             dst = os.path.join('train_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "#             # image directory\n",
    "#             img_directory = os.path.join('train_color', classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "            \n",
    "#             #copying\n",
    "#             shutil.copy(src, dst)\n",
    "            \n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders_2:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         #move depth files\n",
    "#         class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "#         print('copying %d files' %(len(class_files)))\n",
    "#         for idx in range(len(class_files)):        \n",
    "#             src = class_files[idx]\n",
    "#             if \"0001\" not in src: \n",
    "#                 train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "#                 dst = os.path.join('test_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "#                 # image directory\n",
    "#                 img_directory = os.path.join('test_depth', classname)\n",
    "\n",
    "#                 # create folder if not existed\n",
    "#                 if not os.path.exists(img_directory):\n",
    "#                     os.makedirs(img_directory)\n",
    "\n",
    "#                 #copying\n",
    "#                 shutil.copy(src, dst)\n",
    "#             else:\n",
    "#                 print('ignor: %s' %src)\n",
    "            \n",
    "#         #move color files    \n",
    "#     for iid_class in class_folders:\n",
    "#         #move depth files\n",
    "#         class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "#         print('copying %d files' %(len(class_files)))\n",
    "#         for idx in range(len(class_files)):        \n",
    "#             src = class_files[idx]\n",
    "#             train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "#             dst = os.path.join('test_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "#             # image directory\n",
    "#             img_directory = os.path.join('test_color', classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "            \n",
    "#             #copying\n",
    "#             shutil.copy(src, dst)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3886FQ4R65qM",
    "outputId": "561abcc7-9893-401b-c44e-61824e32b29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rGY9wnLH67Hs"
   },
   "outputs": [],
   "source": [
    "# mkdir surrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dFjQq9To6-U0"
   },
   "outputs": [],
   "source": [
    "# mkdir surrey/E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5IEsvhQ36_lN"
   },
   "outputs": [],
   "source": [
    "# mv dataset5/* surrey/E/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HsEaNy2S4wf5"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/4_Surrey_MobileNet_E_L3.hdf5.npy 4_Surrey_MobileNet_E_L3.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "s3H3a90hSveM"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/4_Surrey_MobileNet_E_L1.hdf5.npy 4_Surrey_MobileNet_E_L1.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "s6YtBmwfVAv-"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/4_Surrey_MobileNet_E_L2.hdf5.npy 4_Surrey_MobileNet_E_L2.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0h8M0Uvd4z86"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/9_Surrey_InceptionV3_E_L2.hdf5.npy 9_Surrey_InceptionV3_E_L2.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jl9Bo6dZVi2c"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/9_Surrey_InceptionV3_E_L3.hdf5.npy 9_Surrey_InceptionV3_E_L3.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wjHjfnMCLsoR"
   },
   "outputs": [],
   "source": [
    "# cp /content/gdrive/MyDrive/Surrey_ASL/npy/9_Surrey_InceptionV3_E_L1.hdf5.npy 9_Surrey_InceptionV3_E_L1.hdf5.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a7fyO32U59lh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "mean_pred3_1 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_MobileNet_C_L1_0902.npy'))\n",
    "mean_pred3_2 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_MobileNet_C_L2_0902.npy'))\n",
    "mean_pred3_3 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_MobileNet_C_L3_0902.npy'))\n",
    "\n",
    "mean_pred3_4 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_InceptionV3_C_L1_0902.npy'))\n",
    "mean_pred3_5 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_InceptionV3_C_L2_0902.npy'))\n",
    "mean_pred3_6 = np.load(os.path.join('surrey', 'C', 'npy', 'Surrey_InceptionV3_C_L3_0902.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eGqEXMzW6RhI"
   },
   "outputs": [],
   "source": [
    "# a1 = mean_pred3_1\n",
    "# a2 = mean_pred3_2\n",
    "# a3 = mean_pred3_3\n",
    "# a4 = mean_pred3_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcassava\u001b[0m/                                     \u001b[01;34mNat19\u001b[0m/\r\n",
      "\u001b[01;34mcifar10\u001b[0m/                                     \u001b[01;34mNat19_2\u001b[0m/\r\n",
      "\u001b[01;34mcifar100_png\u001b[0m/                                nohup.out\r\n",
      "\u001b[01;31mcifar-100-python.tar.gz\u001b[0m                      \u001b[01;34msiim_isic_melanoma\u001b[0m/\r\n",
      "\u001b[01;34mdataset5\u001b[0m/                                    \u001b[01;34mSTFDG\u001b[0m/\r\n",
      "\u001b[01;34mDogAge\u001b[0m/                                      \u001b[01;34msurrey\u001b[0m/\r\n",
      "\u001b[01;34mfashion_mnist\u001b[0m/                               Surrey_InceptionV3_D_L1_0902.csv\r\n",
      "\u001b[01;31mfingerspelling5.tar.bz2\u001b[0m                      Surrey_InceptionV3_D_L2_0902.csv\r\n",
      "\u001b[01;34mImageNet\u001b[0m/                                    Surrey_InceptionV3_D_L3_0902.csv\r\n",
      "\u001b[01;31mimages.tar\u001b[0m                                   \u001b[01;34msvhn\u001b[0m/\r\n",
      "\u001b[01;31mlibcudnn7_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m      \u001b[01;34msvhn_v2\u001b[0m/\r\n",
      "\u001b[01;31mlibcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb\u001b[0m  \u001b[01;31mtest.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6LsaO8QI_r0j"
   },
   "outputs": [],
   "source": [
    "mean_a14 = (mean_pred3_1+mean_pred3_4)/2\n",
    "mean_a25 = (mean_pred3_2+mean_pred3_5)/2\n",
    "mean_a36 = (mean_pred3_3+mean_pred3_6)/2\n",
    "mean_a24 = (mean_pred3_2+mean_pred3_4)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "X4_eTiTW6XO6",
    "outputId": "bddbb780-55af-4617-cdb1-286564f5e445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52381 images belonging to 24 classes.\n",
      "Found 13393 images belonging to 24 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a/C_color_0_0002.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a/C_color_0_0003.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a/C_color_0_0004.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a/C_color_0_0005.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/C_color_0_0006.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id predicted\n",
       "0  a/C_color_0_0002.png         a\n",
       "1  a/C_color_0_0003.png         a\n",
       "2  a/C_color_0_0004.png         a\n",
       "3  a/C_color_0_0005.png         a\n",
       "4  a/C_color_0_0006.png         a"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/C/train_color',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "        \n",
    "test_datagen_crop = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('surrey/C/test_color',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_a24,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('surrey_C_Ensemble_0902_meana24.csv')\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp surrey_C_Ensemble_0902_meana24.csv /home/bribeiro/Phong/Nat19/surrey_C_Ensemble_0902_meana24.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "surrey_avg_ensemble_E.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
