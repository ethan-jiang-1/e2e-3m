{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzgBL5UW-XLu",
    "outputId": "7b98f5e6-7986-470c-ed7e-e2c1b165be3f"
   },
   "outputs": [],
   "source": [
    "# ls -l| tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7JeSMCPNgrF",
    "outputId": "b05de98a-7bda-416f-c72d-bd4d02f58723"
   },
   "outputs": [],
   "source": [
    "# #G4\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vl8a81P8NkSE"
   },
   "outputs": [],
   "source": [
    "# cp fingerspelling5.tar.bz2 /media/datastorage/Phong/fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFdjWyY5NwwL"
   },
   "outputs": [],
   "source": [
    "!tar xjf fingerspelling5.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4Vsvp9W5fJu",
    "outputId": "216cb050-377d-4584-efc9-2958cd03145b"
   },
   "outputs": [],
   "source": [
    "cd dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir surrey/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv dataset5/* surrey/A/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlybdoQz5VnW",
    "outputId": "ae0e937a-6dfa-463d-af5b-a0dd7d0c1be0"
   },
   "outputs": [],
   "source": [
    "#remove depth files\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# get parts of image's path\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "\n",
    "#del_folders = ['A','B','C','D','E']  \n",
    "move_folders_1 = ['B','C','D','E']  \n",
    "move_folders_2 = ['A']\n",
    "\n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders_1:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            if \"0001\" not in src: \n",
    "                train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "                dst = os.path.join('train_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "                # image directory\n",
    "                img_directory = os.path.join('train_depth', classname)\n",
    "\n",
    "                # create folder if not existed\n",
    "                if not os.path.exists(img_directory):\n",
    "                    os.makedirs(img_directory)\n",
    "\n",
    "                #copying\n",
    "                shutil.copy(src, dst)\n",
    "            else:\n",
    "                print('ignor: %s' %src)\n",
    "            \n",
    "        #move color files    \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "            dst = os.path.join('train_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "            # image directory\n",
    "            img_directory = os.path.join('train_color', classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "            \n",
    "            #copying\n",
    "            shutil.copy(src, dst)\n",
    "            \n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders_2:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            if \"0001\" not in src: \n",
    "                train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "                dst = os.path.join('test_depth', classname, train_or_test+'_'+ filename)\n",
    "\n",
    "                # image directory\n",
    "                img_directory = os.path.join('test_depth', classname)\n",
    "\n",
    "                # create folder if not existed\n",
    "                if not os.path.exists(img_directory):\n",
    "                    os.makedirs(img_directory)\n",
    "\n",
    "                #copying\n",
    "                shutil.copy(src, dst)\n",
    "            else:\n",
    "                print('ignor: %s' %src)\n",
    "            \n",
    "        #move color files    \n",
    "    for iid_class in class_folders:\n",
    "        #move depth files\n",
    "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
    "        \n",
    "        print('copying %d files' %(len(class_files)))\n",
    "        for idx in range(len(class_files)):        \n",
    "            src = class_files[idx]\n",
    "            train_or_test, classname, _, filename = get_image_parts(src)\n",
    "\n",
    "            dst = os.path.join('test_color', classname, train_or_test+'_'+ filename)\n",
    "            \n",
    "            # image directory\n",
    "            img_directory = os.path.join('test_color', classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "            \n",
    "            #copying\n",
    "            shutil.copy(src, dst)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySsSuGu17Tmx",
    "outputId": "ee889c7c-b780-4168-f408-6fe8706b159e"
   },
   "outputs": [],
   "source": [
    "# #/content\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXV9cPR2m9oU",
    "outputId": "9407012b-69e5-452d-f1e2-d0ea19fe507a"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIMPsCOjGdJe"
   },
   "outputs": [],
   "source": [
    "mkdir dataset5/A/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kCE27WuwJNf",
    "outputId": "b2af0348-523a-4773-91b9-7b70c596745a"
   },
   "outputs": [],
   "source": [
    "cd surrey/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "# from keras.applications import MobileNet\n",
    "from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "# from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def get_adv_model():\n",
    "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "#                     input_shape=(299, 299, 3), \n",
    "#                     pooling='avg')\n",
    "#     f1_x = f1_base.output\n",
    "\n",
    "\n",
    "    f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "    f1_x = f1_base.output\n",
    "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
    "\n",
    "# f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1280])(f1_x)  \n",
    "# f1_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1280])(f1_x)\n",
    "   \n",
    "    #Regularization with noise\n",
    "    f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "    f1_x = Dense(24, activation='softmax')(f1_x)\n",
    "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "    model_1.summary()\n",
    "    \n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53227 images belonging to 24 classes.\n",
      "Found 12547 images belonging to 24 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           24600       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,925,560\n",
      "Trainable params: 23,891,128\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-4-3f2d6c6bbed7>:102: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9120\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80808, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 1150s 691ms/step - loss: 0.2918 - accuracy: 0.9120 - val_loss: 0.7953 - val_accuracy: 0.8081\n",
      "Epoch 2/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9791\n",
      "Epoch 00002: val_accuracy improved from 0.80808 to 0.84211, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 1013s 609ms/step - loss: 0.0690 - accuracy: 0.9791 - val_loss: 0.6944 - val_accuracy: 0.8421\n",
      "Epoch 3/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9841\n",
      "Epoch 00003: val_accuracy improved from 0.84211 to 0.84251, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 1010s 607ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.7079 - val_accuracy: 0.8425\n",
      "Epoch 4/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9863\n",
      "Epoch 00004: val_accuracy improved from 0.84251 to 0.85391, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 990s 595ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.6454 - val_accuracy: 0.8539\n",
      "Epoch 5/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9886\n",
      "Epoch 00005: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 920s 553ms/step - loss: 0.0372 - accuracy: 0.9886 - val_loss: 0.8029 - val_accuracy: 0.8088\n",
      "Epoch 6/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9893\n",
      "Epoch 00006: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 951s 571ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.8289 - val_accuracy: 0.8129\n",
      "Epoch 7/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9901\n",
      "Epoch 00007: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 996s 599ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.7447 - val_accuracy: 0.8373\n",
      "Epoch 8/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9917\n",
      "Epoch 00008: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 0.7738 - val_accuracy: 0.8509\n",
      "Epoch 9/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 00009: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 995s 598ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.8424 - val_accuracy: 0.8401\n",
      "Epoch 10/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 00010: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 993s 597ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.7893 - val_accuracy: 0.8458\n",
      "Epoch 11/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 00011: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 995s 598ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 1.4711 - val_accuracy: 0.7627\n",
      "Epoch 12/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 00012: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 994s 598ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.7374 - val_accuracy: 0.8349\n",
      "Epoch 13/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9940\n",
      "Epoch 00013: val_accuracy did not improve from 0.85391\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 1.0508 - val_accuracy: 0.8039\n",
      "Epoch 14/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9944\n",
      "Epoch 00014: val_accuracy improved from 0.85391 to 0.85574, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.5908 - val_accuracy: 0.8557\n",
      "Epoch 15/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9949\n",
      "Epoch 00015: val_accuracy did not improve from 0.85574\n",
      "1664/1664 [==============================] - 996s 599ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 1.2325 - val_accuracy: 0.7820\n",
      "Epoch 16/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9955\n",
      "Epoch 00016: val_accuracy improved from 0.85574 to 0.86005, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.6673 - val_accuracy: 0.8600\n",
      "Epoch 17/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9952\n",
      "Epoch 00017: val_accuracy improved from 0.86005 to 0.89041, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.5672 - val_accuracy: 0.8904\n",
      "Epoch 18/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9947\n",
      "Epoch 00018: val_accuracy did not improve from 0.89041\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.6998 - val_accuracy: 0.8459\n",
      "Epoch 19/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9954\n",
      "Epoch 00019: val_accuracy did not improve from 0.89041\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.5305 - val_accuracy: 0.8887\n",
      "Epoch 20/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 00020: val_accuracy did not improve from 0.89041\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5256 - val_accuracy: 0.8765\n",
      "Epoch 21/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964\n",
      "Epoch 00021: val_accuracy improved from 0.89041 to 0.93488, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A.hdf5\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.2681 - val_accuracy: 0.9349\n",
      "Epoch 22/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9957\n",
      "Epoch 00022: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.6725 - val_accuracy: 0.8474\n",
      "Epoch 23/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9962\n",
      "Epoch 00023: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 996s 598ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.6983 - val_accuracy: 0.8641\n",
      "Epoch 24/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 00024: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.6944 - val_accuracy: 0.8761\n",
      "Epoch 25/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 00025: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 1001s 601ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.9432 - val_accuracy: 0.8341\n",
      "Epoch 26/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 00026: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.8127 - val_accuracy: 0.8502\n",
      "Epoch 27/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 00027: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 1001s 601ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.8492 - val_accuracy: 0.8264\n",
      "Epoch 28/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9973\n",
      "Epoch 00028: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 1.0061 - val_accuracy: 0.8057\n",
      "Epoch 29/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 00029: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 999s 601ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.6163 - val_accuracy: 0.8720\n",
      "Epoch 30/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 00030: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 994s 597ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.4183 - val_accuracy: 0.9114\n",
      "Epoch 31/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 00031: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 980s 589ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.4742 - val_accuracy: 0.8952\n",
      "Epoch 32/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9974\n",
      "Epoch 00032: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 921s 553ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.3660 - val_accuracy: 0.9232\n",
      "Epoch 33/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 00033: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 920s 553ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.5548 - val_accuracy: 0.9000\n",
      "Epoch 34/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 00034: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 923s 554ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 1.0755 - val_accuracy: 0.8129\n",
      "Epoch 35/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 00035: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 922s 554ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.6081 - val_accuracy: 0.8812\n",
      "Epoch 36/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9973\n",
      "Epoch 00036: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 923s 555ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.5966 - val_accuracy: 0.8683\n",
      "Epoch 37/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 00037: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 901s 542ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.8224 - val_accuracy: 0.8534\n",
      "Epoch 38/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 00038: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 874s 525ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 1.1306 - val_accuracy: 0.8140\n",
      "Epoch 39/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 00039: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 873s 525ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6529 - val_accuracy: 0.8627\n",
      "Epoch 40/40\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 00040: val_accuracy did not improve from 0.93488\n",
      "1664/1664 [==============================] - 873s 525ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.8058 - val_accuracy: 0.8509\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/A/train_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('surrey/A/test_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53227 images belonging to 24 classes.\n",
      "Found 12547 images belonging to 24 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of GPUs: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           24600       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,925,560\n",
      "Trainable params: 23,891,128\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 1\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/A/train_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('surrey/A/test_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbbwOFVGwVvM",
    "outputId": "8a52a0c4-259e-4793-a2ea-fd8b107d1c59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7gHbA9f_iRK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RtpZyKMykDJA",
    "outputId": "9dae8e08-2bc5-4a42-9633-3fef46900dfd"
   },
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "393/393 [==============================] - 34s 86ms/step - loss: 0.2681 - accuracy: 0.9349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26813527941703796, 0.9348848462104797]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-84f9ea64fcb2>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9946\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85295, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A_L2.hdf5\n",
      "1664/1664 [==============================] - 1095s 658ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.6892 - val_accuracy: 0.8530\n",
      "Epoch 2/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9962\n",
      "Epoch 00002: val_accuracy did not improve from 0.85295\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 1.0532 - val_accuracy: 0.8219\n",
      "Epoch 3/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 00003: val_accuracy did not improve from 0.85295\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 1.1016 - val_accuracy: 0.8213\n",
      "Epoch 4/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9961\n",
      "Epoch 00004: val_accuracy did not improve from 0.85295\n",
      "1664/1664 [==============================] - 949s 570ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.7117 - val_accuracy: 0.8521\n",
      "Epoch 5/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9964\n",
      "Epoch 00005: val_accuracy improved from 0.85295 to 0.90603, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A_L2.hdf5\n",
      "1664/1664 [==============================] - 920s 553ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.4437 - val_accuracy: 0.9060\n",
      "Epoch 6/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 00006: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 970s 583ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.5709 - val_accuracy: 0.8698\n",
      "Epoch 7/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9962\n",
      "Epoch 00007: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.9741 - val_accuracy: 0.8377\n",
      "Epoch 8/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9967\n",
      "Epoch 00008: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 996s 599ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.9505 - val_accuracy: 0.8308\n",
      "Epoch 9/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 00009: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 1000s 601ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.6715 - val_accuracy: 0.8727\n",
      "Epoch 10/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9969\n",
      "Epoch 00010: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 1000s 601ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.6539 - val_accuracy: 0.8974\n",
      "Epoch 11/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 00011: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.9845 - val_accuracy: 0.8488\n",
      "Epoch 12/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 00012: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 1000s 601ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.9191 - val_accuracy: 0.8567\n",
      "Epoch 13/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 00013: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.2944 - val_accuracy: 0.7922\n",
      "Epoch 14/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00014: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 1001s 602ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.9048 - val_accuracy: 0.8687\n",
      "Epoch 15/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 00015: val_accuracy did not improve from 0.90603\n",
      "1664/1664 [==============================] - 1002s 602ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.9690 - val_accuracy: 0.8288\n"
     ]
    }
   ],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A_L2.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 33s 85ms/step - loss: 0.4437 - accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4436695873737335, 0.9060333371162415]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-d84d2c90ce9a>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/bribeiro/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91560, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A_L3.hdf5\n",
      "1664/1664 [==============================] - 1152s 692ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.4110 - val_accuracy: 0.9156\n",
      "Epoch 2/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 00002: val_accuracy did not improve from 0.91560\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4777 - val_accuracy: 0.9057\n",
      "Epoch 3/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00003: val_accuracy did not improve from 0.91560\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.4667 - val_accuracy: 0.9085\n",
      "Epoch 4/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00004: val_accuracy improved from 0.91560 to 0.92070, saving model to surrey/A/checkpoints/Surrey_InceptionV3_A_L3.hdf5\n",
      "1664/1664 [==============================] - 1000s 601ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.3805 - val_accuracy: 0.9207\n",
      "Epoch 5/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00005: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 922s 554ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.5524 - val_accuracy: 0.8973\n",
      "Epoch 6/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00006: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 923s 555ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4987 - val_accuracy: 0.9064\n",
      "Epoch 7/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00007: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 960s 577ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.5426 - val_accuracy: 0.9103\n",
      "Epoch 8/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00008: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4740 - val_accuracy: 0.9090\n",
      "Epoch 9/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00009: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 997s 599ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5028 - val_accuracy: 0.9046\n",
      "Epoch 10/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00010: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 998s 600ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5377 - val_accuracy: 0.9004\n",
      "Epoch 11/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00011: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5288 - val_accuracy: 0.9019\n",
      "Epoch 12/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00012: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 1000s 601ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5331 - val_accuracy: 0.9052\n",
      "Epoch 13/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00013: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 999s 601ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4601 - val_accuracy: 0.9178\n",
      "Epoch 14/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00014: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 999s 600ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4424 - val_accuracy: 0.9135\n",
      "Epoch 15/15\n",
      "1664/1664 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00015: val_accuracy did not improve from 0.92070\n",
      "1664/1664 [==============================] - 939s 564ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4777 - val_accuracy: 0.9071\n"
     ]
    }
   ],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A_L3.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('surrey', 'A', 'checkpoints', 'Surrey_InceptionV3_A_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 34s 85ms/step - loss: 0.3805 - accuracy: 0.9207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38052988052368164, 0.9206981658935547]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mul.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53227 images belonging to 24 classes.\n",
      "Found 12547 images belonging to 24 classes.\n",
      "  2/393 [..............................] - ETA: 15sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_predict_batch_end` time: 0.0686s). Check your callbacks.\n",
      "393/393 [==============================] - 34s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a/A_color_0_0002.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a/A_color_0_0003.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a/A_color_0_0004.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a/A_color_0_0005.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/A_color_0_0006.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name predicted1\n",
       "0  a/A_color_0_0002.png          a\n",
       "1  a/A_color_0_0003.png          a\n",
       "2  a/A_color_0_0004.png          a\n",
       "3  a/A_color_0_0005.png          a\n",
       "4  a/A_color_0_0006.png          a"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('surrey/A/train_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('surrey/A/test_color/',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "# if NUM_GPU != 1:\n",
    "predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Surrey_InceptionV3_A_L3_0902.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Surrey_InceptionV3_A_L3_0902.csv /home/bribeiro/Phong/Nat19/Surrey_InceptionV3_A_L3_0902.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('surrey', 'A', 'npy', 'Surrey_InceptionV3_A_L2_0902.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('surrey', 'A', 'npy', 'Surrey_InceptionV3_A_L3_0902.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZY19H9TkLKZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory('dataset5/test_color/',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 seed=7,\n",
    "                                                 shuffle=False\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "y_pred = model.predict_generator(testing_set,steps = testing_set.n//testing_set.batch_size)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true = testing_set.classes\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# print(model.evaluate_generator(testing_set,\n",
    "#                                steps = testing_set.n//testing_set.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "as5-kZJZeOYi",
    "outputId": "cb8faea6-53d2-4407-f598-74a70c496891"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1413
    },
    "id": "jGCKo7UImjLo",
    "outputId": "6159d98c-b68c-4446-8b95-01049cf84965"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xMLFBZEK4Rt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DBewr1xLpKq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le4SgbXkK7Fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qkv4WXdmLOZG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do2PnIyXfwgc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxkumxw1YGNy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpYe5AaVp9OH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP-OnVj5LSDH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kf9FmkAVHkf0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juICyuElcBb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7Qvh9qdXCbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7xkHd_ehyXa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcLnd3hib_Eu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-T2S3-ixzqs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "R4JkwCKkvkFW",
    "outputId": "99a51a96-b686-498b-feb4-3e8606154346"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20210204 4_D_0.9045_Surrey_ASL_1Frame_MobileNetV1_total_CUDNN_128_4_1_weights_best.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
