{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20210204_Colab5_D_Surrey_ASL_MobileNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgBL5UW-XLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0224c8-2d6c-4297-f6a9-d861a47fda0a"
      },
      "source": [
        "ls -l| tail -10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Feb  4 15:26 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7JeSMCPNgrF",
        "outputId": "6e45b38f-2b4e-42cd-f937-e2bee982170a"
      },
      "source": [
        "#G4\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl8a81P8NkSE"
      },
      "source": [
        "cp gdrive/My\\ Drive/fingerspelling5.tar.bz2 fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmsrWqA-Upth"
      },
      "source": [
        "# rm -r surrey/\n",
        "%rm -r dataset5/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9HCXeVyqtPq"
      },
      "source": [
        "# rm fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pDE3biHqtPq"
      },
      "source": [
        "# cd /media/datastorage/Phong/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFdjWyY5NwwL"
      },
      "source": [
        "!tar xjf fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Vsvp9W5fJu",
        "outputId": "587c0c9d-f9be-4787-f059-24600a4b25aa"
      },
      "source": [
        "cd dataset5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPA8-rDbqtPr"
      },
      "source": [
        "mkdir surrey"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTZia9GbqtPr"
      },
      "source": [
        "mkdir surrey/D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7F8ou8qtPs"
      },
      "source": [
        "mv dataset5/* surrey/D/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSs1Nbvd1flC",
        "outputId": "c48ae61b-2c9a-4e60-ff67-148bcf259e76"
      },
      "source": [
        "cd surrey"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/surrey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SswlvOGSqtPs",
        "outputId": "9a094155-39a2-4354-d548-9d94469dacde"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlybdoQz5VnW",
        "outputId": "38fc1171-d3cf-4545-8b6b-ce8d178258bc"
      },
      "source": [
        "#remove depth files\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# get parts of image's path\n",
        "def get_image_parts(image_path):\n",
        "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
        "    parts = image_path.split(os.path.sep)\n",
        "    #print(parts)\n",
        "    filename = parts[2]\n",
        "    filename_no_ext = filename.split('.')[0]\n",
        "    classname = parts[1]\n",
        "    train_or_test = parts[0]\n",
        "\n",
        "    return train_or_test, classname, filename_no_ext, filename\n",
        "\n",
        "\n",
        "#del_folders = ['A','B','C','D','E']  \n",
        "move_folders_1 = ['A','B','C','E']  \n",
        "move_folders_2 = ['D']\n",
        "\n",
        "# look for all images in sub-folders\n",
        "for folder in move_folders_1:\n",
        "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
        "        \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            if \"0001\" not in src: \n",
        "                train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "                dst = os.path.join('train_depth', classname, train_or_test+'_'+ filename)\n",
        "\n",
        "                # image directory\n",
        "                img_directory = os.path.join('train_depth', classname)\n",
        "\n",
        "                # create folder if not existed\n",
        "                if not os.path.exists(img_directory):\n",
        "                    os.makedirs(img_directory)\n",
        "\n",
        "                #copying\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print('ignor: %s' %src)\n",
        "            \n",
        "        #move color files    \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "            dst = os.path.join('train_color', classname, train_or_test+'_'+ filename)\n",
        "            \n",
        "            # image directory\n",
        "            img_directory = os.path.join('train_color', classname)\n",
        "\n",
        "            # create folder if not existed\n",
        "            if not os.path.exists(img_directory):\n",
        "                os.makedirs(img_directory)\n",
        "            \n",
        "            #copying\n",
        "            shutil.copy(src, dst)\n",
        "            \n",
        "# look for all images in sub-folders\n",
        "for folder in move_folders_2:\n",
        "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
        "        \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            if \"0001\" not in src: \n",
        "                train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "                dst = os.path.join('test_depth', classname, train_or_test+'_'+ filename)\n",
        "\n",
        "                # image directory\n",
        "                img_directory = os.path.join('test_depth', classname)\n",
        "\n",
        "                # create folder if not existed\n",
        "                if not os.path.exists(img_directory):\n",
        "                    os.makedirs(img_directory)\n",
        "\n",
        "                #copying\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print('ignor: %s' %src)\n",
        "            \n",
        "        #move color files    \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "            dst = os.path.join('test_color', classname, train_or_test+'_'+ filename)\n",
        "            \n",
        "            # image directory\n",
        "            img_directory = os.path.join('test_color', classname)\n",
        "\n",
        "            # create folder if not existed\n",
        "            if not os.path.exists(img_directory):\n",
        "                os.makedirs(img_directory)\n",
        "            \n",
        "            #copying\n",
        "            shutil.copy(src, dst)                "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "copying 516 files\n",
            "ignor: A/b/depth_1_0001.png\n",
            "copying 524 files\n",
            "ignor: A/e/depth_4_0001.png\n",
            "copying 536 files\n",
            "ignor: A/d/depth_3_0001.png\n",
            "copying 522 files\n",
            "ignor: A/x/depth_23_0001.png\n",
            "copying 518 files\n",
            "ignor: A/k/depth_10_0001.png\n",
            "copying 572 files\n",
            "ignor: A/p/depth_15_0001.png\n",
            "copying 512 files\n",
            "ignor: A/o/depth_14_0001.png\n",
            "copying 516 files\n",
            "ignor: A/l/depth_11_0001.png\n",
            "copying 528 files\n",
            "ignor: A/r/depth_17_0001.png\n",
            "copying 525 files\n",
            "ignor: A/w/depth_22_0001.png\n",
            "copying 524 files\n",
            "ignor: A/t/depth_19_0001.png\n",
            "copying 528 files\n",
            "ignor: A/a/depth_0_0001.png\n",
            "copying 507 files\n",
            "ignor: A/v/depth_21_0001.png\n",
            "copying 524 files\n",
            "ignor: A/u/depth_20_0001.png\n",
            "copying 519 files\n",
            "ignor: A/f/depth_5_0001.png\n",
            "copying 471 files\n",
            "copying 516 files\n",
            "ignor: A/q/depth_16_0001.png\n",
            "copying 515 files\n",
            "ignor: A/i/depth_8_0001.png\n",
            "copying 557 files\n",
            "ignor: A/c/depth_2_0001.png\n",
            "copying 530 files\n",
            "ignor: A/n/depth_13_0001.png\n",
            "copying 523 files\n",
            "ignor: A/h/depth_7_0001.png\n",
            "copying 533 files\n",
            "ignor: A/y/depth_24_0001.png\n",
            "copying 527 files\n",
            "ignor: A/m/depth_12_0001.png\n",
            "copying 528 files\n",
            "ignor: A/g/depth_6_0001.png\n",
            "copying 515 files\n",
            "copying 523 files\n",
            "copying 535 files\n",
            "copying 521 files\n",
            "copying 517 files\n",
            "copying 571 files\n",
            "copying 511 files\n",
            "copying 515 files\n",
            "copying 527 files\n",
            "copying 524 files\n",
            "copying 523 files\n",
            "copying 527 files\n",
            "copying 506 files\n",
            "copying 523 files\n",
            "copying 518 files\n",
            "copying 470 files\n",
            "copying 515 files\n",
            "copying 514 files\n",
            "copying 556 files\n",
            "copying 529 files\n",
            "copying 522 files\n",
            "copying 532 files\n",
            "copying 526 files\n",
            "copying 527 files\n",
            "copying 577 files\n",
            "ignor: B/b/depth_1_0001.png\n",
            "copying 565 files\n",
            "ignor: B/e/depth_4_0001.png\n",
            "copying 552 files\n",
            "ignor: B/d/depth_3_0001.png\n",
            "copying 622 files\n",
            "ignor: B/x/depth_23_0001.png\n",
            "copying 777 files\n",
            "ignor: B/k/depth_10_0001.png\n",
            "copying 642 files\n",
            "ignor: B/p/depth_15_0001.png\n",
            "copying 529 files\n",
            "ignor: B/o/depth_14_0001.png\n",
            "copying 577 files\n",
            "ignor: B/l/depth_11_0001.png\n",
            "copying 550 files\n",
            "ignor: B/r/depth_17_0001.png\n",
            "copying 648 files\n",
            "ignor: B/w/depth_22_0001.png\n",
            "copying 514 files\n",
            "ignor: B/t/depth_19_0001.png\n",
            "copying 536 files\n",
            "ignor: B/a/depth_0_0001.png\n",
            "copying 628 files\n",
            "ignor: B/v/depth_21_0001.png\n",
            "copying 542 files\n",
            "ignor: B/u/depth_20_0001.png\n",
            "copying 530 files\n",
            "ignor: B/f/depth_5_0001.png\n",
            "copying 749 files\n",
            "ignor: B/s/depth_18_0001.png\n",
            "copying 540 files\n",
            "ignor: B/q/depth_16_0001.png\n",
            "copying 543 files\n",
            "ignor: B/i/depth_8_0001.png\n",
            "copying 549 files\n",
            "ignor: B/c/depth_2_0001.png\n",
            "copying 544 files\n",
            "ignor: B/n/depth_13_0001.png\n",
            "copying 545 files\n",
            "ignor: B/h/depth_7_0001.png\n",
            "copying 537 files\n",
            "ignor: B/y/depth_24_0001.png\n",
            "copying 582 files\n",
            "ignor: B/m/depth_12_0001.png\n",
            "copying 544 files\n",
            "ignor: B/g/depth_6_0001.png\n",
            "copying 576 files\n",
            "copying 564 files\n",
            "copying 551 files\n",
            "copying 621 files\n",
            "copying 776 files\n",
            "copying 641 files\n",
            "copying 528 files\n",
            "copying 576 files\n",
            "copying 549 files\n",
            "copying 647 files\n",
            "copying 513 files\n",
            "copying 535 files\n",
            "copying 627 files\n",
            "copying 541 files\n",
            "copying 529 files\n",
            "copying 748 files\n",
            "copying 539 files\n",
            "copying 542 files\n",
            "copying 548 files\n",
            "copying 543 files\n",
            "copying 544 files\n",
            "copying 536 files\n",
            "copying 581 files\n",
            "copying 543 files\n",
            "copying 533 files\n",
            "ignor: C/b/depth_1_0001.png\n",
            "copying 529 files\n",
            "ignor: C/e/depth_4_0001.png\n",
            "copying 526 files\n",
            "ignor: C/d/depth_3_0001.png\n",
            "copying 531 files\n",
            "ignor: C/x/depth_23_0001.png\n",
            "copying 539 files\n",
            "ignor: C/k/depth_10_0001.png\n",
            "copying 534 files\n",
            "ignor: C/p/depth_15_0001.png\n",
            "copying 548 files\n",
            "ignor: C/o/depth_14_0001.png\n",
            "copying 586 files\n",
            "ignor: C/l/depth_11_0001.png\n",
            "copying 530 files\n",
            "ignor: C/r/depth_17_0001.png\n",
            "copying 890 files\n",
            "ignor: C/w/depth_22_0001.png\n",
            "copying 529 files\n",
            "ignor: C/t/depth_19_0001.png\n",
            "copying 524 files\n",
            "ignor: C/a/depth_0_0001.png\n",
            "copying 536 files\n",
            "ignor: C/v/depth_21_0001.png\n",
            "copying 530 files\n",
            "ignor: C/u/depth_20_0001.png\n",
            "copying 518 files\n",
            "ignor: C/f/depth_5_0001.png\n",
            "copying 507 files\n",
            "ignor: C/s/depth_18_0001.png\n",
            "copying 541 files\n",
            "ignor: C/q/depth_16_0001.png\n",
            "copying 530 files\n",
            "ignor: C/i/depth_8_0001.png\n",
            "copying 743 files\n",
            "ignor: C/c/depth_2_0001.png\n",
            "copying 564 files\n",
            "ignor: C/n/depth_13_0001.png\n",
            "copying 536 files\n",
            "ignor: C/h/depth_7_0001.png\n",
            "copying 543 files\n",
            "ignor: C/y/depth_24_0001.png\n",
            "copying 538 files\n",
            "ignor: C/m/depth_12_0001.png\n",
            "copying 532 files\n",
            "ignor: C/g/depth_6_0001.png\n",
            "copying 532 files\n",
            "copying 528 files\n",
            "copying 525 files\n",
            "copying 530 files\n",
            "copying 538 files\n",
            "copying 533 files\n",
            "copying 547 files\n",
            "copying 585 files\n",
            "copying 529 files\n",
            "copying 889 files\n",
            "copying 528 files\n",
            "copying 523 files\n",
            "copying 535 files\n",
            "copying 529 files\n",
            "copying 517 files\n",
            "copying 506 files\n",
            "copying 540 files\n",
            "copying 529 files\n",
            "copying 742 files\n",
            "copying 563 files\n",
            "copying 535 files\n",
            "copying 542 files\n",
            "copying 537 files\n",
            "copying 531 files\n",
            "copying 535 files\n",
            "ignor: E/b/depth_1_0001.png\n",
            "copying 540 files\n",
            "ignor: E/e/depth_4_0001.png\n",
            "copying 545 files\n",
            "ignor: E/d/depth_3_0001.png\n",
            "copying 523 files\n",
            "ignor: E/x/depth_23_0001.png\n",
            "copying 570 files\n",
            "ignor: E/k/depth_10_0001.png\n",
            "copying 528 files\n",
            "ignor: E/p/depth_15_0001.png\n",
            "copying 533 files\n",
            "ignor: E/o/depth_14_0001.png\n",
            "copying 515 files\n",
            "ignor: E/l/depth_11_0001.png\n",
            "copying 563 files\n",
            "ignor: E/r/depth_17_0001.png\n",
            "copying 514 files\n",
            "ignor: E/w/depth_22_0001.png\n",
            "copying 532 files\n",
            "ignor: E/t/depth_19_0001.png\n",
            "copying 546 files\n",
            "ignor: E/a/depth_0_0001.png\n",
            "copying 528 files\n",
            "ignor: E/v/depth_21_0001.png\n",
            "copying 530 files\n",
            "ignor: E/u/depth_20_0001.png\n",
            "copying 528 files\n",
            "ignor: E/f/depth_5_0001.png\n",
            "copying 527 files\n",
            "ignor: E/s/depth_18_0001.png\n",
            "copying 530 files\n",
            "ignor: E/q/depth_16_0001.png\n",
            "copying 526 files\n",
            "ignor: E/i/depth_8_0001.png\n",
            "copying 541 files\n",
            "ignor: E/c/depth_2_0001.png\n",
            "copying 531 files\n",
            "ignor: E/n/depth_13_0001.png\n",
            "copying 535 files\n",
            "ignor: E/h/depth_7_0001.png\n",
            "copying 522 files\n",
            "ignor: E/y/depth_24_0001.png\n",
            "copying 526 files\n",
            "ignor: E/m/depth_12_0001.png\n",
            "copying 538 files\n",
            "ignor: E/g/depth_6_0001.png\n",
            "copying 534 files\n",
            "copying 539 files\n",
            "copying 544 files\n",
            "copying 522 files\n",
            "copying 569 files\n",
            "copying 527 files\n",
            "copying 532 files\n",
            "copying 514 files\n",
            "copying 562 files\n",
            "copying 513 files\n",
            "copying 531 files\n",
            "copying 545 files\n",
            "copying 527 files\n",
            "copying 529 files\n",
            "copying 527 files\n",
            "copying 526 files\n",
            "copying 529 files\n",
            "copying 525 files\n",
            "copying 540 files\n",
            "copying 530 files\n",
            "copying 534 files\n",
            "copying 521 files\n",
            "copying 525 files\n",
            "copying 537 files\n",
            "copying 572 files\n",
            "ignor: D/b/depth_1_0001.png\n",
            "copying 528 files\n",
            "ignor: D/e/depth_4_0001.png\n",
            "copying 526 files\n",
            "ignor: D/d/depth_3_0001.png\n",
            "copying 538 files\n",
            "ignor: D/x/depth_23_0001.png\n",
            "copying 540 files\n",
            "ignor: D/k/depth_10_0001.png\n",
            "copying 532 files\n",
            "ignor: D/p/depth_15_0001.png\n",
            "copying 539 files\n",
            "ignor: D/o/depth_14_0001.png\n",
            "copying 565 files\n",
            "ignor: D/l/depth_11_0001.png\n",
            "copying 774 files\n",
            "ignor: D/r/depth_17_0001.png\n",
            "copying 536 files\n",
            "ignor: D/w/depth_22_0001.png\n",
            "copying 530 files\n",
            "ignor: D/t/depth_19_0001.png\n",
            "copying 547 files\n",
            "ignor: D/a/depth_0_0001.png\n",
            "copying 544 files\n",
            "ignor: D/v/depth_21_0001.png\n",
            "copying 532 files\n",
            "ignor: D/u/depth_20_0001.png\n",
            "copying 525 files\n",
            "ignor: D/f/depth_5_0001.png\n",
            "copying 535 files\n",
            "ignor: D/s/depth_18_0001.png\n",
            "copying 550 files\n",
            "ignor: D/q/depth_16_0001.png\n",
            "copying 522 files\n",
            "ignor: D/i/depth_8_0001.png\n",
            "copying 531 files\n",
            "ignor: D/c/depth_2_0001.png\n",
            "copying 530 files\n",
            "ignor: D/n/depth_13_0001.png\n",
            "copying 562 files\n",
            "ignor: D/h/depth_7_0001.png\n",
            "copying 536 files\n",
            "ignor: D/y/depth_24_0001.png\n",
            "copying 542 files\n",
            "ignor: D/m/depth_12_0001.png\n",
            "copying 542 files\n",
            "ignor: D/g/depth_6_0001.png\n",
            "copying 571 files\n",
            "copying 527 files\n",
            "copying 525 files\n",
            "copying 537 files\n",
            "copying 539 files\n",
            "copying 531 files\n",
            "copying 538 files\n",
            "copying 564 files\n",
            "copying 773 files\n",
            "copying 535 files\n",
            "copying 529 files\n",
            "copying 546 files\n",
            "copying 543 files\n",
            "copying 531 files\n",
            "copying 524 files\n",
            "copying 534 files\n",
            "copying 549 files\n",
            "copying 521 files\n",
            "copying 530 files\n",
            "copying 529 files\n",
            "copying 561 files\n",
            "copying 535 files\n",
            "copying 541 files\n",
            "copying 541 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySsSuGu17Tmx",
        "outputId": "ee889c7c-b780-4168-f408-6fe8706b159e"
      },
      "source": [
        "# #/content\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/media/datastorage/Phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXV9cPR2m9oU"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIMPsCOjGdJe"
      },
      "source": [
        "mkdir surrey/E/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kCE27WuwJNf"
      },
      "source": [
        "cd surrey/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wszQliiqtPu"
      },
      "source": [
        "#MUL 1 - Inception - ST\n",
        "\n",
        "from keras.applications import MobileNet\n",
        "# from keras.applications import InceptionV3\n",
        "# from keras.applications import Xception\n",
        "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "# from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
        "\n",
        "# from keras.applications.inception_v3 import preprocess_input\n",
        "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def get_adv_model():\n",
        "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
        "#                     input_shape=(299, 299, 3), \n",
        "#                     pooling='avg')\n",
        "#     f1_x = f1_base.output\n",
        "\n",
        "\n",
        "    f1_base = MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3))  \n",
        "    f1_x = f1_base.output\n",
        "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
        "\n",
        "# f1_x = f1_base.layers[-151].output   #layer 5\n",
        "\n",
        "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
        "# f1_x = Flatten()(f1_x)\n",
        "\n",
        "# f1_x = Reshape([1,1280])(f1_x)  \n",
        "# f1_x = SimpleRNN(2048, \n",
        "#             return_sequences=False,                       \n",
        "# #             dropout=0.8                                     \n",
        "#             input_shape=[1,1280])(f1_x)\n",
        "   \n",
        "    #Regularization with noise\n",
        "    f1_x = GaussianNoise(0.1)(f1_x)\n",
        "\n",
        "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
        "    f1_x = Dense(24, activation='softmax')(f1_x)\n",
        "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
        "    model_1.summary()\n",
        "    \n",
        "    return model_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOqjwlvxqtPu"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "#Stop training on val_acc\n",
        "class EarlyStoppingByAccVal(Callback):\n",
        "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
        "        super(Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "        if current >= self.value:\n",
        "            if self.verbose > 0:\n",
        "                print(\"Epoch %05d: early stopping\" % epoch)\n",
        "            self.model.stop_training = True\n",
        "\n",
        "#Save large model using pickle formate instead of h5            \n",
        "class SaveCheckPoint(Callback):\n",
        "    def __init__(self, model, dest_folder):\n",
        "        super(Callback, self).__init__()\n",
        "        self.model = model\n",
        "        self.dest_folder = dest_folder\n",
        "        \n",
        "        #initiate\n",
        "        self.best_val_acc = 0\n",
        "        self.best_val_loss = sys.maxsize #get max value\n",
        "          \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_acc = logs['val_acc']\n",
        "        val_loss = logs['val_loss']\n",
        "\n",
        "        if val_acc > self.best_val_acc:\n",
        "            self.best_val_acc = val_acc\n",
        "            \n",
        "            # Save weights in pickle format instead of h5\n",
        "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
        "            weigh= self.model.get_weights()\n",
        "\n",
        "            #now, use pickle to save your model weights, instead of .h5\n",
        "            #for heavy model architectures, .h5 file is unsupported.\n",
        "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
        "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "            fpkl.close()\n",
        "            \n",
        "#             model.save('tmp.h5')\n",
        "        elif val_acc == self.best_val_acc:\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss=val_loss\n",
        "                \n",
        "                # Save weights in pickle format instead of h5\n",
        "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
        "                weigh= self.model.get_weights()\n",
        "\n",
        "                #now, use pickle to save your model weights, instead of .h5\n",
        "                #for heavy model architectures, .h5 file is unsupported.\n",
        "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
        "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "                fpkl.close()                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uz-InFqqtPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d34b281-e256-4616-f2d3-709aadd13fd0"
      },
      "source": [
        "# Training\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time, os\n",
        "from math import ceil\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,##\n",
        "#     brightness_range=[0.5, 1.5],##\n",
        "    channel_shift_range=10,##\n",
        "    fill_mode='nearest',\n",
        "    # preprocessing_function=get_cutout_v2(),\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "NUM_GPU = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('surrey/D/train_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"training\"\n",
        "                                              )\n",
        "\n",
        "valid_set = test_datagen.flow_from_directory('surrey/D/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "model_txt = 'st'\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('surrey', 'D', 'checkpoints', 'Surrey_MobileNet_D_tmp.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
        "\n",
        "epochs = 40##!!!\n",
        "lr = 1e-3\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# train on multiple-gpus\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model_mul = get_adv_model()\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
        "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
        "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
        "\n",
        "# result = model_mul.fit_generator(\n",
        "#     generator = train_set, \n",
        "#     steps_per_epoch = step_size_train,\n",
        "#     validation_data = valid_set,\n",
        "#     validation_steps = step_size_valid,\n",
        "#     shuffle=True,\n",
        "#     epochs=epochs,\n",
        "#     callbacks=[checkpointer],\n",
        "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "#     verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52620 images belonging to 24 classes.\n",
            "Found 13154 images belonging to 24 classes.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of GPUs: 1\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                24600     \n",
            "=================================================================\n",
            "Total params: 4,303,064\n",
            "Trainable params: 4,281,176\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rc6oqjlqtPx",
        "outputId": "f2f161e2-428f-488a-d798-9acc43021c13"
      },
      "source": [
        "# Training\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time, os\n",
        "from math import ceil\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,##\n",
        "#     brightness_range=[0.5, 1.5],##\n",
        "    channel_shift_range=10,##\n",
        "    fill_mode='nearest',\n",
        "    # preprocessing_function=get_cutout_v2(),\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "NUM_GPU = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('surrey/D/train_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"training\"\n",
        "                                              )\n",
        "\n",
        "valid_set = test_datagen.flow_from_directory('surrey/D/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "model_txt = 'st'\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
        "\n",
        "epochs = 40##!!!\n",
        "lr = 1e-3\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# train on multiple-gpus\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model_mul = get_adv_model()\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
        "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
        "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52620 images belonging to 24 classes.\n",
            "Found 13154 images belonging to 24 classes.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of GPUs: 1\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                24600     \n",
            "=================================================================\n",
            "Total params: 4,303,064\n",
            "Trainable params: 4,281,176\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "823/823 [==============================] - 719s 855ms/step - loss: 0.6120 - accuracy: 0.8204 - val_loss: 2.0594 - val_accuracy: 0.6145\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61449, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D.hdf5\n",
            "Epoch 2/40\n",
            "823/823 [==============================] - 709s 861ms/step - loss: 0.0967 - accuracy: 0.9696 - val_loss: 3.6853 - val_accuracy: 0.4765\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.61449\n",
            "Epoch 3/40\n",
            "823/823 [==============================] - 710s 862ms/step - loss: 0.0728 - accuracy: 0.9786 - val_loss: 2.8949 - val_accuracy: 0.5533\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.61449\n",
            "Epoch 4/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0632 - accuracy: 0.9810 - val_loss: 1.1949 - val_accuracy: 0.7433\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.61449 to 0.74327, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D.hdf5\n",
            "Epoch 5/40\n",
            "823/823 [==============================] - 706s 858ms/step - loss: 0.0612 - accuracy: 0.9824 - val_loss: 0.5332 - val_accuracy: 0.8511\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.74327 to 0.85115, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D.hdf5\n",
            "Epoch 6/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0442 - accuracy: 0.9866 - val_loss: 1.0812 - val_accuracy: 0.7803\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.85115\n",
            "Epoch 7/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 2.5133 - val_accuracy: 0.6277\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.85115\n",
            "Epoch 8/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 1.4162 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.85115\n",
            "Epoch 9/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 1.0160 - val_accuracy: 0.8020\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.85115\n",
            "Epoch 10/40\n",
            "823/823 [==============================] - 709s 862ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 1.3537 - val_accuracy: 0.7900\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.85115\n",
            "Epoch 11/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 1.0698 - val_accuracy: 0.7837\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.85115\n",
            "Epoch 12/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 1.1290 - val_accuracy: 0.7915\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.85115\n",
            "Epoch 13/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 1.1235 - val_accuracy: 0.7702\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.85115\n",
            "Epoch 14/40\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.7589 - val_accuracy: 0.8313\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.85115\n",
            "Epoch 15/40\n",
            "823/823 [==============================] - 711s 863ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 1.0796 - val_accuracy: 0.7813\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.85115\n",
            "Epoch 16/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.8943 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85115\n",
            "Epoch 17/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.8571 - val_accuracy: 0.8029\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85115\n",
            "Epoch 18/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.8789 - val_accuracy: 0.8167\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85115\n",
            "Epoch 19/40\n",
            "823/823 [==============================] - 707s 858ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.5257 - val_accuracy: 0.8769\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.85115 to 0.87692, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D.hdf5\n",
            "Epoch 20/40\n",
            "823/823 [==============================] - 713s 866ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.7910 - val_accuracy: 0.8201\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87692\n",
            "Epoch 21/40\n",
            "823/823 [==============================] - 709s 861ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.8467 - val_accuracy: 0.8115\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87692\n",
            "Epoch 22/40\n",
            "823/823 [==============================] - 712s 865ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.7001 - val_accuracy: 0.8381\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87692\n",
            "Epoch 23/40\n",
            "823/823 [==============================] - 716s 870ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.6965 - val_accuracy: 0.8372\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87692\n",
            "Epoch 24/40\n",
            "823/823 [==============================] - 714s 868ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 1.5661 - val_accuracy: 0.7052\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87692\n",
            "Epoch 25/40\n",
            "823/823 [==============================] - 715s 869ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.8906 - val_accuracy: 0.8078\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87692\n",
            "Epoch 26/40\n",
            "823/823 [==============================] - 716s 869ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.8363 - val_accuracy: 0.8223\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87692\n",
            "Epoch 27/40\n",
            "823/823 [==============================] - 714s 868ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.5880 - val_accuracy: 0.8591\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87692\n",
            "Epoch 28/40\n",
            "823/823 [==============================] - 714s 867ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 1.2041 - val_accuracy: 0.7797\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87692\n",
            "Epoch 29/40\n",
            "823/823 [==============================] - 716s 869ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.5596 - val_accuracy: 0.8482\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87692\n",
            "Epoch 30/40\n",
            "823/823 [==============================] - 715s 868ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.6576 - val_accuracy: 0.8635\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87692\n",
            "Epoch 31/40\n",
            "823/823 [==============================] - 713s 867ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.7248 - val_accuracy: 0.8641\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87692\n",
            "Epoch 32/40\n",
            "823/823 [==============================] - 713s 866ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.5862 - val_accuracy: 0.8629\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87692\n",
            "Epoch 33/40\n",
            "823/823 [==============================] - 712s 865ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.6765 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87692\n",
            "Epoch 34/40\n",
            "823/823 [==============================] - 710s 862ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.6072 - val_accuracy: 0.8762\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87692\n",
            "Epoch 35/40\n",
            "823/823 [==============================] - 705s 856ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.5312 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87692\n",
            "Epoch 36/40\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.6869 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87692\n",
            "Epoch 37/40\n",
            "823/823 [==============================] - 709s 861ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.7197 - val_accuracy: 0.8344\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87692\n",
            "Epoch 38/40\n",
            "823/823 [==============================] - 711s 864ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.5814 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87692\n",
            "Epoch 39/40\n",
            "823/823 [==============================] - 706s 858ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.8398 - val_accuracy: 0.8288\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87692\n",
            "Epoch 40/40\n",
            "823/823 [==============================] - 701s 852ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 1.1149 - val_accuracy: 0.7738\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlM9FVDqtPy"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbbwOFVGwVvM"
      },
      "source": [
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.load_weights(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJJgjmwhqHRF",
        "outputId": "d354a140-49a5-417a-f9e6-3d8300d39dc5"
      },
      "source": [
        "model_mul.evaluate(valid_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 34s 117ms/step - loss: 0.3835 - accuracy: 0.9023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5256789326667786, 0.8769195675849915]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tH7k4tzeqtPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68beb4a-65ec-4c3b-e413-58dcdb4b0cb4"
      },
      "source": [
        "\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D_L2.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "epochs = 15##!!!\n",
        "lr = 1e-4\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "823/823 [==============================] - 735s 874ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.5809 - val_accuracy: 0.8754\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87540, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D_L2.hdf5\n",
            "Epoch 2/15\n",
            "823/823 [==============================] - 714s 867ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6624 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.87540\n",
            "Epoch 3/15\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5526 - val_accuracy: 0.8811\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.87540 to 0.88110, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D_L2.hdf5\n",
            "Epoch 4/15\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4927 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.88110 to 0.89881, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D_L2.hdf5\n",
            "Epoch 5/15\n",
            "823/823 [==============================] - 707s 858ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.6000 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89881\n",
            "Epoch 6/15\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5619 - val_accuracy: 0.8853\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89881\n",
            "Epoch 7/15\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.6166 - val_accuracy: 0.8805\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.89881\n",
            "Epoch 8/15\n",
            "823/823 [==============================] - 706s 858ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5367 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.89881\n",
            "Epoch 9/15\n",
            "823/823 [==============================] - 705s 856ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.5379 - val_accuracy: 0.8882\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89881\n",
            "Epoch 10/15\n",
            "823/823 [==============================] - 704s 855ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6044 - val_accuracy: 0.8835\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89881\n",
            "Epoch 11/15\n",
            "823/823 [==============================] - 704s 855ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.7025 - val_accuracy: 0.8691\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.89881\n",
            "Epoch 12/15\n",
            "823/823 [==============================] - 705s 856ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6431 - val_accuracy: 0.8780\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89881\n",
            "Epoch 13/15\n",
            "823/823 [==============================] - 704s 855ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.6600 - val_accuracy: 0.8713\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89881\n",
            "Epoch 14/15\n",
            "823/823 [==============================] - 708s 861ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.7839 - val_accuracy: 0.8647\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89881\n",
            "Epoch 15/15\n",
            "823/823 [==============================] - 708s 861ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6969 - val_accuracy: 0.8835\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7gHbA9f_iRK"
      },
      "source": [
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.load_weights(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D_L2.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pog-MY0LsiYT",
        "outputId": "1f6a6803-7ec8-4179-8edc-9490826733a3"
      },
      "source": [
        "model_mul.evaluate(valid_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 30s 116ms/step - loss: 0.4206 - accuracy: 0.9067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49265995621681213, 0.8988140225410461]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtpZyKMykDJA",
        "outputId": "a9cf93e6-4727-4f0d-ceb6-8b45c53ff123"
      },
      "source": [
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D_L3.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "epochs = 15##!!!\n",
        "lr = 1e-5\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "823/823 [==============================] - 719s 860ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5070 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.89539, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D_L3.hdf5\n",
            "Epoch 2/15\n",
            "823/823 [==============================] - 707s 858ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.4901 - val_accuracy: 0.8965\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.89539 to 0.89653, saving model to gdrive/My Drive/Surrey_ASL/5_Surrey_MobileNet_D_L3.hdf5\n",
            "Epoch 3/15\n",
            "823/823 [==============================] - 705s 856ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.5018 - val_accuracy: 0.8951\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.89653\n",
            "Epoch 4/15\n",
            "823/823 [==============================] - 705s 856ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.4899 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.89653\n",
            "Epoch 5/15\n",
            "823/823 [==============================] - 706s 857ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5039 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89653\n",
            "Epoch 6/15\n",
            "823/823 [==============================] - 704s 856ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.5228 - val_accuracy: 0.8920\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89653\n",
            "Epoch 7/15\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.5248 - val_accuracy: 0.8911\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.89653\n",
            "Epoch 8/15\n",
            "823/823 [==============================] - 705s 857ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5251 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.89653\n",
            "Epoch 9/15\n",
            "823/823 [==============================] - 706s 857ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.5168 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89653\n",
            "Epoch 10/15\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5200 - val_accuracy: 0.8921\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89653\n",
            "Epoch 11/15\n",
            "823/823 [==============================] - 707s 858ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.5448 - val_accuracy: 0.8901\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.89653\n",
            "Epoch 12/15\n",
            "823/823 [==============================] - 708s 860ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.5394 - val_accuracy: 0.8895\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89653\n",
            "Epoch 13/15\n",
            "823/823 [==============================] - 707s 859ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.5364 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89653\n",
            "Epoch 14/15\n",
            "823/823 [==============================] - 706s 857ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.5462 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89653\n",
            "Epoch 15/15\n",
            "823/823 [==============================] - 706s 858ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.5466 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrcWwX55tJWL"
      },
      "source": [
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.load_weights(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '5_Surrey_MobileNet_D_L3.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV1wo91DtIkD",
        "outputId": "25f3b772-098d-423c-edca-95d3fc591eda"
      },
      "source": [
        "model_mul.evaluate(valid_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 30s 118ms/step - loss: 0.4298 - accuracy: 0.9053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4901493191719055, 0.8965333700180054]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Aa5f4w6Aqsg9",
        "outputId": "19d2c229-07c3-46b7-d05a-305b9a2f43e3"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time, os\n",
        "from math import ceil\n",
        "\n",
        "# PREDICT ON OFFICIAL TEST\n",
        "train_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,##\n",
        "#     brightness_range=[0.5, 1.5],##\n",
        "    channel_shift_range=10,##\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_datagen1 = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('surrey/D/train_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"training\"\n",
        "                                              )\n",
        "\n",
        "test_set1 = test_datagen1.flow_from_directory('surrey/D/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "# if NUM_GPU != 1:\n",
        "predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
        "# else:\n",
        "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
        "    \n",
        "predicted_class_indices=np.argmax(predict1,axis=1)\n",
        "labels = (train_set.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions1 = [labels[k] for k in predicted_class_indices]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "filenames=test_set1.filenames\n",
        "results=pd.DataFrame({\"file_name\":filenames,\n",
        "                      \"predicted1\":predictions1,\n",
        "                      })\n",
        "results.to_csv('Surrey_MobileNet_D_L3_0902.csv')\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52620 images belonging to 24 classes.\n",
            "Found 13154 images belonging to 24 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 26s 120ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>predicted1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a/D_color_0_0002.png</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a/D_color_0_0003.png</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a/D_color_0_0004.png</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a/D_color_0_0005.png</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a/D_color_0_0006.png</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              file_name predicted1\n",
              "0  a/D_color_0_0002.png          a\n",
              "1  a/D_color_0_0003.png          a\n",
              "2  a/D_color_0_0004.png          a\n",
              "3  a/D_color_0_0005.png          a\n",
              "4  a/D_color_0_0006.png          a"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWjjSHnGrnxG"
      },
      "source": [
        "np.save(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', 'npy', '5Colab_Surrey_MobileNet_D_L2_0902.hdf5'), predict1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVXYSHS7thEY"
      },
      "source": [
        "np.save(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', 'npy', '5Colab_Surrey_MobileNet_D_L3_0902.hdf5'), predict1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZY19H9TkLKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696f0fb0-38db-4815-cc40-a8be89475796"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input)\n",
        "\n",
        "testing_set = test_datagen.flow_from_directory('surrey/D/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 seed=7,\n",
        "                                                 shuffle=False\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "y_pred = model_mul.predict_generator(testing_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_true = testing_set.classes\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# print(model.evaluate_generator(testing_set,\n",
        "#                                steps = testing_set.n//testing_set.batch_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13154 images belonging to 24 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[514   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   0   0\n",
            "   20   0   0   0   0   0]\n",
            " [  0 565   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   1 526   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
            "    0   0   0   1   0   0]\n",
            " [  0   0   1 337   0   2   0   0   1   9   5   0   0 128   0   0   0   0\n",
            "    0   1   4   6  31   0]\n",
            " [  0   6   0   0 511   1   0   0   1   0   0   0   0   0   0   0   8   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   1   0   0 430   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  34  56   3   0]\n",
            " [  0   0   5   0   2   2 477  40   4   2   0   0   0   0   6   0   0   0\n",
            "    0   0   0   0   3   0]\n",
            " [  0   0   0   0   0   0   0 561   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 488   1   0   0   0   0   0   0   0   0\n",
            "   24   0   0   0   0   8]\n",
            " [  0   0   0   0   0   8   0  11   0 518   0   0   0   0   0   0   0   0\n",
            "    0   1   1   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 558   0   0   0   0   0   0   0\n",
            "    0   0   6   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0   0 538   0   0   1   0   0   0\n",
            "    0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  18   1   0 255 213   0  15   0   0   0\n",
            "   26   0   1   0   0   0]\n",
            " [  0   0   3   0   2   0   0   0  11   0   0   0   0 513   0   0   0   3\n",
            "    1   0   0   0   1   4]\n",
            " [  0   1  14   1   0  12   0   0   0   7   0   0   0   0 408  67   1   0\n",
            "    0   2   1   1   2  14]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0  73 466   0   0\n",
            "    0   6   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 760   0\n",
            "    0   5   7   0   1   0]\n",
            " [  0   0   0   0   5   0   0   0  26   0   0   0   5  13   0   0   0 423\n",
            "   61   0   0   0   0   1]\n",
            " [  1   0   0   0   0   0   0   0   7   0   0  10  51   0   0   0   0   0\n",
            "  456   0   0   0   0   4]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0 527   2   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0   0\n",
            "    0   0 515  19   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   1 534   0   0]\n",
            " [  0   1   0   2   0   5   0   0   4  13   0   0   0   0   5   0  75   0\n",
            "    0   5   0   0 427   0]\n",
            " [  0   0   0   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 528]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as5-kZJZeOYi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGCKo7UImjLo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xMLFBZEK4Rt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DBewr1xLpKq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le4SgbXkK7Fd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkv4WXdmLOZG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do2PnIyXfwgc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxkumxw1YGNy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYe5AaVp9OH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP-OnVj5LSDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf9FmkAVHkf0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juICyuElcBb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Qvh9qdXCbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7xkHd_ehyXa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLnd3hib_Eu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-T2S3-ixzqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4JkwCKkvkFW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}