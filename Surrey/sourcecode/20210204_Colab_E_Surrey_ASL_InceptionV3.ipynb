{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20210204_Colab9_E_Surrey_ASL_InceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgBL5UW-XLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e863649d-1932-4cc7-b2e7-bd03fc27e117"
      },
      "source": [
        "ls -l| tail -10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2193900\n",
            "-rw------- 1 root root 2246539027 Feb  8 10:34 fingerspelling5.tar.bz2\n",
            "drwx------ 5 root root       4096 Feb  8 10:32 \u001b[0m\u001b[01;34mgdrive\u001b[0m/\n",
            "drwxr-xr-x 1 root root       4096 Feb  4 15:26 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7JeSMCPNgrF",
        "outputId": "e94bbcdc-efa7-4ec2-b5c0-059a808770e3"
      },
      "source": [
        "#G4\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl8a81P8NkSE"
      },
      "source": [
        "cp gdrive/My\\ Drive/fingerspelling5.tar.bz2 fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9HCXeVyqtPq"
      },
      "source": [
        "# rm fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pDE3biHqtPq",
        "outputId": "d7c8e2ec-490e-4ff1-ee27-d72743d99fb2"
      },
      "source": [
        "# cd /media/datastorage/Phong/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/media/datastorage/Phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFdjWyY5NwwL"
      },
      "source": [
        "!tar xjf fingerspelling5.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Vsvp9W5fJu",
        "outputId": "dfa1e201-6bd0-45ed-f2ba-15c916105e4f"
      },
      "source": [
        "cd dataset5/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPA8-rDbqtPr"
      },
      "source": [
        "mkdir surrey"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTZia9GbqtPr"
      },
      "source": [
        "mkdir surrey/E"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7F8ou8qtPs"
      },
      "source": [
        "mv dataset5/* surrey/E/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SswlvOGSqtPs",
        "outputId": "718b9e5a-2b27-458c-c41e-61169b039263"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlybdoQz5VnW",
        "outputId": "61d95051-0d1a-40db-a517-a7c57ebb1cfb"
      },
      "source": [
        "#remove depth files\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# get parts of image's path\n",
        "def get_image_parts(image_path):\n",
        "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
        "    parts = image_path.split(os.path.sep)\n",
        "    #print(parts)\n",
        "    filename = parts[2]\n",
        "    filename_no_ext = filename.split('.')[0]\n",
        "    classname = parts[1]\n",
        "    train_or_test = parts[0]\n",
        "\n",
        "    return train_or_test, classname, filename_no_ext, filename\n",
        "\n",
        "\n",
        "#del_folders = ['A','B','C','D','E']  \n",
        "move_folders_1 = ['A','B','C','D']  \n",
        "move_folders_2 = ['E']\n",
        "\n",
        "# look for all images in sub-folders\n",
        "for folder in move_folders_1:\n",
        "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
        "        \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            if \"0001\" not in src: \n",
        "                train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "                dst = os.path.join('train_depth', classname, train_or_test+'_'+ filename)\n",
        "\n",
        "                # image directory\n",
        "                img_directory = os.path.join('train_depth', classname)\n",
        "\n",
        "                # create folder if not existed\n",
        "                if not os.path.exists(img_directory):\n",
        "                    os.makedirs(img_directory)\n",
        "\n",
        "                #copying\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print('ignor: %s' %src)\n",
        "            \n",
        "        #move color files    \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "            dst = os.path.join('train_color', classname, train_or_test+'_'+ filename)\n",
        "            \n",
        "            # image directory\n",
        "            img_directory = os.path.join('train_color', classname)\n",
        "\n",
        "            # create folder if not existed\n",
        "            if not os.path.exists(img_directory):\n",
        "                os.makedirs(img_directory)\n",
        "            \n",
        "            #copying\n",
        "            shutil.copy(src, dst)\n",
        "            \n",
        "# look for all images in sub-folders\n",
        "for folder in move_folders_2:\n",
        "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
        "        \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'depth*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            if \"0001\" not in src: \n",
        "                train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "                dst = os.path.join('test_depth', classname, train_or_test+'_'+ filename)\n",
        "\n",
        "                # image directory\n",
        "                img_directory = os.path.join('test_depth', classname)\n",
        "\n",
        "                # create folder if not existed\n",
        "                if not os.path.exists(img_directory):\n",
        "                    os.makedirs(img_directory)\n",
        "\n",
        "                #copying\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print('ignor: %s' %src)\n",
        "            \n",
        "        #move color files    \n",
        "    for iid_class in class_folders:\n",
        "        #move depth files\n",
        "        class_files = glob.glob(os.path.join(iid_class, 'color*.png'))\n",
        "        \n",
        "        print('copying %d files' %(len(class_files)))\n",
        "        for idx in range(len(class_files)):        \n",
        "            src = class_files[idx]\n",
        "            train_or_test, classname, _, filename = get_image_parts(src)\n",
        "\n",
        "            dst = os.path.join('test_color', classname, train_or_test+'_'+ filename)\n",
        "            \n",
        "            # image directory\n",
        "            img_directory = os.path.join('test_color', classname)\n",
        "\n",
        "            # create folder if not existed\n",
        "            if not os.path.exists(img_directory):\n",
        "                os.makedirs(img_directory)\n",
        "            \n",
        "            #copying\n",
        "            shutil.copy(src, dst)                "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "copying 522 files\n",
            "ignor: A/x/depth_23_0001.png\n",
            "copying 516 files\n",
            "ignor: A/q/depth_16_0001.png\n",
            "copying 507 files\n",
            "ignor: A/v/depth_21_0001.png\n",
            "copying 471 files\n",
            "copying 512 files\n",
            "ignor: A/o/depth_14_0001.png\n",
            "copying 533 files\n",
            "ignor: A/y/depth_24_0001.png\n",
            "copying 528 files\n",
            "ignor: A/g/depth_6_0001.png\n",
            "copying 516 files\n",
            "ignor: A/l/depth_11_0001.png\n",
            "copying 524 files\n",
            "ignor: A/t/depth_19_0001.png\n",
            "copying 528 files\n",
            "ignor: A/a/depth_0_0001.png\n",
            "copying 523 files\n",
            "ignor: A/h/depth_7_0001.png\n",
            "copying 536 files\n",
            "ignor: A/d/depth_3_0001.png\n",
            "copying 516 files\n",
            "ignor: A/b/depth_1_0001.png\n",
            "copying 557 files\n",
            "ignor: A/c/depth_2_0001.png\n",
            "copying 527 files\n",
            "ignor: A/m/depth_12_0001.png\n",
            "copying 528 files\n",
            "ignor: A/r/depth_17_0001.png\n",
            "copying 530 files\n",
            "ignor: A/n/depth_13_0001.png\n",
            "copying 525 files\n",
            "ignor: A/w/depth_22_0001.png\n",
            "copying 524 files\n",
            "ignor: A/u/depth_20_0001.png\n",
            "copying 572 files\n",
            "ignor: A/p/depth_15_0001.png\n",
            "copying 518 files\n",
            "ignor: A/k/depth_10_0001.png\n",
            "copying 515 files\n",
            "ignor: A/i/depth_8_0001.png\n",
            "copying 524 files\n",
            "ignor: A/e/depth_4_0001.png\n",
            "copying 519 files\n",
            "ignor: A/f/depth_5_0001.png\n",
            "copying 521 files\n",
            "copying 515 files\n",
            "copying 506 files\n",
            "copying 470 files\n",
            "copying 511 files\n",
            "copying 532 files\n",
            "copying 527 files\n",
            "copying 515 files\n",
            "copying 523 files\n",
            "copying 527 files\n",
            "copying 522 files\n",
            "copying 535 files\n",
            "copying 515 files\n",
            "copying 556 files\n",
            "copying 526 files\n",
            "copying 527 files\n",
            "copying 529 files\n",
            "copying 524 files\n",
            "copying 523 files\n",
            "copying 571 files\n",
            "copying 517 files\n",
            "copying 514 files\n",
            "copying 523 files\n",
            "copying 518 files\n",
            "copying 622 files\n",
            "ignor: B/x/depth_23_0001.png\n",
            "copying 540 files\n",
            "ignor: B/q/depth_16_0001.png\n",
            "copying 628 files\n",
            "ignor: B/v/depth_21_0001.png\n",
            "copying 749 files\n",
            "ignor: B/s/depth_18_0001.png\n",
            "copying 529 files\n",
            "ignor: B/o/depth_14_0001.png\n",
            "copying 537 files\n",
            "ignor: B/y/depth_24_0001.png\n",
            "copying 544 files\n",
            "ignor: B/g/depth_6_0001.png\n",
            "copying 577 files\n",
            "ignor: B/l/depth_11_0001.png\n",
            "copying 514 files\n",
            "ignor: B/t/depth_19_0001.png\n",
            "copying 536 files\n",
            "ignor: B/a/depth_0_0001.png\n",
            "copying 545 files\n",
            "ignor: B/h/depth_7_0001.png\n",
            "copying 552 files\n",
            "ignor: B/d/depth_3_0001.png\n",
            "copying 577 files\n",
            "ignor: B/b/depth_1_0001.png\n",
            "copying 549 files\n",
            "ignor: B/c/depth_2_0001.png\n",
            "copying 582 files\n",
            "ignor: B/m/depth_12_0001.png\n",
            "copying 550 files\n",
            "ignor: B/r/depth_17_0001.png\n",
            "copying 544 files\n",
            "ignor: B/n/depth_13_0001.png\n",
            "copying 648 files\n",
            "ignor: B/w/depth_22_0001.png\n",
            "copying 542 files\n",
            "ignor: B/u/depth_20_0001.png\n",
            "copying 642 files\n",
            "ignor: B/p/depth_15_0001.png\n",
            "copying 777 files\n",
            "ignor: B/k/depth_10_0001.png\n",
            "copying 543 files\n",
            "ignor: B/i/depth_8_0001.png\n",
            "copying 565 files\n",
            "ignor: B/e/depth_4_0001.png\n",
            "copying 530 files\n",
            "ignor: B/f/depth_5_0001.png\n",
            "copying 621 files\n",
            "copying 539 files\n",
            "copying 627 files\n",
            "copying 748 files\n",
            "copying 528 files\n",
            "copying 536 files\n",
            "copying 543 files\n",
            "copying 576 files\n",
            "copying 513 files\n",
            "copying 535 files\n",
            "copying 544 files\n",
            "copying 551 files\n",
            "copying 576 files\n",
            "copying 548 files\n",
            "copying 581 files\n",
            "copying 549 files\n",
            "copying 543 files\n",
            "copying 647 files\n",
            "copying 541 files\n",
            "copying 641 files\n",
            "copying 776 files\n",
            "copying 542 files\n",
            "copying 564 files\n",
            "copying 529 files\n",
            "copying 531 files\n",
            "ignor: C/x/depth_23_0001.png\n",
            "copying 541 files\n",
            "ignor: C/q/depth_16_0001.png\n",
            "copying 536 files\n",
            "ignor: C/v/depth_21_0001.png\n",
            "copying 507 files\n",
            "ignor: C/s/depth_18_0001.png\n",
            "copying 548 files\n",
            "ignor: C/o/depth_14_0001.png\n",
            "copying 543 files\n",
            "ignor: C/y/depth_24_0001.png\n",
            "copying 532 files\n",
            "ignor: C/g/depth_6_0001.png\n",
            "copying 586 files\n",
            "ignor: C/l/depth_11_0001.png\n",
            "copying 529 files\n",
            "ignor: C/t/depth_19_0001.png\n",
            "copying 524 files\n",
            "ignor: C/a/depth_0_0001.png\n",
            "copying 536 files\n",
            "ignor: C/h/depth_7_0001.png\n",
            "copying 526 files\n",
            "ignor: C/d/depth_3_0001.png\n",
            "copying 533 files\n",
            "ignor: C/b/depth_1_0001.png\n",
            "copying 743 files\n",
            "ignor: C/c/depth_2_0001.png\n",
            "copying 538 files\n",
            "ignor: C/m/depth_12_0001.png\n",
            "copying 530 files\n",
            "ignor: C/r/depth_17_0001.png\n",
            "copying 564 files\n",
            "ignor: C/n/depth_13_0001.png\n",
            "copying 890 files\n",
            "ignor: C/w/depth_22_0001.png\n",
            "copying 530 files\n",
            "ignor: C/u/depth_20_0001.png\n",
            "copying 534 files\n",
            "ignor: C/p/depth_15_0001.png\n",
            "copying 539 files\n",
            "ignor: C/k/depth_10_0001.png\n",
            "copying 530 files\n",
            "ignor: C/i/depth_8_0001.png\n",
            "copying 529 files\n",
            "ignor: C/e/depth_4_0001.png\n",
            "copying 518 files\n",
            "ignor: C/f/depth_5_0001.png\n",
            "copying 530 files\n",
            "copying 540 files\n",
            "copying 535 files\n",
            "copying 506 files\n",
            "copying 547 files\n",
            "copying 542 files\n",
            "copying 531 files\n",
            "copying 585 files\n",
            "copying 528 files\n",
            "copying 523 files\n",
            "copying 535 files\n",
            "copying 525 files\n",
            "copying 532 files\n",
            "copying 742 files\n",
            "copying 537 files\n",
            "copying 529 files\n",
            "copying 563 files\n",
            "copying 889 files\n",
            "copying 529 files\n",
            "copying 533 files\n",
            "copying 538 files\n",
            "copying 529 files\n",
            "copying 528 files\n",
            "copying 517 files\n",
            "copying 538 files\n",
            "ignor: D/x/depth_23_0001.png\n",
            "copying 550 files\n",
            "ignor: D/q/depth_16_0001.png\n",
            "copying 544 files\n",
            "ignor: D/v/depth_21_0001.png\n",
            "copying 535 files\n",
            "ignor: D/s/depth_18_0001.png\n",
            "copying 539 files\n",
            "ignor: D/o/depth_14_0001.png\n",
            "copying 536 files\n",
            "ignor: D/y/depth_24_0001.png\n",
            "copying 542 files\n",
            "ignor: D/g/depth_6_0001.png\n",
            "copying 565 files\n",
            "ignor: D/l/depth_11_0001.png\n",
            "copying 530 files\n",
            "ignor: D/t/depth_19_0001.png\n",
            "copying 547 files\n",
            "ignor: D/a/depth_0_0001.png\n",
            "copying 562 files\n",
            "ignor: D/h/depth_7_0001.png\n",
            "copying 526 files\n",
            "ignor: D/d/depth_3_0001.png\n",
            "copying 572 files\n",
            "ignor: D/b/depth_1_0001.png\n",
            "copying 531 files\n",
            "ignor: D/c/depth_2_0001.png\n",
            "copying 542 files\n",
            "ignor: D/m/depth_12_0001.png\n",
            "copying 774 files\n",
            "ignor: D/r/depth_17_0001.png\n",
            "copying 530 files\n",
            "ignor: D/n/depth_13_0001.png\n",
            "copying 536 files\n",
            "ignor: D/w/depth_22_0001.png\n",
            "copying 532 files\n",
            "ignor: D/u/depth_20_0001.png\n",
            "copying 532 files\n",
            "ignor: D/p/depth_15_0001.png\n",
            "copying 540 files\n",
            "ignor: D/k/depth_10_0001.png\n",
            "copying 522 files\n",
            "ignor: D/i/depth_8_0001.png\n",
            "copying 528 files\n",
            "ignor: D/e/depth_4_0001.png\n",
            "copying 525 files\n",
            "ignor: D/f/depth_5_0001.png\n",
            "copying 537 files\n",
            "copying 549 files\n",
            "copying 543 files\n",
            "copying 534 files\n",
            "copying 538 files\n",
            "copying 535 files\n",
            "copying 541 files\n",
            "copying 564 files\n",
            "copying 529 files\n",
            "copying 546 files\n",
            "copying 561 files\n",
            "copying 525 files\n",
            "copying 571 files\n",
            "copying 530 files\n",
            "copying 541 files\n",
            "copying 773 files\n",
            "copying 529 files\n",
            "copying 535 files\n",
            "copying 531 files\n",
            "copying 531 files\n",
            "copying 539 files\n",
            "copying 521 files\n",
            "copying 527 files\n",
            "copying 524 files\n",
            "copying 523 files\n",
            "ignor: E/x/depth_23_0001.png\n",
            "copying 530 files\n",
            "ignor: E/q/depth_16_0001.png\n",
            "copying 528 files\n",
            "ignor: E/v/depth_21_0001.png\n",
            "copying 527 files\n",
            "ignor: E/s/depth_18_0001.png\n",
            "copying 533 files\n",
            "ignor: E/o/depth_14_0001.png\n",
            "copying 522 files\n",
            "ignor: E/y/depth_24_0001.png\n",
            "copying 538 files\n",
            "ignor: E/g/depth_6_0001.png\n",
            "copying 515 files\n",
            "ignor: E/l/depth_11_0001.png\n",
            "copying 532 files\n",
            "ignor: E/t/depth_19_0001.png\n",
            "copying 546 files\n",
            "ignor: E/a/depth_0_0001.png\n",
            "copying 535 files\n",
            "ignor: E/h/depth_7_0001.png\n",
            "copying 545 files\n",
            "ignor: E/d/depth_3_0001.png\n",
            "copying 535 files\n",
            "ignor: E/b/depth_1_0001.png\n",
            "copying 541 files\n",
            "ignor: E/c/depth_2_0001.png\n",
            "copying 526 files\n",
            "ignor: E/m/depth_12_0001.png\n",
            "copying 563 files\n",
            "ignor: E/r/depth_17_0001.png\n",
            "copying 531 files\n",
            "ignor: E/n/depth_13_0001.png\n",
            "copying 514 files\n",
            "ignor: E/w/depth_22_0001.png\n",
            "copying 530 files\n",
            "ignor: E/u/depth_20_0001.png\n",
            "copying 528 files\n",
            "ignor: E/p/depth_15_0001.png\n",
            "copying 570 files\n",
            "ignor: E/k/depth_10_0001.png\n",
            "copying 526 files\n",
            "ignor: E/i/depth_8_0001.png\n",
            "copying 540 files\n",
            "ignor: E/e/depth_4_0001.png\n",
            "copying 528 files\n",
            "ignor: E/f/depth_5_0001.png\n",
            "copying 522 files\n",
            "copying 529 files\n",
            "copying 527 files\n",
            "copying 526 files\n",
            "copying 532 files\n",
            "copying 521 files\n",
            "copying 537 files\n",
            "copying 514 files\n",
            "copying 531 files\n",
            "copying 545 files\n",
            "copying 534 files\n",
            "copying 544 files\n",
            "copying 534 files\n",
            "copying 540 files\n",
            "copying 525 files\n",
            "copying 562 files\n",
            "copying 530 files\n",
            "copying 513 files\n",
            "copying 529 files\n",
            "copying 527 files\n",
            "copying 569 files\n",
            "copying 525 files\n",
            "copying 539 files\n",
            "copying 527 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySsSuGu17Tmx",
        "outputId": "ee889c7c-b780-4168-f408-6fe8706b159e"
      },
      "source": [
        "# #/content\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/media/datastorage/Phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXV9cPR2m9oU"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIMPsCOjGdJe"
      },
      "source": [
        "mkdir surrey/E/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kCE27WuwJNf"
      },
      "source": [
        "cd surrey/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wszQliiqtPu"
      },
      "source": [
        "#MUL 1 - Inception - ST\n",
        "\n",
        "# from keras.applications import MobileNet\n",
        "from keras.applications import InceptionV3\n",
        "# from keras.applications import Xception\n",
        "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
        "\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "# from keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "from keras.layers import GaussianNoise\n",
        "\n",
        "def get_adv_model():\n",
        "#     f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
        "#                     input_shape=(299, 299, 3), \n",
        "#                     pooling='avg')\n",
        "#     f1_x = f1_base.output\n",
        "\n",
        "\n",
        "    f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
        "    f1_x = f1_base.output\n",
        "    f1_x = GlobalAveragePooling2D()(f1_x)    \n",
        "\n",
        "# f1_x = f1_base.layers[-151].output   #layer 5\n",
        "\n",
        "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
        "# f1_x = Flatten()(f1_x)\n",
        "\n",
        "# f1_x = Reshape([1,1280])(f1_x)  \n",
        "# f1_x = SimpleRNN(2048, \n",
        "#             return_sequences=False,                       \n",
        "# #             dropout=0.8                                     \n",
        "#             input_shape=[1,1280])(f1_x)\n",
        "   \n",
        "    #Regularization with noise\n",
        "    f1_x = GaussianNoise(0.1)(f1_x)\n",
        "\n",
        "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
        "    f1_x = Dense(24, activation='softmax')(f1_x)\n",
        "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
        "    model_1.summary()\n",
        "    \n",
        "    return model_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOqjwlvxqtPu"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "#Stop training on val_acc\n",
        "class EarlyStoppingByAccVal(Callback):\n",
        "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
        "        super(Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "        if current >= self.value:\n",
        "            if self.verbose > 0:\n",
        "                print(\"Epoch %05d: early stopping\" % epoch)\n",
        "            self.model.stop_training = True\n",
        "\n",
        "#Save large model using pickle formate instead of h5            \n",
        "class SaveCheckPoint(Callback):\n",
        "    def __init__(self, model, dest_folder):\n",
        "        super(Callback, self).__init__()\n",
        "        self.model = model\n",
        "        self.dest_folder = dest_folder\n",
        "        \n",
        "        #initiate\n",
        "        self.best_val_acc = 0\n",
        "        self.best_val_loss = sys.maxsize #get max value\n",
        "          \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_acc = logs['val_acc']\n",
        "        val_loss = logs['val_loss']\n",
        "\n",
        "        if val_acc > self.best_val_acc:\n",
        "            self.best_val_acc = val_acc\n",
        "            \n",
        "            # Save weights in pickle format instead of h5\n",
        "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
        "            weigh= self.model.get_weights()\n",
        "\n",
        "            #now, use pickle to save your model weights, instead of .h5\n",
        "            #for heavy model architectures, .h5 file is unsupported.\n",
        "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
        "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "            fpkl.close()\n",
        "            \n",
        "#             model.save('tmp.h5')\n",
        "        elif val_acc == self.best_val_acc:\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss=val_loss\n",
        "                \n",
        "                # Save weights in pickle format instead of h5\n",
        "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
        "                weigh= self.model.get_weights()\n",
        "\n",
        "                #now, use pickle to save your model weights, instead of .h5\n",
        "                #for heavy model architectures, .h5 file is unsupported.\n",
        "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
        "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "                fpkl.close()                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uz-InFqqtPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac1824e-31ed-4f72-a257-f208155496a1"
      },
      "source": [
        "# Training\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time, os\n",
        "from math import ceil\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,##\n",
        "#     brightness_range=[0.5, 1.5],##\n",
        "    channel_shift_range=10,##\n",
        "    fill_mode='nearest',\n",
        "    # preprocessing_function=get_cutout_v2(),\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "NUM_GPU = 1\n",
        "batch_size = 32\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('surrey/E/train_color/',\n",
        "                                                 target_size = (299, 299),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"training\"\n",
        "                                              )\n",
        "\n",
        "valid_set = test_datagen.flow_from_directory('surrey/E/test_color/',\n",
        "                                                 target_size = (299, 299),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "model_txt = 'st'\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('surrey', 'E', 'checkpoints', 'Surrey_InceptionV3_E.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
        "\n",
        "epochs = 40##!!!\n",
        "lr = 1e-3\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# train on multiple-gpus\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model_mul = get_adv_model()\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
        "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
        "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
        "\n",
        "# result = model_mul.fit_generator(\n",
        "#     generator = train_set, \n",
        "#     steps_per_epoch = step_size_train,\n",
        "#     validation_data = valid_set,\n",
        "#     validation_steps = step_size_valid,\n",
        "#     shuffle=True,\n",
        "#     epochs=epochs,\n",
        "#     callbacks=[checkpointer],\n",
        "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "#     verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52992 images belonging to 24 classes.\n",
            "Found 12782 images belonging to 24 classes.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of GPUs: 1\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise (GaussianNoise)  (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     gaussian_noise[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 24)           24600       dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 23,925,560\n",
            "Trainable params: 23,891,128\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rc6oqjlqtPx",
        "outputId": "9e650c5d-4a83-4c88-b181-16c298829ca4"
      },
      "source": [
        "# Training\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time, os\n",
        "from math import ceil\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,##\n",
        "#     brightness_range=[0.5, 1.5],##\n",
        "    channel_shift_range=10,##\n",
        "    fill_mode='nearest',\n",
        "    # preprocessing_function=get_cutout_v2(),\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "#     rescale = 1./255\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "NUM_GPU = 1\n",
        "batch_size = 32\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('surrey/E/train_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"training\"\n",
        "                                              )\n",
        "\n",
        "valid_set = test_datagen.flow_from_directory('surrey/E/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False,\n",
        "                                                 seed=7,\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "model_txt = 'st'\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '9_Surrey_InceptionV3_E.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
        "\n",
        "epochs = 40##!!!\n",
        "lr = 1e-3\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# train on multiple-gpus\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model_mul = get_adv_model()\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
        "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
        "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 52992 images belonging to 24 classes.\n",
            "Found 12782 images belonging to 24 classes.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of GPUs: 1\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 149, 149, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 149, 149, 32) 96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 149, 149, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 147, 147, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 147, 147, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 147, 147, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 147, 147, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 147, 147, 64) 192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 147, 147, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 73, 73, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 73, 73, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 71, 71, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 71, 71, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 71, 71, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 35, 35, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 35, 35, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 35, 35, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 35, 35, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 35, 35, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 35, 35, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 35, 35, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 35, 35, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 35, 35, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 35, 35, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 35, 35, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 35, 35, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 35, 35, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 35, 35, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 35, 35, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 35, 35, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 35, 35, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 35, 35, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 35, 35, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 35, 35, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 35, 35, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 35, 35, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 35, 35, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 35, 35, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 35, 35, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 35, 35, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 35, 35, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 35, 35, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 35, 35, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 35, 35, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 35, 35, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 35, 35, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 35, 35, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 35, 35, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 35, 35, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 35, 35, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 35, 35, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 35, 35, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 35, 35, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 35, 35, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 35, 35, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 35, 35, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 384)  1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 128)  384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 192)  576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 160)  480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 160)  480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 17, 17, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 17, 17, 192)  576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 17, 17, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 17, 17, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_1 (GaussianNoise (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         2098176     gaussian_noise_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 24)           24600       dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,925,560\n",
            "Trainable params: 23,891,128\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1656/1656 [==============================] - 784s 462ms/step - loss: 1.6691 - accuracy: 0.4793 - val_loss: 0.9439 - val_accuracy: 0.8414\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84142, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 2/40\n",
            "1656/1656 [==============================] - 755s 456ms/step - loss: 0.2667 - accuracy: 0.9191 - val_loss: 0.6357 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.84142 to 0.87193, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 3/40\n",
            "1656/1656 [==============================] - 755s 455ms/step - loss: 0.1726 - accuracy: 0.9479 - val_loss: 1.0655 - val_accuracy: 0.7821\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.87193\n",
            "Epoch 4/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.1314 - accuracy: 0.9609 - val_loss: 0.7095 - val_accuracy: 0.8591\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.87193\n",
            "Epoch 5/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.1086 - accuracy: 0.9674 - val_loss: 0.5280 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.87193 to 0.89071, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 6/40\n",
            "1656/1656 [==============================] - 751s 454ms/step - loss: 0.0985 - accuracy: 0.9712 - val_loss: 0.3751 - val_accuracy: 0.9112\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.89071 to 0.91120, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 7/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.0834 - accuracy: 0.9748 - val_loss: 0.5596 - val_accuracy: 0.8993\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91120\n",
            "Epoch 8/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.0738 - accuracy: 0.9783 - val_loss: 0.7013 - val_accuracy: 0.8575\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91120\n",
            "Epoch 9/40\n",
            "1656/1656 [==============================] - 746s 451ms/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 0.5585 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91120\n",
            "Epoch 10/40\n",
            "1656/1656 [==============================] - 749s 452ms/step - loss: 0.0658 - accuracy: 0.9805 - val_loss: 0.6810 - val_accuracy: 0.8673\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91120\n",
            "Epoch 11/40\n",
            "1656/1656 [==============================] - 748s 452ms/step - loss: 0.0537 - accuracy: 0.9846 - val_loss: 0.4545 - val_accuracy: 0.9014\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91120\n",
            "Epoch 12/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.0523 - accuracy: 0.9847 - val_loss: 0.4780 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91120\n",
            "Epoch 13/40\n",
            "1656/1656 [==============================] - 747s 451ms/step - loss: 0.0467 - accuracy: 0.9865 - val_loss: 0.3880 - val_accuracy: 0.9056\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91120\n",
            "Epoch 14/40\n",
            "1656/1656 [==============================] - 753s 454ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.4310 - val_accuracy: 0.9067\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91120\n",
            "Epoch 15/40\n",
            "1656/1656 [==============================] - 752s 454ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.4911 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91120 to 0.92724, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 16/40\n",
            "1656/1656 [==============================] - 757s 457ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.6710 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92724\n",
            "Epoch 17/40\n",
            "1656/1656 [==============================] - 753s 455ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.6668 - val_accuracy: 0.9077\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92724\n",
            "Epoch 18/40\n",
            "1656/1656 [==============================] - 752s 454ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2587 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92724 to 0.93726, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E.hdf5\n",
            "Epoch 19/40\n",
            "1656/1656 [==============================] - 755s 456ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.5317 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.93726\n",
            "Epoch 20/40\n",
            "1656/1656 [==============================] - 752s 454ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.4541 - val_accuracy: 0.9186\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.93726\n",
            "Epoch 21/40\n",
            "1656/1656 [==============================] - 760s 459ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.7600 - val_accuracy: 0.8826\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.93726\n",
            "Epoch 22/40\n",
            "1656/1656 [==============================] - 751s 454ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.5980 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.93726\n",
            "Epoch 23/40\n",
            "1656/1656 [==============================] - 752s 454ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.4067 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.93726\n",
            "Epoch 24/40\n",
            "1656/1656 [==============================] - 750s 453ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.5460 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.93726\n",
            "Epoch 25/40\n",
            "1656/1656 [==============================] - 751s 454ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.2478 - val_accuracy: 0.9323\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.93726\n",
            "Epoch 26/40\n",
            "1656/1656 [==============================] - 758s 458ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.5113 - val_accuracy: 0.8945\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.93726\n",
            "Epoch 27/40\n",
            "1656/1656 [==============================] - 760s 459ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.5700 - val_accuracy: 0.9060\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.93726\n",
            "Epoch 28/40\n",
            "1656/1656 [==============================] - 760s 459ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.3155 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.93726\n",
            "Epoch 29/40\n",
            "1656/1656 [==============================] - 758s 457ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.4110 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.93726\n",
            "Epoch 30/40\n",
            "1656/1656 [==============================] - 761s 459ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.4965 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.93726\n",
            "Epoch 31/40\n",
            "1656/1656 [==============================] - 758s 458ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.3687 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.93726\n",
            "Epoch 32/40\n",
            "1656/1656 [==============================] - 756s 456ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.4591 - val_accuracy: 0.9182\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93726\n",
            "Epoch 33/40\n",
            "1656/1656 [==============================] - 761s 459ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.4227 - val_accuracy: 0.9070\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.93726\n",
            "Epoch 34/40\n",
            "1656/1656 [==============================] - 759s 458ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.4784 - val_accuracy: 0.9139\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93726\n",
            "Epoch 35/40\n",
            "1656/1656 [==============================] - 762s 460ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.8911 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93726\n",
            "Epoch 36/40\n",
            "1656/1656 [==============================] - 764s 461ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.8900 - val_accuracy: 0.8630\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.93726\n",
            "Epoch 37/40\n",
            "1656/1656 [==============================] - 761s 460ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.6335 - val_accuracy: 0.8948\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93726\n",
            "Epoch 38/40\n",
            "1656/1656 [==============================] - 764s 461ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.5662 - val_accuracy: 0.9182\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93726\n",
            "Epoch 39/40\n",
            "1656/1656 [==============================] - 762s 460ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.5691 - val_accuracy: 0.9136\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93726\n",
            "Epoch 40/40\n",
            "1656/1656 [==============================] - 763s 461ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.3708 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlM9FVDqtPy"
      },
      "source": [
        "ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbbwOFVGwVvM"
      },
      "source": [
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.load_weights(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '9_Surrey_InceptionV3_E.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tH7k4tzeqtPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94383d7-e80b-4bac-a1a5-2e29677e8dfa"
      },
      "source": [
        "\n",
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '9_Surrey_InceptionV3_E_L2.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "epochs = 15##!!!\n",
        "lr = 1e-4\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1656/1656 [==============================] - 1320s 776ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.2020 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.95228, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E_L2.hdf5\n",
            "Epoch 2/15\n",
            "1656/1656 [==============================] - 1283s 775ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.3677 - val_accuracy: 0.9269\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.95228\n",
            "Epoch 3/15\n",
            "1656/1656 [==============================] - 1280s 773ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.2436 - val_accuracy: 0.9425\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.95228\n",
            "Epoch 4/15\n",
            "1656/1656 [==============================] - 1278s 772ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.2977 - val_accuracy: 0.9334\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.95228\n",
            "Epoch 5/15\n",
            "1656/1656 [==============================] - 1278s 772ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2495 - val_accuracy: 0.9370\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.95228\n",
            "Epoch 6/15\n",
            "1656/1656 [==============================] - 1277s 771ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.3088 - val_accuracy: 0.9296\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.95228\n",
            "Epoch 7/15\n",
            "1656/1656 [==============================] - 1278s 771ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.4767 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.95228\n",
            "Epoch 8/15\n",
            "1656/1656 [==============================] - 1278s 771ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.3397 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.95228\n",
            "Epoch 9/15\n",
            "1656/1656 [==============================] - 1282s 774ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.3557 - val_accuracy: 0.9375\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.95228\n",
            "Epoch 10/15\n",
            "1656/1656 [==============================] - 1286s 776ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.3711 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.95228\n",
            "Epoch 11/15\n",
            "1656/1656 [==============================] - 1289s 778ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.3810 - val_accuracy: 0.9280\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.95228\n",
            "Epoch 12/15\n",
            "1656/1656 [==============================] - 1290s 779ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.4221 - val_accuracy: 0.9280\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.95228\n",
            "Epoch 13/15\n",
            "1656/1656 [==============================] - 1289s 778ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.3577 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.95228\n",
            "Epoch 14/15\n",
            "1656/1656 [==============================] - 1279s 772ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.4201 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.95228\n",
            "Epoch 15/15\n",
            "1656/1656 [==============================] - 1281s 774ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.3353 - val_accuracy: 0.9419\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.95228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7gHbA9f_iRK"
      },
      "source": [
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.load_weights(os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '9_Surrey_InceptionV3_E_L2.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtpZyKMykDJA",
        "outputId": "ab0deeb1-27c7-41d1-c37f-790d7f1a7744"
      },
      "source": [
        "# Helper: Save the model.\n",
        "savedfilename = os.path.join('gdrive', 'My Drive', 'Surrey_ASL', '9_Surrey_InceptionV3_E_L3.hdf5')\n",
        "\n",
        "checkpointer = ModelCheckpoint(savedfilename,\n",
        "                          monitor='val_accuracy', verbose=1, \n",
        "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
        "\n",
        "epochs = 15##!!!\n",
        "lr = 1e-5\n",
        "decay = lr/epochs\n",
        "optimizer = Adam(lr=lr, decay=decay)\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "result = model_mul.fit_generator(\n",
        "    generator = train_set, \n",
        "    steps_per_epoch = step_size_train,\n",
        "    validation_data = valid_set,\n",
        "    validation_steps = step_size_valid,\n",
        "    shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[checkpointer],\n",
        "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
        "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
        "    verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1656/1656 [==============================] - 1316s 776ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.2315 - val_accuracy: 0.9466\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94657, saving model to gdrive/My Drive/Surrey_ASL/9_Surrey_InceptionV3_E_L3.hdf5\n",
            "Epoch 2/15\n",
            "1656/1656 [==============================] - 1280s 772ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.2392 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.94657\n",
            "Epoch 3/15\n",
            "1656/1656 [==============================] - 1288s 777ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.2420 - val_accuracy: 0.9454\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.94657\n",
            "Epoch 4/15\n",
            "1656/1656 [==============================] - 1287s 777ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.2558 - val_accuracy: 0.9427\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.94657\n",
            "Epoch 5/15\n",
            "1656/1656 [==============================] - 1286s 776ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.2474 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.94657\n",
            "Epoch 6/15\n",
            "1656/1656 [==============================] - 1284s 775ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.2511 - val_accuracy: 0.9441\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.94657\n",
            "Epoch 7/15\n",
            "1656/1656 [==============================] - 1283s 775ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.2451 - val_accuracy: 0.9451\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.94657\n",
            "Epoch 8/15\n",
            "1656/1656 [==============================] - 1283s 775ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.2554 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.94657\n",
            "Epoch 9/15\n",
            "1656/1656 [==============================] - 1282s 774ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.2638 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.94657\n",
            "Epoch 10/15\n",
            "1656/1656 [==============================] - 1282s 774ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.2694 - val_accuracy: 0.9411\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.94657\n",
            "Epoch 11/15\n",
            "1468/1656 [=========================>....] - ETA: 2:16 - loss: 0.0079 - accuracy: 0.9976"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZY19H9TkLKZ"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255)\n",
        "\n",
        "testing_set = test_datagen.flow_from_directory('dataset5/test_color/',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 seed=7,\n",
        "                                                 shuffle=False\n",
        "#                                                  subset=\"validation\"\n",
        "                                             )\n",
        "\n",
        "y_pred = model.predict_generator(testing_set,steps = testing_set.n//testing_set.batch_size)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_true = testing_set.classes\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# print(model.evaluate_generator(testing_set,\n",
        "#                                steps = testing_set.n//testing_set.batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as5-kZJZeOYi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGCKo7UImjLo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xMLFBZEK4Rt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DBewr1xLpKq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le4SgbXkK7Fd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkv4WXdmLOZG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do2PnIyXfwgc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxkumxw1YGNy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYe5AaVp9OH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP-OnVj5LSDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf9FmkAVHkf0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juICyuElcBb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Qvh9qdXCbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7xkHd_ehyXa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLnd3hib_Eu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-T2S3-ixzqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4JkwCKkvkFW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}