{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddS2ZoUzyFKK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9943441039808454111\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10778352778388286654\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3469758049656496457\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1469088473516666726\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1159377961293133002\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9655712524109053367\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15822884736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 15694099026197562166\n",
      "physical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:3d:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15822884736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4293649571853685516\n",
      "physical_device_desc: \"device: 1, name: Quadro P5000, pci bus id: 0000:3e:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15822884736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 7617049644390461549\n",
      "physical_device_desc: \"device: 2, name: Quadro P5000, pci bus id: 0000:3f:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15822884736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 17980831043475030115\n",
      "physical_device_desc: \"device: 3, name: Quadro P5000, pci bus id: 0000:40:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /media/datastorage/Phong/svhn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir svhn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9hjOmqPK9VFh",
    "outputId": "0fe03253-0045-485f-d511-498f833b6383"
   },
   "outputs": [],
   "source": [
    "!wget http://ufldl.stanford.edu/housenumbers/extra_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDfVRAPW9mD1"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "X-7jWS6Pzk6h",
    "outputId": "3cfa1a8c-9f2b-48cb-b47b-3cb02bc78246"
   },
   "outputs": [],
   "source": [
    "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnWpgWtR1sF0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "def convert_img_square(im_pth='', dest_path='', desired_size=224):\n",
    "#     print(im_pth)\n",
    "    \n",
    "    im = Image.open(im_pth)\n",
    "    old_size = im.size  # (width, height) format\n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "#     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "    new_im = im.resize(new_size)\n",
    "    \n",
    "    new_im = new_im.convert('RGB')\n",
    "    \n",
    "    new_im.save(dest_path)\n",
    "\n",
    "    return True\n",
    "    \n",
    "# path = 'train/0/twinjet_s_001442.png'\n",
    "# dest_path = 't1/test4.jpg'\n",
    "\n",
    "# orig_arr = convert_img_square(path, dest_path, 499)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# # orig_arr = orig_arr.convert('RGB')\n",
    "# # orig_arr.save('t1/test2.jpg')\n",
    "\n",
    "# from IPython.display import Image \n",
    "# Image(filename='t1/test4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hmmIZ9jbjff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrFKG9Sgbs8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvVh5O9kbnUt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igXkdJTE1v5-"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtF1nCmV1zw9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_svhn():\n",
    "    dir_name = \"./svhn_train\"\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    print(\"Loading matlab train of SVHN\")\n",
    "    mat = sio.loadmat(\"train_32x32.mat\")\n",
    "    data = mat['X']\n",
    "    folders = mat['y']\n",
    "    \n",
    "    for i in range(data.shape[3]):\n",
    "        if not os.path.isfile(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i)):  \n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(os.path.join(dir_name, str(folders[i][0]))):\n",
    "                os.makedirs(os.path.join(dir_name, str(folders[i][0])))\n",
    "\n",
    "            plt.imsave(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i), data[..., i])\n",
    "            \n",
    "    print(\"Program done!\")\n",
    "\n",
    "save_svhn()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wCI0358H14H8",
    "outputId": "b468ab4c-48c3-49d5-b900-0ad1626aec62"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_svhn():\n",
    "    dir_name = \"./svhn_extra\"\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    print(\"Loading matlab data of SVHN\")\n",
    "    mat = sio.loadmat(\"extra_32x32.mat\")\n",
    "    data = mat['X']\n",
    "    folders = mat['y']\n",
    "    \n",
    "    for i in range(data.shape[3]):\n",
    "        if not os.path.isfile(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i)):  \n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(os.path.join(dir_name, str(folders[i][0]))):\n",
    "                os.makedirs(os.path.join(dir_name, str(folders[i][0])))\n",
    "\n",
    "            plt.imsave(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i), data[..., i])\n",
    "            \n",
    "    print(\"Program done!\")\n",
    "\n",
    "save_svhn()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gpN67dZ76EfW",
    "outputId": "6c8555fd-2658-48f9-ebdd-f8d0fc379921"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_svhn_test():\n",
    "    dir_name = \"./svhn_test\"\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    print(\"Loading matlab data of SVHN\")\n",
    "    mat = sio.loadmat(\"test_32x32.mat\")\n",
    "    data = mat['X']\n",
    "    folders = mat['y']\n",
    "    \n",
    "    for i in range(data.shape[3]):\n",
    "        if not os.path.isfile(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i)):  \n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(os.path.join(dir_name, str(folders[i][0]))):\n",
    "                os.makedirs(os.path.join(dir_name, str(folders[i][0])))\n",
    "\n",
    "            plt.imsave(os.path.join(dir_name, str(folders[i][0]), \"%05d.png\" % i), data[..., i])\n",
    "            \n",
    "    print(\"done!\")\n",
    "\n",
    "save_svhn_test()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "505yv8PKCFSF"
   },
   "outputs": [],
   "source": [
    "####=======================\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "#move class folder from classname_# to classname/#\n",
    "\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "move_folders = ['svhn_train']\n",
    "dest_folder = 'train_resized_299'\n",
    "data_file = []\n",
    "\n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "    print('folder %s' %class_folders)\n",
    "    \n",
    "#     for sub_folder in class_folders:\n",
    "#         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "#         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        print(iid_class)\n",
    "        \n",
    "        class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "#         #Determize Set# (No Suffle)\n",
    "        set = len(class_files)\n",
    "        inner = range(0*set, 1*set) #all\n",
    "\n",
    "        print('moving %d files' %(len(inner)))\n",
    "\n",
    "#         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "#         for idx in range(len(random_list)):\n",
    "\n",
    "        for idx in range(len(inner)):\n",
    "            src = class_files[inner[idx]]\n",
    "\n",
    "            train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "            dst = os.path.join(dest_folder, classname, 'train_'+filename)\n",
    "\n",
    "            # image directory\n",
    "            img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "                \n",
    "            # convert image\n",
    "            convert_img_square(src, dst, 299)\n",
    "            #moving file\n",
    "            # shutil.move(src, dst)\n",
    "#                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPB1Rz3a_SUw"
   },
   "outputs": [],
   "source": [
    "####=======================\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "#move class folder from classname_# to classname/#\n",
    "\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "move_folders = ['svhn_extra']\n",
    "dest_folder = 'train_resized_299'\n",
    "data_file = []\n",
    "\n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "    print('folder %s' %class_folders)\n",
    "    \n",
    "#     for sub_folder in class_folders:\n",
    "#         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "#         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        print(iid_class)\n",
    "        \n",
    "        class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "#         #Determize Set# (No Suffle)\n",
    "        set = len(class_files)\n",
    "        inner = range(0*set, 1*set) #all\n",
    "\n",
    "        print('moving %d files' %(len(inner)))\n",
    "\n",
    "#         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "#         for idx in range(len(random_list)):\n",
    "\n",
    "        for idx in range(len(inner)):\n",
    "            src = class_files[inner[idx]]\n",
    "\n",
    "            train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "            dst = os.path.join(dest_folder, classname, 'extra_'+filename)\n",
    "\n",
    "            # image directory\n",
    "            img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "                \n",
    "            # convert image\n",
    "            convert_img_square(src, dst, 299)\n",
    "            #moving file\n",
    "            # shutil.move(src, dst)\n",
    "#                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWIq2AAg-Rjh"
   },
   "outputs": [],
   "source": [
    "####=======================\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "#move class folder from classname_# to classname/#\n",
    "\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "move_folders = ['svhn_test']\n",
    "dest_folder = 'test_resized_299'\n",
    "data_file = []\n",
    "\n",
    "# look for all images in sub-folders\n",
    "for folder in move_folders:\n",
    "    class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "    print('folder %s' %class_folders)\n",
    "    \n",
    "#     for sub_folder in class_folders:\n",
    "#         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "#         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "    for iid_class in class_folders:\n",
    "        print(iid_class)\n",
    "        \n",
    "        class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "#         #Determize Set# (No Suffle)\n",
    "        set = len(class_files)\n",
    "        inner = range(0*set, 1*set) #all\n",
    "\n",
    "        print('moving %d files' %(len(inner)))\n",
    "\n",
    "#         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "#         for idx in range(len(random_list)):\n",
    "\n",
    "        for idx in range(len(inner)):\n",
    "            src = class_files[inner[idx]]\n",
    "\n",
    "            train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "            dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "            # image directory\n",
    "            img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "            # create folder if not existed\n",
    "            if not os.path.exists(img_directory):\n",
    "                os.makedirs(img_directory)\n",
    "                \n",
    "            # convert image\n",
    "            convert_img_square(src, dst, 299)\n",
    "            #moving file\n",
    "            # shutil.move(src, dst)\n",
    "#                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2MwT1Dh-WUG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gv37mrDqCL8h"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sg09eH64C-kO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIlCeOsECoDf"
   },
   "outputs": [],
   "source": [
    "!zip -r svhn_train_resized_229.zip svhn_train_resized_229\n",
    "!zip -r svhn_test_resized_229.zip svhn_test_resized_229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_0aMFCoCrnD"
   },
   "outputs": [],
   "source": [
    "# %cp svhn_train_resized_229.zip gdrive/My\\ Drive/svhn_train_resized_229.zip\n",
    "# %cp svhn_test_resized_229.zip gdrive/My\\ Drive/svhn_test_resized_229.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVeqXfhNMzQx"
   },
   "outputs": [],
   "source": [
    "%cp gdrive/My\\ Drive/svhn_train.zip svhn_train_32.zip \n",
    "%cp gdrive/My\\ Drive/svhn_test.zip svhn_test_32.zip  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g2b9RNYM7XO"
   },
   "outputs": [],
   "source": [
    "!unzip -q svhn_train_32.zip\n",
    "!unzip -q svhn_test_32.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "SU2cgVh2jjks",
    "outputId": "da972a51-a4ea-4cd6-e463-7949784eb206"
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MUL 1 - Inception - ST\n",
    "\n",
    "# # from keras.applications import InceptionV3\n",
    "# # from keras.applications import Xception\n",
    "# # from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from tensorflow.keras.applications import EfficientNetB1\n",
    "\n",
    "# from keras.models import Model\n",
    "# # from keras.layers import concatenate\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "# # from keras.applications.inception_v3 import preprocess_input\n",
    "# from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "# # from efficientnet.keras import preprocess_input\n",
    "\n",
    "# from keras.layers import GaussianNoise\n",
    "\n",
    "# f1_base = EfficientNetB1(include_top=False, weights='imagenet', \n",
    "#                 input_shape=(299, 299, 3), \n",
    "#                 pooling='avg')\n",
    "\n",
    "# # import efficientnet.keras as efn\n",
    "# # f1_base = efn.EfficientNetB1(include_top=False, weights='imagenet', \n",
    "# #                 input_shape=(299, 299, 3), \n",
    "# #                 pooling='avg')\n",
    "\n",
    "# # f1_base = Xception(weights='imagenet', include_top=False, input_shape=(450,450,3))\n",
    "\n",
    "# f1_x = f1_base.output\n",
    "\n",
    "# # f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# # f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# # f1_x = Flatten()(f1_x)\n",
    "\n",
    "# # f1_x = Reshape([1,1280])(f1_x)  \n",
    "# # f1_x = SimpleRNN(2048, \n",
    "# #             return_sequences=False,                       \n",
    "# # #             dropout=0.8                                     \n",
    "# #             input_shape=[1,1280])(f1_x)\n",
    "\n",
    "# #Regularization with noise\n",
    "# f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "# f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "# f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "# model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, SimpleRNN, LSTM, Flatten, GRU, Reshape\n",
    "\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "def get_adv_model():\n",
    "    f1_base = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "                    input_shape=(299, 299, 3), \n",
    "                    pooling='avg')\n",
    "    # f1_base = Xception(weights='imagenet', include_top=False, input_shape=(450,450,3))\n",
    "\n",
    "    f1_x = f1_base.output\n",
    "\n",
    "# f1_x = f1_base.layers[-151].output   #layer 5\n",
    "\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1280])(f1_x)  \n",
    "# f1_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1280])(f1_x)\n",
    "   \n",
    "    #Regularization with noise\n",
    "    f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "    f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "    f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "    model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "    model_1.summary()\n",
    "    \n",
    "    return model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZIRj8Ae2jne1",
    "outputId": "779932d7-7398-4d4f-effa-5ef345499243"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYlOSabnEy1p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxB7_So2E3Eu"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkmOYEZU0Db3"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "\n",
    "def get_cutout_v2(p=0.5, n_holes=2, length=20):\n",
    "    def cutout(np_img):\n",
    "        # print(type(image))\n",
    "        # h = img.size(1)\n",
    "        # w = img.size(2)\n",
    "        img = Image.fromarray(((np_img)).astype(np.uint8))\n",
    "\n",
    "        w, h = img.size\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        \n",
    "        length = np.random.randint(low=w//16, high=w//4) #w=h\n",
    "\n",
    "        for n in range(n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - length // 2, 0, h)\n",
    "            y2 = np.clip(y + length // 2, 0, h)\n",
    "            x1 = np.clip(x - length // 2, 0, w)\n",
    "            x2 = np.clip(x + length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        # mask = torch.from_numpy(mask)\n",
    "\n",
    "        # ary = np.random.normal(size=(2, 2))\n",
    "        # mask = K.cast(mask, dtype='float32')\n",
    "\n",
    "        # mask = mask.expand_as(img)\n",
    "\n",
    "        mask = np.expand_dims(mask, axis=2)\n",
    "\n",
    "        re_img = img * mask\n",
    "\n",
    "        return preprocess_input(re_img)\n",
    "        # return re_img\n",
    "\n",
    "    return cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHW7L6CEaO5s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IO8JJRbeFEgK"
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir svhn_output\n",
    "%mkdir svhn_output/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "fQREEQLxE5qu",
    "outputId": "751beac8-6384-4318-f387-88fb1690e633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of GPUs: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 299, 299, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 301, 301, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 151, 151, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 75, 75, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 79, 79, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 38, 38, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 39, 39, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 19, 19, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 19, 19, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 19, 19, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 19, 19, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 23, 23, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 672)  16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 672)  2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 672)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 672)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 192)  129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 192)  768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1152) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1152) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 192)  768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 10, 10, 192)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 192)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1152) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1152) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 192)  768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 10, 10, 192)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 192)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1152) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1152) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 192)  768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 10, 10, 192)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 192)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1152) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1152) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1152) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 320)  368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 320)  1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 1280) 409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 1280) 5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 1280) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1311744     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 5,371,565\n",
      "Trainable params: 5,329,542\n",
      "Non-trainable params: 42,023\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-3-038de9f06f39>:102: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 215 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 215 all-reduces with algorithm = nccl, num_packs = 1\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9492 \n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97077, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 32765s 10s/step - loss: 0.1688 - accuracy: 0.9492 - val_loss: 0.1179 - val_accuracy: 0.9708\n",
      "Epoch 2/20\n",
      " 441/3148 [===>..........................] - ETA: 7:56:23 - loss: 0.1129 - accuracy: 0.9683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9714 \n",
      "Epoch 00002: val_accuracy improved from 0.97077 to 0.97303, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 32225s 10s/step - loss: 0.1013 - accuracy: 0.9714 - val_loss: 0.1079 - val_accuracy: 0.9730\n",
      "Epoch 3/20\n",
      "3128/3148 [============================>.] - ETA: 3:23 - loss: 0.0865 - accuracy: 0.9760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9792\n",
      "Epoch 00004: val_accuracy did not improve from 0.98018\n",
      "3148/3148 [==============================] - 30187s 10s/step - loss: 0.0763 - accuracy: 0.9792 - val_loss: 0.0885 - val_accuracy: 0.9798\n",
      "Epoch 5/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9809\n",
      "Epoch 00005: val_accuracy did not improve from 0.98018\n",
      "3148/3148 [==============================] - 28152s 9s/step - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.0895 - val_accuracy: 0.9785\n",
      "Epoch 6/20\n",
      "2275/3148 [====================>.........] - ETA: 2:06:00 - loss: 0.0661 - accuracy: 0.9819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9834\n",
      "Epoch 00007: val_accuracy improved from 0.98110 to 0.98283, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 26984s 9s/step - loss: 0.0618 - accuracy: 0.9834 - val_loss: 0.0759 - val_accuracy: 0.9828\n",
      "Epoch 8/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9843\n",
      "Epoch 00008: val_accuracy improved from 0.98283 to 0.98321, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 26887s 9s/step - loss: 0.0583 - accuracy: 0.9843 - val_loss: 0.0756 - val_accuracy: 0.9832\n",
      "Epoch 9/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9852\n",
      "Epoch 00009: val_accuracy improved from 0.98321 to 0.98425, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 27316s 9s/step - loss: 0.0555 - accuracy: 0.9852 - val_loss: 0.0726 - val_accuracy: 0.9843\n",
      "Epoch 10/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9859\n",
      "Epoch 00010: val_accuracy did not improve from 0.98425\n",
      "3148/3148 [==============================] - 27525s 9s/step - loss: 0.0535 - accuracy: 0.9859 - val_loss: 0.0807 - val_accuracy: 0.9825\n",
      "Epoch 11/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9865\n",
      "Epoch 00011: val_accuracy improved from 0.98425 to 0.98440, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 27573s 9s/step - loss: 0.0509 - accuracy: 0.9865 - val_loss: 0.0691 - val_accuracy: 0.9844\n",
      "Epoch 12/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9869\n",
      "Epoch 00012: val_accuracy improved from 0.98440 to 0.98575, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 27644s 9s/step - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.0667 - val_accuracy: 0.9857\n",
      "Epoch 13/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9875\n",
      "Epoch 00013: val_accuracy did not improve from 0.98575\n",
      "3148/3148 [==============================] - 27475s 9s/step - loss: 0.0472 - accuracy: 0.9875 - val_loss: 0.0720 - val_accuracy: 0.9835\n",
      "Epoch 14/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9880\n",
      "Epoch 00014: val_accuracy did not improve from 0.98575\n",
      "3148/3148 [==============================] - 27978s 9s/step - loss: 0.0459 - accuracy: 0.9880 - val_loss: 0.0681 - val_accuracy: 0.9851\n",
      "Epoch 15/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9882\n",
      "Epoch 00015: val_accuracy improved from 0.98575 to 0.98579, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 27604s 9s/step - loss: 0.0448 - accuracy: 0.9882 - val_loss: 0.0655 - val_accuracy: 0.9858\n",
      "Epoch 16/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9888\n",
      "Epoch 00016: val_accuracy did not improve from 0.98579\n",
      "3148/3148 [==============================] - 27727s 9s/step - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.0704 - val_accuracy: 0.9855\n",
      "Epoch 17/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9890\n",
      "Epoch 00017: val_accuracy improved from 0.98579 to 0.98644, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2.hdf5\n",
      "3148/3148 [==============================] - 27304s 9s/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.0671 - val_accuracy: 0.9864\n",
      "Epoch 18/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9892\n",
      "Epoch 00018: val_accuracy did not improve from 0.98644\n",
      "3148/3148 [==============================] - 26895s 9s/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0681 - val_accuracy: 0.9861\n",
      "Epoch 19/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9897\n",
      "Epoch 00019: val_accuracy did not improve from 0.98644\n",
      "3148/3148 [==============================] - 26907s 9s/step - loss: 0.0386 - accuracy: 0.9897 - val_loss: 0.0764 - val_accuracy: 0.9834\n",
      "Epoch 20/20\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 00020: val_accuracy did not improve from 0.98644\n",
      "3148/3148 [==============================] - 27050s 9s/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 0.0683 - val_accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# NUM_GPU = 4\n",
    "batch_size = 192\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_EffB0_299_v2_upgraded_r2.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of GPUs: 4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 299, 299, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 301, 301, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 32) 864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 151, 151, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 75, 75, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 79, 79, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 38, 38, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 39, 39, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 19, 19, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 19, 19, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 19, 19, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 19, 19, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 23, 23, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 672)  16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 672)  2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 672)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 672)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 192)  129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 192)  768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1152) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1152) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 192)  768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 10, 10, 192)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 192)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1152) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1152) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 192)  768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 10, 10, 192)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 192)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1152) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1152) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 192)  768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 10, 10, 192)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 192)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1152) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1152) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1152) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 320)  368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 320)  1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 1280) 409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 1280) 5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 1280) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1311744     gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 5,371,565\n",
      "Trainable params: 5,329,542\n",
      "Non-trainable params: 42,023\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    # preprocessing_function=get_cutout_v2(),\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# NUM_GPU = 4\n",
    "batch_size = 192\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_EffB0_299_v2_upgraded_r2_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_accuracy', value=0.9900, verbose=1)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# train on multiple-gpus\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of GPUs: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model_mul = get_adv_model()\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1JwAn1jKFZV6",
    "outputId": "e047b4e6-fdc2-491f-aadd-f5aa72fa6f7a"
   },
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('checkpoints', 'SVHN_EffB0_299_v2_upgraded_r2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qyBzNzsdahbe",
    "outputId": "4676c11c-6355-47c8-c044-4817adfa66af",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-aae97670cde1>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 215 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 215 all-reduces with algorithm = nccl, num_packs = 1\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9905\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98736, saving model to checkpoints/SVHN_EffB0_299_v2_upgraded_r2_L2.hdf5\n",
      "3148/3148 [==============================] - 26529s 8s/step - loss: 0.0361 - accuracy: 0.9905 - val_loss: 0.0644 - val_accuracy: 0.9874\n",
      "Epoch 2/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9911 \n",
      "Epoch 00002: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 35807s 11s/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 0.0654 - val_accuracy: 0.9872\n",
      "Epoch 3/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9913 \n",
      "Epoch 00003: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 38316s 12s/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.0663 - val_accuracy: 0.9868\n",
      "Epoch 4/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9916 \n",
      "Epoch 00004: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 37970s 12s/step - loss: 0.0319 - accuracy: 0.9916 - val_loss: 0.0688 - val_accuracy: 0.9868\n",
      "Epoch 5/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9915 \n",
      "Epoch 00005: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 36893s 12s/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 0.0687 - val_accuracy: 0.9868\n",
      "Epoch 6/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9919 \n",
      "Epoch 00006: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 35080s 11s/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.0734 - val_accuracy: 0.9854\n",
      "Epoch 7/15\n",
      " 307/3148 [=>............................] - ETA: 6:51:20 - loss: 0.0300 - accuracy: 0.9919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9920\n",
      "Epoch 00007: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 27568s 9s/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0759 - val_accuracy: 0.9862\n",
      "Epoch 8/15\n",
      "1720/3148 [===============>..............] - ETA: 3:23:46 - loss: 0.0294 - accuracy: 0.9922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9923\n",
      "Epoch 00009: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 27177s 9s/step - loss: 0.0287 - accuracy: 0.9923 - val_loss: 0.0780 - val_accuracy: 0.9857\n",
      "Epoch 10/15\n",
      " 374/3148 [==>...........................] - ETA: 6:42:13 - loss: 0.0306 - accuracy: 0.9916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9924\n",
      "Epoch 00010: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 27115s 9s/step - loss: 0.0284 - accuracy: 0.9924 - val_loss: 0.0800 - val_accuracy: 0.9848\n",
      "Epoch 11/15\n",
      "3148/3148 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9925\n",
      "Epoch 00011: val_accuracy did not improve from 0.98736\n",
      "3148/3148 [==============================] - 27206s 9s/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.0821 - val_accuracy: 0.9851\n",
      "Epoch 12/15\n",
      "1225/3148 [==========>...................] - ETA: 4:33:18 - loss: 0.0273 - accuracy: 0.9925"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aae97670cde1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     callbacks=[csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     verbose=1) \n\u001b[0m",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_EffB0_299_v2_upgraded_r2_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_accuracy', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpointer],\n",
    "#     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9864397644996643, 0.9707667231559753)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result.history['val_accuracy']),min(result.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = result\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = result\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy l2')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BDQffVPvamBk",
    "outputId": "80fd2662-2141-46e5-8dbb-abc1d6bcaaa5"
   },
   "outputs": [],
   "source": [
    "# model_mul.load_weights(os.path.join('checkpoints', 'SVHN_EffB1_299_v2_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Non-Groups\n",
    "# #Split training and validation\n",
    "# #Using Expert Data\n",
    "\n",
    "# savedfilename = os.path.join('checkpoints', 'SVHN_EffB1_299_v2_L3.hdf5')\n",
    "# checkpointer = ModelCheckpoint(savedfilename,\n",
    "#                           monitor='val_acc', verbose=1, \n",
    "#                           save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# epochs = 15##!!!\n",
    "# lr = 1e-4\n",
    "# decay = lr/epochs\n",
    "# optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[checkpointer],\n",
    "# #     callbacks=[csv_logger, checkpointer, earlystopping],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    model_mul.load_weights(os.path.join('checkpoints', 'SVHN_EffB0_299_v2_upgraded_r2_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From <ipython-input-9-fe2130becefe>:48: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "724/724 [==============================] - 216s 298ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/00002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/00007.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/00008.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/00013.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name predicted1\n",
       "0  1/00002.png          1\n",
       "1  1/00005.png          1\n",
       "2  1/00007.png          1\n",
       "3  1/00008.png          1\n",
       "4  1/00013.png          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "# if NUM_GPU != 1:\n",
    "predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('SVHN_EffB0_299_v2_upgraded_r2_L2_1511.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','SVHN_EffB0_299_v2_upgraded_r2_L2_1511.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp SVHN_EffB1_299_v2_upgraded_1910.csv /home/bribeiro/Phong/Nat19/SVHN_EffB1_299_v2_upgraded_1910.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import time, os\n",
    "# from math import ceil\n",
    "\n",
    "# # PREDICT ON OFFICIAL TEST\n",
    "# train_datagen = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     shear_range=0.3,\n",
    "#     zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "# #     brightness_range=[0.5, 1.5],##\n",
    "#     channel_shift_range=10,##\n",
    "#     fill_mode='nearest',\n",
    "#     preprocessing_function=preprocess_input,\n",
    "# )\n",
    "\n",
    "# test_datagen1 = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "#     preprocessing_function=preprocess_input\n",
    "# )\n",
    "\n",
    "# batch_size = 36\n",
    "\n",
    "# train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "#                                                  target_size = (299, 299),\n",
    "#                                                  batch_size = batch_size,\n",
    "#                                                  class_mode = 'categorical',\n",
    "#                                                  shuffle=True,\n",
    "#                                                  seed=7,\n",
    "# #                                                  subset=\"training\"\n",
    "#                                               )\n",
    "\n",
    "# test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "#                                                  target_size = (299, 299),\n",
    "#                                                  batch_size = batch_size,\n",
    "#                                                  class_mode = 'categorical',\n",
    "#                                                  shuffle=False,\n",
    "#                                                  seed=7,\n",
    "# #                                                  subset=\"validation\"\n",
    "#                                              )\n",
    "\n",
    "# # if NUM_GPU != 1:\n",
    "# predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# # else:\n",
    "# #     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "# predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "# labels = (train_set.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# filenames=test_set1.filenames\n",
    "# results=pd.DataFrame({\"file_name\":filenames,\n",
    "#                       \"predicted1\":predictions1,\n",
    "#                       })\n",
    "# results.to_csv('SVHN_Eff_B4_299_v2_L3_2109.csv')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(os.path.join('pred_npy','SVHN_EffB4_299_v2_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp SVHN_Eff_B4_299_v2_2009.csv /home/bribeiro/Phong/Nat19/SVHN_Eff_B4_299_v2_2009.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/phohenecker/switch-cuda.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVHN_Extra_EfficientNetB7_Crop5_STD_T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
