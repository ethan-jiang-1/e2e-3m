{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10890925857787718776\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16069084631113094040\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2670914422904927305\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4775689347252003777\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9990058568676356461\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16102781748\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 9124341658491191407\n",
      "physical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:3d:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16102781748\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 12183085543115403339\n",
      "physical_device_desc: \"device: 1, name: Quadro P5000, pci bus id: 0000:3e:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16102781748\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 8884282131502077320\n",
      "physical_device_desc: \"device: 2, name: Quadro P5000, pci bus id: 0000:3f:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get image parts\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "np.random.seed(42)\n",
    "rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "for i, rand_img in enumerate(rand_imgs):\n",
    "    train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "    j = i // 5\n",
    "    k = i % 5\n",
    "    axarr[j][k].imshow(imread(rand_img))\n",
    "    axarr[j][k].title.set_text(classname)\n",
    "    axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy\n",
    "\n",
    "# def convert_img_square(im_pth='', dest_path='', desired_size=224):\n",
    "# #     print(im_pth)\n",
    "    \n",
    "#     im = Image.open(im_pth)\n",
    "#     old_size = im.size  # (width, height) format\n",
    "\n",
    "#     ratio = float(desired_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "# #     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "#     new_im = im.resize(new_size)\n",
    "    \n",
    "#     new_im = new_im.convert('RGB')\n",
    "    \n",
    "#     new_im.save(dest_path)\n",
    "\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['fashion_mnist_train_resized_299']\n",
    "# dest_folder = 'fashion_mnist_train_resized_350'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 350)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['fashion_mnist_test_resized_299']\n",
    "# dest_folder = 'fashion_mnist_test_resized_350'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 299)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_gpu_model(model, gpus):\n",
    "    if isinstance(gpus, (list, tuple)):\n",
    "        num_gpus = len(gpus)\n",
    "        target_gpu_ids = gpus\n",
    "    else:\n",
    "        num_gpus = gpus\n",
    "        target_gpu_ids = range(num_gpus)\n",
    "\n",
    "    def get_slice(data, i, parts):\n",
    "        shape = tf.shape(data)\n",
    "        batch_size = shape[:1]\n",
    "        input_shape = shape[1:]\n",
    "        step = batch_size // parts\n",
    "        if i == num_gpus - 1:\n",
    "            size = batch_size - step * i\n",
    "        else:\n",
    "            size = step\n",
    "        size = tf.concat([size, input_shape], axis=0)\n",
    "        stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "        start = stride * i\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    all_outputs = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        all_outputs.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU,\n",
    "    # each getting a slice of the inputs.\n",
    "    for i, gpu_id in enumerate(target_gpu_ids):\n",
    "        with tf.device('/gpu:%d' % gpu_id):\n",
    "            with tf.name_scope('replica_%d' % gpu_id):\n",
    "                inputs = []\n",
    "                # Retrieve a slice of the input.\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_i = Lambda(get_slice,\n",
    "                                   output_shape=input_shape,\n",
    "                                   arguments={'i': i,\n",
    "                                              'parts': num_gpus})(x)\n",
    "                    inputs.append(slice_i)\n",
    "\n",
    "                # Apply model on slice\n",
    "                # (creating a model replica on the target device).\n",
    "                outputs = model(inputs)\n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "\n",
    "                # Save the outputs for merging back together later.\n",
    "                for o in range(len(outputs)):\n",
    "                    all_outputs[o].append(outputs[o])\n",
    "\n",
    "    # Merge outputs on CPU.\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for name, outputs in zip(model.output_names, all_outputs):\n",
    "            merged.append(concatenate(outputs,\n",
    "                                    axis=0, name=name))\n",
    "        return Model(model.inputs, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET 1\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f2_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f2_x = GlobalAveragePooling2D()(f2_base.output)\n",
    "\n",
    "#ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(1024, activation='relu')(f2_x)\n",
    "f2_x = Dense(100, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mv train_resized train_resized_299\n",
    "# %mv test_resized test_resized_299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 40\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change LR=1e-5\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L2.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('SeNet - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('SeNet - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L2.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change LR=1e-6\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras.backend as K\n",
    "\n",
    "# run_meta = tf.RunMetadata()\n",
    "# with tf.Session(graph=tf.Graph()) as sess:\n",
    "#     K.set_session(sess)\n",
    "#     net = senet(input_tensor=tf.placeholder('float32', shape=(1,421,421,3)))\n",
    "\n",
    "#     opts = tf.profiler.ProfileOptionBuilder.float_operation()    \n",
    "#     flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "#     opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
    "#     params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "#     print(\"{:,} --- {:,}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_SeResNet101_MulModels299_STD_2208_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_1511_v8.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_1511_v8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pred_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (320, 320),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 11\n",
    "predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save weights in pickle format instead of h5\n",
    "# import pickle\n",
    "\n",
    "# #use get_weights() command to get your model weights\n",
    "# weigh= model_2.get_weights()\n",
    "\n",
    "# #now, use pickle to save your model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG501_Mul_STD.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use pickle to load model weights\n",
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG299_Mul_LSTM_L3.pkl')\n",
    "\n",
    "# f= open(pklfile, 'rb')     #Python 3                 \n",
    "# weigh= pickle.load(f);                \n",
    "# f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 - SeResNext101\n",
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# load to multi gpu\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "#load model the saved weights\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#set the saved weight to mul-gpus model\n",
    "model_mul.set_weights(weigh)\n",
    "\n",
    "f2_sgl = model_mul.layers[-2]\n",
    "\n",
    "#get weight from single gpu\n",
    "weigh= f2_sgl.get_weights()\n",
    "\n",
    "#now, use pickle to save model weights, instead of .h5\n",
    "#for heavy model architectures, .h5 file is unsupported.\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3_SGL.pkl')\n",
    "\n",
    "fpkl= open(pklfile, 'wb') #Python 3\n",
    "pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2 - SEResNext101\n",
    "#load model the saved weights\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3_SGL.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#set the saved weight to mul-gpus model\n",
    "model_2.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load to multi gpu\n",
    "# NUM_GPU = 4\n",
    "# model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# #get weight from mul gpu\n",
    "# weigh= model_mul.get_weights()\n",
    "\n",
    "# #now, use pickle to save model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG299_Mul_LSTM_L3_SGL.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 1\n",
    "#MUL 1 - Xception\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Reshape, Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f1_base = Xception(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "f1_x = f1_base.output\n",
    "f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,2048])(f1_x)  \n",
    "# f1_x = Bidirectional(LSTM(1024, \n",
    "#                                  return_sequences=False, \n",
    "# #                                  dropout=0.8\n",
    "#                                 ),\n",
    "#                             input_shape=[1,2048],\n",
    "#                             merge_mode='concat')(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(2048, activation='relu')(f1_x)\n",
    "f1_x = Dense(100, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 100\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = result\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2_v2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import numpy as np\n",
    "\n",
    "print(result.history['val_acc'])\n",
    "print(np.mean(result.history['val_acc']))\n",
    "print(np.max(result.history['val_acc']))\n",
    "\n",
    "print(result.history['acc'])\n",
    "print(np.mean(result.history['acc']))\n",
    "print(np.max(result.history['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "NUM_GPU = 4\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2_v2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Xception_MulModels299_2408_01.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pred_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Xception_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 - Xception\n",
    "# load to multi gpu\n",
    "\n",
    "#use hdf5\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "hdf5file= os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L2.hdf5')\n",
    "model_mul.load_weights(hdf5file)\n",
    "\n",
    "f1_sgl = model_mul.layers[-2]\n",
    "f1_sgl.save(os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.load_weights(os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 35, 35, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 35, 35, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 35, 35, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 35, 35, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 35, 35, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 35, 35, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 384)  884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 384)  1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 160)  143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 160)  480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 160)  143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 160)  480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 128)  384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 160)  143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 160)  480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 128)  384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 160)  143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 160)  480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 160)  143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 160)  480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 128)  384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 160)  143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 160)  480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 160)  143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 160)  480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 160)  143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 160)  480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 192)  576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 128)  384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 160)  143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 160)  480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 17, 17, 128)  384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 160)  143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 17, 17, 160)  480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 17, 17, 128)  384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 160)  143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 17, 17, 160)  480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 192)  576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 17, 17, 128)  384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 160)  143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 17, 17, 160)  480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 192)  576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 160)  143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 160)  480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 160)  143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 160)  480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 192)  576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 128)  384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 160)  143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 128)  384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 160)  143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 128)  384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 160)  143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 160)  480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 192)  576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 128)  384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 160)  143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 128)  384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 160)  143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 192)  576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 128)  384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 160)  143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 160)  480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 160)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 192)  215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 256)  768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 17, 17, 288)  663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 17, 17, 256)  768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 17, 17, 256)  768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 17, 17, 288)  864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 17, 17, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 17, 17, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 8, 8, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 8, 8, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 8, 8, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 8, 8, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 8, 8, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 8, 8, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 8, 8, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 8, 8, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 8, 8, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 8, 8, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 8, 8, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 1536)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1573888     gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           10250       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 55,920,874\n",
      "Trainable params: 55,860,330\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#501\n",
    "#MUL 3 InceptionResNetV2\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f3_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "# for layer in f3_base.layers:\n",
    "#     layer.trainable = False \n",
    "f3_x = f3_base.output\n",
    "f3_x = GlobalAveragePooling2D()(f3_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f3_x = GaussianNoise(0.1)(f3_x)\n",
    "\n",
    "f3_x = Dense(1024, activation='relu')(f3_x)\n",
    "f3_x = Dense(10, activation='softmax')(f3_x)\n",
    "model_3 = Model(inputs=[f3_base.input],outputs=[f3_x])\n",
    "\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3022/3022 [==============================] - 13217s 4s/step - loss: 0.1909 - acc: 0.9429 - val_loss: 0.1870 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94883, saving model to checkpoints/SVHN_IcpResNetV2_LRG299.hdf5\n",
      "Epoch 2/20\n",
      "3022/3022 [==============================] - 12623s 4s/step - loss: 0.1103 - acc: 0.9687 - val_loss: 0.1204 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94883 to 0.96904, saving model to checkpoints/SVHN_IcpResNetV2_LRG299.hdf5\n",
      "Epoch 3/20\n",
      "3022/3022 [==============================] - 12576s 4s/step - loss: 0.0925 - acc: 0.9739 - val_loss: 0.0890 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.96904 to 0.97895, saving model to checkpoints/SVHN_IcpResNetV2_LRG299.hdf5\n",
      "Epoch 4/20\n",
      "3022/3022 [==============================] - 14191s 5s/step - loss: 0.0813 - acc: 0.9775 - val_loss: 0.1009 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97895\n",
      "Epoch 5/20\n",
      "3022/3022 [==============================] - 19587s 6s/step - loss: 0.0731 - acc: 0.9799 - val_loss: 0.0952 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97895\n",
      "Epoch 6/20\n",
      "3022/3022 [==============================] - 16508s 5s/step - loss: 0.0679 - acc: 0.9815 - val_loss: 0.0930 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97895\n",
      "Epoch 7/20\n",
      "3022/3022 [==============================] - 15415s 5s/step - loss: 0.0635 - acc: 0.9829 - val_loss: 0.0893 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97895\n",
      "Epoch 8/20\n",
      "3022/3022 [==============================] - 14532s 5s/step - loss: 0.0594 - acc: 0.9841 - val_loss: 0.0926 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97895\n",
      "Epoch 9/20\n",
      "1577/3022 [==============>...............] - ETA: 1:51:21 - loss: 0.0574 - acc: 0.9845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3dc77dfc6e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     verbose=1) \n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 3\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "   6/5037 [..............................] - ETA: 37:57:47 - loss: 2.6866 - acc: 0.1278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-596188671c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     verbose=1) \n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 3\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_v2_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5037/5037 [==============================] - 14370s 3s/step - loss: 0.0429 - acc: 0.9889 - val_loss: 0.0656 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98575, saving model to checkpoints/SVHN_IcpResNetV2_LRG299_Mul_STD_L2.hdf5\n",
      "Epoch 2/15\n",
      "5037/5037 [==============================] - 13465s 3s/step - loss: 0.0391 - acc: 0.9900 - val_loss: 0.0680 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.98575 to 0.98602, saving model to checkpoints/SVHN_IcpResNetV2_LRG299_Mul_STD_L2.hdf5\n",
      "Epoch 3/15\n",
      "5037/5037 [==============================] - 13879s 3s/step - loss: 0.0368 - acc: 0.9907 - val_loss: 0.0675 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98602\n",
      "Epoch 4/15\n",
      "5037/5037 [==============================] - 21426s 4s/step - loss: 0.0349 - acc: 0.9913 - val_loss: 0.0667 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98602\n",
      "Epoch 5/15\n",
      "5037/5037 [==============================] - 13525s 3s/step - loss: 0.0328 - acc: 0.9919 - val_loss: 0.0740 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98602\n",
      "Epoch 6/15\n",
      "5037/5037 [==============================] - 13313s 3s/step - loss: 0.0313 - acc: 0.9924 - val_loss: 0.0681 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98602\n",
      "Epoch 7/15\n",
      " 325/5037 [>.............................] - ETA: 3:20:16 - loss: 0.0282 - acc: 0.9929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-42884f05f2c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     verbose=1) \n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_Mul_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "epochs = 15##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper: Save the model.\n",
    "# savedfilename = os.path.join('checkpoints', 'Cifar100_IcpResNetV2_LRG299_Mul_STD_L3.hdf5')\n",
    "# checkpointer = ModelCheckpoint(savedfilename,\n",
    "#                           monitor='val_acc', verbose=1, \n",
    "#                           save_best_only=True, mode='max',save_weights_only=True)########\n",
    "# epochs = 15##!!!\n",
    "# lr = 1e-6\n",
    "# decay = lr/epochs\n",
    "# optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "# model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# result = model_mul.fit_generator(\n",
    "#     generator = train_set, \n",
    "#     steps_per_epoch = step_size_train,\n",
    "#     validation_data = valid_set,\n",
    "#     validation_steps = step_size_valid,\n",
    "#     shuffle=True,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=[earlystopping, checkpointer],\n",
    "# #     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "#     verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# import os\n",
    "\n",
    "# # NUM_GPU = 4\n",
    "# # if NUM_GPU != 1:\n",
    "# #     model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "# model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_IcpResNetV2_LRG299_Mul_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "217/217 [==============================] - 183s 845ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('SVHN_MulModels299_v2_InpResNetV2_1110_v1.csv')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','SVHN_MulModels299_v2_InpResNetV2_L2.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 - InceptionResNetV2\n",
    "# load to multi gpu\n",
    "\n",
    "#use hdf5\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "hdf5file= os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2.hdf5')\n",
    "model_mul.load_weights(hdf5file)\n",
    "\n",
    "f1_sgl = model_mul.layers[-2]\n",
    "f1_sgl.save(os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net 4 - SEResNext-50\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext50')\n",
    "\n",
    "f4_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# #ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(10, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_SEResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_4, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 1\n",
    "#MUL 1 - InceptionV3\n",
    "#Net 6\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Reshape, Bidirectional\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.applications.xception import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "f1_x = f1_base.output\n",
    "f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,2048])(f1_x)  \n",
    "# f1_x = Bidirectional(LSTM(1024, \n",
    "#                                  return_sequences=False, \n",
    "# #                                  dropout=0.8\n",
    "#                                 ),\n",
    "#                             input_shape=[1,2048],\n",
    "#                             merge_mode='concat')(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "f1_x = Dense(100, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_InpResNet_MulModels299_2408_01.csv')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_InceptionV3_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net 5 - ResNext-50\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('resnext50')\n",
    "\n",
    "f5_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f5_x = GlobalAveragePooling2D()(f5_base.output)\n",
    "\n",
    "# #ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f5_x = GaussianNoise(0.1)(f5_x)\n",
    "\n",
    "f5_x = Dense(1024, activation='relu')(f5_x)\n",
    "f5_x = Dense(100, activation='softmax')(f5_x)\n",
    "model_5 = Model(inputs=[f5_base.input],outputs=[f5_x])\n",
    "\n",
    "print(model_5.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_5, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_5, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_tmp.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2.pkl')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change LR=1e-5\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v2.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v2.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v3.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','FashionMNIST_IcpResNetV2_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred3_1 = np.load(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'))\n",
    "mean_pred3_2 = np.load(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3_v2.npy'))\n",
    "mean_pred3_3 = np.load(os.path.join('pred_npy','Cifar100_EfficientB0_299_STD_L3_v2.npy'))\n",
    "mean_pred3 = (mean_pred3_1+mean_pred3_2+mean_pred3_3)/3\n",
    "print(mean_pred3[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "        \n",
    "test_datagen_crop = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred3,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar100_MulModels299_AVG_Assembe_2208.csv')\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar100_MulModels299_AVG_Assembe_2208.csv /home/bribeiro/Phong/Nat19/Cifar100_MulModels299_AVG_Assembe_2208.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred3_1 = np.load(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'))\n",
    "mean_pred3_2 = np.load(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3_v2.npy'))\n",
    "mean_pred3_3 = np.load(os.path.join('pred_npy','Cifar100_EfficientB0_299_STD_L3_v2.npy'))\n",
    "mean_pred3_4 = np.load(os.path.join('pred_npy','Cifar100_Xception_LRG299_Mul.npy'))\n",
    "\n",
    "mean_pred3 = (mean_pred3_1+mean_pred3_2+mean_pred3_3+mean_pred3_4)/4\n",
    "print(mean_pred3[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "        \n",
    "test_datagen_crop = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred3,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar100_MulModels299_AVG_Assembe_2308_v1.csv')\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar100_MulModels299_AVG_Assembe_2308_v1.csv /home/bribeiro/Phong/Nat19/Cifar100_MulModels299_AVG_Assembe_2308_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Xception_LRG501_Mul_Pretrained_STD_SGL.hdf5'))\n",
    "# # model_2.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Inception_LRG501_Mul_Pretrained_STD_SGL.hdf5'))\n",
    "# model_3.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_IcpResNetV2_LRG501_Mul_Pretrained_STD_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 models\n",
    "# 501\n",
    "# pre-trainned weight\n",
    "# get pretrained [-1] layer\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, LeakyReLU, Dropout\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "\n",
    "f1_mul_x = model_1.layers[-1].output \n",
    "f2_mul_x = model_2.layers[-1].output\n",
    "f3_mul_x = model_3.layers[-1].output\n",
    "\n",
    "x = concatenate([f1_mul_x, f2_mul_x, f3_mul_x])\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model_mul = Model(inputs=[model_1.get_input_at(0),model_2.get_input_at(0),model_3.get_input_at(0)],outputs=[x])\n",
    "\n",
    "print(model_mul.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mul.layers[:-4]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_mul.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators for three inputs\n",
    "def train_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator(    \n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,##\n",
    "    #     brightness_range=[0.5, 1.5],##\n",
    "        channel_shift_range=10,##\n",
    "        fill_mode='nearest')\n",
    "    \n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, seed=1, target_size = (299, 299))    \n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield [X1i[0], X1i[0], X1i[0]], X1i[1]\n",
    "        \n",
    "def valid_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator()\n",
    "\n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, seed=1, target_size = (299, 299))        \n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield [X1i[0], X1i[0], X1i[0]], X1i[1]    \n",
    "    \n",
    "def test_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator(\n",
    "#         preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, shuffle=False, target_size = (299, 299))        \n",
    "    while True:\n",
    "        X1i_0, X1i_1 = next(genX1)\n",
    "        yield [X1i_0, X1i_0, X1i_0]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train_resized_299',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('test_resized_299',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, savecheckpoint, earlystopping], \n",
    "    callbacks=[savecheckpoint, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v1.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MULTI GPUS\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from math import ceil\n",
    "# import numpy as np\n",
    "\n",
    "# #Non-Crop-Official Test\n",
    "# def non_random_crop(img, random_crop_size):\n",
    "# #     # Note: image_data_format is 'channel_last'\n",
    "# #     assert img.shape[2] == 3\n",
    "# #     height, width = img.shape[0], img.shape[1]\n",
    "# #     dy, dx = random_crop_size\n",
    "# #     x = np.random.randint(0, width - dx + 1)\n",
    "# #     y = np.random.randint(0, height - dy + 1)\n",
    "# #     return img[y:(y+dy), x:(x+dx), :]\n",
    "#     return img\n",
    "\n",
    "# def non_crop_generator_three_models(batches, crop_length):\n",
    "#     \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "#     while True:\n",
    "#         batch_x, _ = next(batches)\n",
    "#         batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "#         for i in range(batch_x.shape[0]):\n",
    "#             batch_crops[i] = non_random_crop(batch_x[i], (crop_length, crop_length))\n",
    "#         yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "# gen = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "# #         preprocessing_function=preprocess_input\n",
    "# )\n",
    "\n",
    "# genX1 = gen.flow_from_directory('test_resized_299',\n",
    "#                                  target_size = (299, 299),\n",
    "#                                  batch_size = batch_size,\n",
    "#                                  class_mode = 'categorical',\n",
    "#                                  shuffle=False,\n",
    "#                                  seed=7,\n",
    "#                               )\n",
    "\n",
    "# #steps\n",
    "# step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "# #customized generator\n",
    "# test_crops = non_crop_generator_three_models(genX1, 299)\n",
    "\n",
    "# #number of crops\n",
    "# tta_steps = 1\n",
    "# predictions = []\n",
    "\n",
    "# for i in range(tta_steps):\n",
    "#     print('iteration = %d' %i)\n",
    "#     #reset index\n",
    "#     genX1.reset()\n",
    "    \n",
    "#     preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "#     predictions.append(preds)\n",
    "\n",
    "# mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "# labels = (train_set.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "# import pandas as pd\n",
    "# filenames=genX1.filenames\n",
    "# results=pd.DataFrame({\"id\":filenames,\n",
    "#                       \"predicted\":finalpre,\n",
    "#                       })\n",
    "# results.to_csv('Cifar10_MulModels299_STD_TTA1_0811_v6.csv')\n",
    "# results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MULTI GPUS\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from math import ceil\n",
    "# import numpy as np\n",
    "\n",
    "# #Crop-Official Test\n",
    "# def random_crop(img, random_crop_size):\n",
    "#     # Note: image_data_format is 'channel_last'\n",
    "#     assert img.shape[2] == 3\n",
    "#     height, width = img.shape[0], img.shape[1]\n",
    "#     dy, dx = random_crop_size\n",
    "#     x = np.random.randint(0, width - dx + 1)\n",
    "#     y = np.random.randint(0, height - dy + 1)\n",
    "#     return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "# def crop_generator_three_models(batches, crop_length):\n",
    "#     \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "#     while True:\n",
    "#         batch_x, _ = next(batches)\n",
    "#         batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "#         for i in range(batch_x.shape[0]):\n",
    "#             batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "#         yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "# gen = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "# #         preprocessing_function=preprocess_input\n",
    "# )\n",
    "\n",
    "# genX1 = gen.flow_from_directory('test_resized_299',\n",
    "#                                  target_size = (299, 299),\n",
    "#                                  batch_size = batch_size,\n",
    "#                                  class_mode = 'categorical',\n",
    "#                                  shuffle=False,\n",
    "#                                  seed=7,\n",
    "#                               )\n",
    "\n",
    "# #steps\n",
    "# step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "# #customized generator\n",
    "# test_crops = crop_generator_three_models(genX1, 299)\n",
    "\n",
    "# #number of crops\n",
    "# tta_steps = 1\n",
    "# predictions = []\n",
    "\n",
    "# for i in range(tta_steps):\n",
    "#     print('iteration = %d' %i)\n",
    "#     #reset index\n",
    "#     genX1.reset()\n",
    "    \n",
    "#     preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "#     predictions.append(preds)\n",
    "\n",
    "# mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "# labels = (train_set.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "# import pandas as pd\n",
    "# filenames=genX1.filenames\n",
    "# results=pd.DataFrame({\"id\":filenames,\n",
    "#                       \"predicted\":finalpre,\n",
    "#                       })\n",
    "# results.to_csv('Cifar10_MulModels299_STD_TTA1_0811_v5.csv')\n",
    "# results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_MulModels299_STD_TTA1_0811_v6.csv /home/bribeiro/Phong/Nat19/Cifar10_MulModels299_STD_TTA1_0811_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 models\n",
    "# 501\n",
    "# pre-trainned weight\n",
    "# get pretrained [-1] layer\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, LeakyReLU, Dropout\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "\n",
    "f1_mul_x = model_1.layers[-1].output \n",
    "f2_mul_x = model_2.layers[-1].output\n",
    "f3_mul_x = model_3.layers[-1].output\n",
    "\n",
    "x = concatenate([f1_mul_x, f2_mul_x, f3_mul_x])\n",
    "\n",
    "x = Reshape([1,30])(x)  \n",
    "x = Bidirectional(LSTM(1024, \n",
    "                                 return_sequences=False, \n",
    "#                                  dropout=0.8\n",
    "                                ),\n",
    "                            input_shape=[1,30],\n",
    "                            merge_mode='concat')(x)\n",
    "\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model_mul = Model(inputs=[model_1.get_input_at(0),model_2.get_input_at(0),model_3.get_input_at(0)],outputs=[x])\n",
    "\n",
    "print(model_mul.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('fashion_mnist_train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('fashion_mnist_test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'FashionMNIST_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_BiLSTM.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=False)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('fmnist_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('fmnist_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# else:\n",
    "#     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(training_set.n/training_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('fashion_mnist_train_resized_299',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('fashion_mnist_test_resized_299',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v1.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v1.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI GPUS\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator_three_models(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "    while True:\n",
    "        batch_x, _ = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "#         preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "genX1 = gen.flow_from_directory('test',\n",
    "                                 target_size = (541, 541),\n",
    "                                 batch_size = batch_size,\n",
    "                                 class_mode = 'categorical',\n",
    "                                 shuffle=False,\n",
    "                                 seed=7,\n",
    "                              )\n",
    "\n",
    "#steps\n",
    "step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "#customized generator\n",
    "test_crops = crop_generator_three_models(genX1, 501)\n",
    "\n",
    "#number of crops\n",
    "tta_steps = 7\n",
    "# predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print('iteration = %d' %i)\n",
    "    #reset index\n",
    "    genX1.reset()\n",
    "    \n",
    "    preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v5.csv')\n",
    "results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v5.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# #use get_weights() command to get your model weights\n",
    "# weigh= model_mul.get_weights()\n",
    "\n",
    "# #now, use pickle to save your model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'Cassava_NonGrp_S1_LRG501_Mul_Pretrained_STD_09076.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cassava_NonGrp_S1_LRG501_Mul_Pretrained_STD_09076.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "gpus_model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "gpus_model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50##!!!\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v6.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v6.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.91, verbose=1)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.913, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=gpus_model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v8.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v8.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI GPUS\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator_three_models(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "    while True:\n",
    "        batch_x, _ = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "#         preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "genX1 = gen.flow_from_directory('test',\n",
    "                                 target_size = (541, 541),\n",
    "                                 batch_size = batch_size,\n",
    "                                 class_mode = 'categorical',\n",
    "                                 shuffle=False,\n",
    "                                 seed=7,\n",
    "                              )\n",
    "\n",
    "#steps\n",
    "step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "#customized generator\n",
    "test_crops = crop_generator_three_models(genX1, 501)\n",
    "\n",
    "#number of crops\n",
    "tta_steps = 5\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print('iteration = %d / %d' %(i+1,tta_steps))\n",
    "    #reset index\n",
    "    genX1.reset()\n",
    "    \n",
    "    preds=gpus_model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v10.csv')\n",
    "results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v10.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v11.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.919, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=gpus_model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v12.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v12.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v12.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "# lr = 1e-5\n",
    "# decay = lr/epochs\n",
    "lr = 1e-6\n",
    "decay = 0\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.925, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seresnext50\n",
    "#Non-Groups\n",
    "#Split training and validation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 20\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG501_Mul_Pretrained_STD_L4.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8870, verbose=1)##!!!!!!\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping],\n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8898756673450369\n",
    "#0.8827708640911651\n",
    "max(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('SeNet50 - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('SeNet50 - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.save_weights(savedfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.save_weights(savedfilename)\n",
    "f2_sgl = model_mul.layers[-2]\n",
    "f2_sgl.save(os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG450_Mul_Pretrained_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (450, 450),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (450, 450),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels450_2108_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels450_2108_v1.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels450_2108_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG450_Mul_Pretrained_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test',\n",
    "                                                 target_size = (500, 500),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 450)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 3\n",
    "predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "#     if NUM_GPU != 1:\n",
    "#         preds=mul_model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "    preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels450_2108_v3.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels450_2108_v3.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels450_2108_v3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "nasnet, preprocess_input = Classifiers.get('senet154')\n",
    "\n",
    "f4_base = nasnet(input_shape=(501,501,3), weights=None, include_top=False)\n",
    "\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(5, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('Cassava_NonGrp_S1_SENet154_LRG501_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# restoredmodel= mymodel()\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "model_4.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_4.layers[:-4]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_4.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_SENet154_LRG501_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8850, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/qubvel/classification_models/releases/download/0.0.1/senet154_imagenet_1000_no_top.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "nasnet, preprocess_input = Classifiers.get('nasnetlarge')\n",
    "\n",
    "f4_base = nasnet(input_shape=(501,501,3), weights=None, include_top=False)\n",
    "\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(5, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# restoredmodel= mymodel()\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "model_4.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 12\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8850, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 2 - Inception\n",
    "#501\n",
    "import keras\n",
    "\n",
    "# from keras_applications.resnext import ResNeXt101, preprocess_input\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from classification_models.senet import SEResNet101, preprocess_input\n",
    "# from classification_models.keras import Classifiers\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "# ResNext101, preprocess_input = Classifiers.get('resnext101')\n",
    "# NASNetLarge = preprocess_input = Classifiers.get('nasnetlarge')\n",
    "\n",
    "# SENet154, preprocess_input = Classifiers.get('senet154')\n",
    "\n",
    "f2_base = SEInceptionResNetV2(include_top=True,\n",
    "                        weights=None,\n",
    "                        input_tensor=None,\n",
    "                        input_shape=(501,501,3),\n",
    "                        pooling=None)\n",
    "\n",
    "# # f2_base = Classifiers.get('nasnetlarge')[0]((501, 501, 3), weights=None)\n",
    "# f2_base = SENet154((501, 501, 3), weights=None)\n",
    "# # f2_base = SeNet154((501,501,3), weights = 'imagenet', include_top=False) \n",
    "# # f2_base = ResNext101((501,501,3), weights = 'imagenet') \n",
    "# # # f2_base = NASNetLarge((501,501,3), weights = 'imagenet')\n",
    "\n",
    "# # # for layer in f3_base.layers:\n",
    "# # #     layer.trainable = False \n",
    "f2_x = f2_base.layers[-2].output\n",
    "# # # f2_x = GlobalAveragePooling2D()(f2_x)\n",
    "\n",
    "# # #Regularization with noise\n",
    "# f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f2_base = senet(input_shape=(501,501,3), weights='imagenet', include_top=False)\n",
    "f2_x = GlobalAveragePooling2D()(f2_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_2.layers[:-3]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_2.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"Load data from file.\"\"\"\n",
    "    with open(os.path.join('cassava_data_senet.csv'), 'r') as fin:\n",
    "        reader = csv.reader(fin)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_extracted_sequence(sample):\n",
    "    \"\"\"Get the extracted features.\"\"\"\n",
    "    filename = sample[0] + '_' + sample[1] + '_' + sample[2]\n",
    "    path = os.path.join('sequences', filename + '.npy')\n",
    "    #print(path)\n",
    "    if os.path.isfile(path):\n",
    "        return np.load(path)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_classes():\n",
    "    \"\"\"Extract the classes from data\"\"\"\n",
    "    classes = []\n",
    "    for item in data:\n",
    "        if item[1] not in classes:\n",
    "            classes.append(item[1])\n",
    "\n",
    "    # Sort them.\n",
    "    classes = sorted(classes)\n",
    "\n",
    "    # Return.\n",
    "    return classes\n",
    "\n",
    "def get_class_one_hot(class_str):\n",
    "    \"\"\"Encode and one-hot classes for training.\n",
    "    Given a class as a string, return its number in the classes list. \"\"\"\n",
    "    # Encode\n",
    "    label_encoded = classes.index(class_str)\n",
    "\n",
    "    # One-hot\n",
    "    label_hot = to_categorical(label_encoded, len(classes))\n",
    "\n",
    "    assert len(label_hot) == len(classes)\n",
    "\n",
    "    return label_hot\n",
    "\n",
    "def get_all_sequences_in_memory(train_test):\n",
    "    \"\"\"\n",
    "    Load everything into memory\n",
    "    \"\"\"\n",
    "    # Get the right dataset.\n",
    "    train, test = split_train_test()\n",
    "    data = train if train_test == 'train' else test\n",
    "    \n",
    "    print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in data:\n",
    "        sequence = get_extracted_sequence(row)\n",
    "        # modify for single sequence\n",
    "        sequence = np.expand_dims(sequence, axis=0)\n",
    "\n",
    "        if sequence is None:\n",
    "            print(\"Can't find sequence?\")\n",
    "            raise\n",
    "\n",
    "        X.append(sequence)\n",
    "        y.append(get_class_one_hot(row[1]))\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def split_train_test():\n",
    "    \"\"\"Split the data into train and test sets.\"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    for item in data:\n",
    "        if item[0] == 'train':\n",
    "            train.append(item)\n",
    "        else:\n",
    "            test.append(item)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f3_base = senet(input_shape=(501,501,3), weights='imagenet', include_top=False)\n",
    "f3_x = GlobalAveragePooling2D()(f3_base.output)\n",
    "\n",
    "# # # #Regularization with noise\n",
    "# f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "# f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "# f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_3 = Model(inputs=[f3_base.input],outputs=[f3_x])\n",
    "\n",
    "print(model_3.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as imgload\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "class Extractor_SeNet():\n",
    "    def __init__(self, weights=None):\n",
    "\n",
    "        # assign model_1 (Xception)\n",
    "        self.model = model_3\n",
    "            \n",
    "    def extract(self, image_path):\n",
    "        img = imgload.load_img(image_path, target_size=(501, 501)) #input size\n",
    "        #img = imgload.load_img(image_path, target_size=(224, 224)) #densenet, mobilenet\n",
    "        x = imgload.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = self.model.predict(x)\n",
    "\n",
    "#         if self.weights is None:\n",
    "#             # For imagenet/default network:\n",
    "#             features = features[0]\n",
    "#         else:\n",
    "#             # For loaded network:\n",
    "#             features = features[0]\n",
    "\n",
    "        return features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv sequences sequences_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# Get model\n",
    "model = Extractor_SeNet()\n",
    "\n",
    "# Multiple GPUs\n",
    "NUM_GPU = 4\n",
    "model.model = multi_gpu_model(model.model, gpus=NUM_GPU)\n",
    "\n",
    "# Load weights\n",
    "# model.model.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Xception_LRG501_Mul_Pretrained_STD.hdf5'))\n",
    "\n",
    "# Get the dataset.\n",
    "data = get_data()\n",
    "print(len(data))\n",
    "\n",
    "# Get the model.\n",
    "# model = Extractor_InceptionV3()\n",
    "\n",
    "# Loop through data.\n",
    "pbar = tqdm(total=len(data))\n",
    "for images in data:\n",
    "    feature_path = os.path.join('sequences', images[0] + '_' + images[1] + '_' + images[2])\n",
    "\n",
    "    # Skip if the file already existed.\n",
    "    if os.path.isfile(feature_path + '.npy'):\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(images[0], images[1], images[2])\n",
    "    feature = model.extract(image_path)\n",
    "\n",
    "    # Save the feature.\n",
    "    np.save(feature_path, feature)\n",
    "    \n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def get_extracted_sequences_one_model(dir1, sample):\n",
    "    \"\"\"Get the extracted features.\"\"\"\n",
    "    filename = sample[0] + '_' + sample[1] + '_' + sample[2]\n",
    "    path1 = os.path.join(dir1, filename + '.npy')\n",
    "    #print(path)\n",
    "    if os.path.isfile(path1):\n",
    "        return np.load(path1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_all_sequences_one_model_in_memory(dir1, train_test):\n",
    "    \"\"\"\n",
    "    Load everything into memory\n",
    "    \"\"\"\n",
    "    # Get the right dataset.\n",
    "    train, test = split_train_test()\n",
    "    data = train if train_test == 'train' else test\n",
    "    \n",
    "    print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in data:\n",
    "        sequence1 = get_extracted_sequences_one_model(dir1, row)\n",
    "        \n",
    "        # add two sequences\n",
    "#         sequence = np.concatenate(sequence1, axis=0)\n",
    "        # modify for single sequence\n",
    "        sequence = np.expand_dims(sequence1, axis=0)\n",
    "\n",
    "        if sequence is None:\n",
    "            print(\"Can't find sequence?\")\n",
    "            raise\n",
    "\n",
    "        X.append(sequence)\n",
    "        y.append(get_class_one_hot(row[1]))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, LeakyReLU\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "\n",
    "def base_line_one_model():\n",
    "    \"\"\"Build a simple model\"\"\"\n",
    "    # Model.\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(32, input_shape=(16,)))\n",
    "    model.add(Flatten(input_shape=(1,2048)))\n",
    "#     model.add(Dense(1024, activation='relu'))#inceptionv3\n",
    "#     model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senet_model = base_line_one_model()\n",
    "senet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset.\n",
    "data = get_data()\n",
    "print(len(data))\n",
    "\n",
    "# Get the classes.\n",
    "classes = get_classes()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 models\n",
    "#IcpResNet, Inception, Xception\n",
    "#501\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "import time, os\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_TL_SeNet501_Mul_Pretrained_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=False)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "early_stopper = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "\n",
    "\n",
    "X_train, y_train = get_all_sequences_one_model_in_memory('sequences','train')\n",
    "X_valid, y_valid = get_all_sequences_one_model_in_memory('sequences','valid')\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 60\n",
    "nb_epoch = 500\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/nb_epoch\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    mul_model = multi_gpu_model(senet_model, gpus=NUM_GPU)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    mul_model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = mul_model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, csv_logger, checkpointer, early_stopper],\n",
    "            epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 40\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_tmp.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
