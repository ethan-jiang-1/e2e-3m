{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1416601680602344192\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10479797700504900734\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12698893763601678739\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6681537180550322869\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16102781748\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 18020258543797099343\n",
      "physical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:40:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16102781748\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 3687381871396434993\n",
      "physical_device_desc: \"device: 1, name: Quadro P5000, pci bus id: 0000:41:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get image parts\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "np.random.seed(42)\n",
    "rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "for i, rand_img in enumerate(rand_imgs):\n",
    "    train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "    j = i // 5\n",
    "    k = i % 5\n",
    "    axarr[j][k].imshow(imread(rand_img))\n",
    "    axarr[j][k].title.set_text(classname)\n",
    "    axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy\n",
    "\n",
    "# def convert_img_square(im_pth='', dest_path='', desired_size=224):\n",
    "# #     print(im_pth)\n",
    "    \n",
    "#     im = Image.open(im_pth)\n",
    "#     old_size = im.size  # (width, height) format\n",
    "\n",
    "#     ratio = float(desired_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "# #     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "#     new_im = im.resize(new_size)\n",
    "    \n",
    "#     new_im = new_im.convert('RGB')\n",
    "    \n",
    "#     new_im.save(dest_path)\n",
    "\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['fashion_mnist_train_resized_299']\n",
    "# dest_folder = 'fashion_mnist_train_resized_350'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 350)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['fashion_mnist_test_resized_299']\n",
    "# dest_folder = 'fashion_mnist_test_resized_350'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 299)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_gpu_model(model, gpus):\n",
    "    if isinstance(gpus, (list, tuple)):\n",
    "        num_gpus = len(gpus)\n",
    "        target_gpu_ids = gpus\n",
    "    else:\n",
    "        num_gpus = gpus\n",
    "        target_gpu_ids = range(num_gpus)\n",
    "\n",
    "    def get_slice(data, i, parts):\n",
    "        shape = tf.shape(data)\n",
    "        batch_size = shape[:1]\n",
    "        input_shape = shape[1:]\n",
    "        step = batch_size // parts\n",
    "        if i == num_gpus - 1:\n",
    "            size = batch_size - step * i\n",
    "        else:\n",
    "            size = step\n",
    "        size = tf.concat([size, input_shape], axis=0)\n",
    "        stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "        start = stride * i\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    all_outputs = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        all_outputs.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU,\n",
    "    # each getting a slice of the inputs.\n",
    "    for i, gpu_id in enumerate(target_gpu_ids):\n",
    "        with tf.device('/gpu:%d' % gpu_id):\n",
    "            with tf.name_scope('replica_%d' % gpu_id):\n",
    "                inputs = []\n",
    "                # Retrieve a slice of the input.\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_i = Lambda(get_slice,\n",
    "                                   output_shape=input_shape,\n",
    "                                   arguments={'i': i,\n",
    "                                              'parts': num_gpus})(x)\n",
    "                    inputs.append(slice_i)\n",
    "\n",
    "                # Apply model on slice\n",
    "                # (creating a model replica on the target device).\n",
    "                outputs = model(inputs)\n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "\n",
    "                # Save the outputs for merging back together later.\n",
    "                for o in range(len(outputs)):\n",
    "                    all_outputs[o].append(outputs[o])\n",
    "\n",
    "    # Merge outputs on CPU.\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for name, outputs in zip(model.output_names, all_outputs):\n",
    "            merged.append(concatenate(outputs,\n",
    "                                    axis=0, name=name))\n",
    "        return Model(model.inputs, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET 1\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f2_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f2_x = GlobalAveragePooling2D()(f2_base.output)\n",
    "\n",
    "#ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(1024, activation='relu')(f2_x)\n",
    "f2_x = Dense(100, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mv train_resized train_resized_299\n",
    "# %mv test_resized test_resized_299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 40\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change LR=1e-5\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L2.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('SeNet - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('SeNet - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L2.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change LR=1e-6\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras.backend as K\n",
    "\n",
    "# run_meta = tf.RunMetadata()\n",
    "# with tf.Session(graph=tf.Graph()) as sess:\n",
    "#     K.set_session(sess)\n",
    "#     net = senet(input_tensor=tf.placeholder('float32', shape=(1,421,421,3)))\n",
    "\n",
    "#     opts = tf.profiler.ProfileOptionBuilder.float_operation()    \n",
    "#     flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "#     opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
    "#     params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "#     print(\"{:,} --- {:,}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_SeResNet101_MulModels299_STD_2208_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_1511_v8.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_1511_v8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pred_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (320, 320),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 11\n",
    "predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_tta_11_1511_v9.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv /home/bribeiro/Phong/Nat19/Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_SeResNet101_MulModels299_STD_tta_15_1511_v6.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save weights in pickle format instead of h5\n",
    "# import pickle\n",
    "\n",
    "# #use get_weights() command to get your model weights\n",
    "# weigh= model_2.get_weights()\n",
    "\n",
    "# #now, use pickle to save your model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG501_Mul_STD.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use pickle to load model weights\n",
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG299_Mul_LSTM_L3.pkl')\n",
    "\n",
    "# f= open(pklfile, 'rb')     #Python 3                 \n",
    "# weigh= pickle.load(f);                \n",
    "# f.close();\n",
    "\n",
    "# #use set_weights to load the modelweights into the model architecture\n",
    "# NUM_GPU = 4\n",
    "# #Using multiple models if more than 1 GPU\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 - SeResNext101\n",
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# load to multi gpu\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "#load model the saved weights\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#set the saved weight to mul-gpus model\n",
    "model_mul.set_weights(weigh)\n",
    "\n",
    "f2_sgl = model_mul.layers[-2]\n",
    "\n",
    "#get weight from single gpu\n",
    "weigh= f2_sgl.get_weights()\n",
    "\n",
    "#now, use pickle to save model weights, instead of .h5\n",
    "#for heavy model architectures, .h5 file is unsupported.\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3_SGL.pkl')\n",
    "\n",
    "fpkl= open(pklfile, 'wb') #Python 3\n",
    "pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2 - SEResNext101\n",
    "#load model the saved weights\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_SEResNext101_LRG299_Mul_STD_L3_SGL.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#set the saved weight to mul-gpus model\n",
    "model_2.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load to multi gpu\n",
    "# NUM_GPU = 4\n",
    "# model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# #get weight from mul gpu\n",
    "# weigh= model_mul.get_weights()\n",
    "\n",
    "# #now, use pickle to save model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'FashionMNIST_SEResNext101_LRG299_Mul_LSTM_L3_SGL.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           10250       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,969,906\n",
      "Trainable params: 22,915,378\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Set 1\n",
    "#MUL 1 - Xception\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Reshape, Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f1_base = Xception(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "f1_x = f1_base.output\n",
    "f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,2048])(f1_x)  \n",
    "# f1_x = Bidirectional(LSTM(1024, \n",
    "#                                  return_sequences=False, \n",
    "# #                                  dropout=0.8\n",
    "#                                 ),\n",
    "#                             input_shape=[1,2048],\n",
    "#                             merge_mode='concat')(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From /home/phong/Documents/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "9444/9444 [==============================] - 13677s 1s/step - loss: 0.2376 - acc: 0.9264 - val_loss: 0.1457 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96547, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 2/20\n",
      "9444/9444 [==============================] - 13299s 1s/step - loss: 0.1017 - acc: 0.9719 - val_loss: 0.1127 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96547 to 0.97192, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 3/20\n",
      "9444/9444 [==============================] - 20408s 2s/step - loss: 0.0825 - acc: 0.9777 - val_loss: 0.0902 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97192 to 0.97945, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 4/20\n",
      "9444/9444 [==============================] - 14209s 2s/step - loss: 0.0724 - acc: 0.9808 - val_loss: 0.0840 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.97945 to 0.98045, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 5/20\n",
      "9444/9444 [==============================] - 13257s 1s/step - loss: 0.0644 - acc: 0.9830 - val_loss: 0.0767 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98045 to 0.98287, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 6/20\n",
      "9444/9444 [==============================] - 16218s 2s/step - loss: 0.0592 - acc: 0.9845 - val_loss: 0.0789 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98287\n",
      "Epoch 7/20\n",
      "9444/9444 [==============================] - 14025s 1s/step - loss: 0.0552 - acc: 0.9856 - val_loss: 0.0768 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.98287 to 0.98302, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 8/20\n",
      "9444/9444 [==============================] - 13203s 1s/step - loss: 0.0524 - acc: 0.9865 - val_loss: 0.0739 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98302 to 0.98314, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 9/20\n",
      "9444/9444 [==============================] - 13185s 1s/step - loss: 0.0496 - acc: 0.9873 - val_loss: 0.0734 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98314 to 0.98402, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 10/20\n",
      "9444/9444 [==============================] - 13183s 1s/step - loss: 0.0470 - acc: 0.9880 - val_loss: 0.0737 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98402\n",
      "Epoch 11/20\n",
      "9444/9444 [==============================] - 13342s 1s/step - loss: 0.0442 - acc: 0.9887 - val_loss: 0.0724 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98402\n",
      "Epoch 12/20\n",
      "9444/9444 [==============================] - 17504s 2s/step - loss: 0.0423 - acc: 0.9893 - val_loss: 0.0703 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.98402 to 0.98433, saving model to checkpoints/SVHN_Xception_299_v2.hdf5\n",
      "Epoch 13/20\n",
      "4362/9444 [============>.................] - ETA: 2:40:25 - loss: 0.0398 - acc: 0.9897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4079/9444 [===========>..................] - ETA: 2:08:18 - loss: 0.0392 - acc: 0.9901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8995/9444 [===========================>..] - ETA: 11:29 - loss: 0.0375 - acc: 0.9905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444/9444 [==============================] - 13297s 1s/step - loss: 0.0355 - acc: 0.9910 - val_loss: 0.0761 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98433\n",
      "Epoch 17/20\n",
      "9444/9444 [==============================] - 13319s 1s/step - loss: 0.0346 - acc: 0.9912 - val_loss: 0.0766 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98433\n",
      "Epoch 18/20\n",
      "7103/9444 [=====================>........] - ETA: 1:02:05 - loss: 0.0330 - acc: 0.9916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4190/9444 [============>.................] - ETA: 2:04:02 - loss: 0.0318 - acc: 0.9920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4146/9444 [============>.................] - ETA: 2:05:25 - loss: 0.0303 - acc: 0.9924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 2\n",
    "batch_size = 64\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_Xception_299_v2.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9843269821757836, 0.9654655808236017)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = result\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'SVHN_Xception_299_v2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "9444/9444 [==============================] - 13047s 1s/step - loss: 0.0373 - acc: 0.9906 - val_loss: 0.0712 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98529, saving model to checkpoints/SVHN_Xception_299_v2_L2.hdf5\n",
      "Epoch 2/15\n",
      "9444/9444 [==============================] - 12943s 1s/step - loss: 0.0342 - acc: 0.9915 - val_loss: 0.0725 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98529\n",
      "Epoch 3/15\n",
      "9444/9444 [==============================] - 13019s 1s/step - loss: 0.0316 - acc: 0.9921 - val_loss: 0.0765 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98529\n",
      "Epoch 4/15\n",
      "9444/9444 [==============================] - 13142s 1s/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.0773 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98529\n",
      "Epoch 5/15\n",
      "3112/9444 [========>.....................] - ETA: 2:22:07 - loss: 0.0274 - acc: 0.9934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444/9444 [==============================] - 12847s 1s/step - loss: 0.0275 - acc: 0.9933 - val_loss: 0.0783 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98529\n",
      "Epoch 6/15\n",
      "9444/9444 [==============================] - 12817s 1s/step - loss: 0.0258 - acc: 0.9938 - val_loss: 0.0859 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98529\n",
      "Epoch 7/15\n",
      "9444/9444 [==============================] - 12851s 1s/step - loss: 0.0242 - acc: 0.9942 - val_loss: 0.0877 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98529\n",
      "Epoch 8/15\n",
      "9444/9444 [==============================] - 12833s 1s/step - loss: 0.0231 - acc: 0.9944 - val_loss: 0.0862 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98529\n",
      "Epoch 9/15\n",
      "9444/9444 [==============================] - 12764s 1s/step - loss: 0.0219 - acc: 0.9947 - val_loss: 0.0924 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98529\n",
      "Epoch 10/15\n",
      "9444/9444 [==============================] - 12834s 1s/step - loss: 0.0205 - acc: 0.9950 - val_loss: 0.0926 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98529\n",
      "Epoch 11/15\n",
      "5885/9444 [=================>............] - ETA: 1:19:46 - loss: 0.0193 - acc: 0.9952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444/9444 [==============================] - 12794s 1s/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.0997 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98529\n",
      "Epoch 12/15\n",
      "9427/9444 [============================>.] - ETA: 23s - loss: 0.0183 - acc: 0.9955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444/9444 [==============================] - 12934s 1s/step - loss: 0.0272 - acc: 0.9928 - val_loss: 0.0911 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98529\n",
      "Epoch 14/15\n",
      "9444/9444 [==============================] - 12960s 1s/step - loss: 0.0259 - acc: 0.9931 - val_loss: 0.0965 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98529\n",
      "Epoch 15/15\n",
      "9444/9444 [==============================] - 12958s 1s/step - loss: 0.0253 - acc: 0.9933 - val_loss: 0.1029 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98529\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_Xception_299_v2_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'SVHN_Xception_299_v2_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2_v2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import numpy as np\n",
    "\n",
    "print(result.history['val_acc'])\n",
    "print(np.mean(result.history['val_acc']))\n",
    "print(np.max(result.history['val_acc']))\n",
    "\n",
    "print(result.history['acc'])\n",
    "print(np.mean(result.history['acc']))\n",
    "print(np.max(result.history['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "NUM_GPU = 4\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Xception_LRG299_Mul_STD_L2_v2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 604388 images belonging to 10 classes.\n",
      "Found 26032 images belonging to 10 classes.\n",
      "407/407 [==============================] - 131s 323ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/00002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/00005.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/00007.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/00008.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/00013.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name predicted1\n",
       "0  1/00002.png          1\n",
       "1  1/00005.png          1\n",
       "2  1/00007.png          1\n",
       "3  1/00008.png          1\n",
       "4  1/00013.png          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('SVHN_Xception_299_v2_L2_1610_01.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pred_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','SVHN_Xception_299_v2_L2_1610_01.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 - Xception\n",
    "# load to multi gpu\n",
    "\n",
    "#use hdf5\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "hdf5file= os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L2.hdf5')\n",
    "model_mul.load_weights(hdf5file)\n",
    "\n",
    "f1_sgl = model_mul.layers[-2]\n",
    "f1_sgl.save(os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.load_weights(os.path.join('checkpoints', 'Cifar10_Xception_LRG299_Mul_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#501\n",
    "#MUL 3 InceptionResNetV2\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f3_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "# for layer in f3_base.layers:\n",
    "#     layer.trainable = False \n",
    "f3_x = f3_base.output\n",
    "f3_x = GlobalAveragePooling2D()(f3_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f3_x = GaussianNoise(0.1)(f3_x)\n",
    "\n",
    "f3_x = Dense(1024, activation='relu')(f3_x)\n",
    "f3_x = Dense(10, activation='softmax')(f3_x)\n",
    "model_3 = Model(inputs=[f3_base.input],outputs=[f3_x])\n",
    "\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 3\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 3\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_v2_tmp.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('svhn_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('svhn_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-3\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'SVHN_IcpResNetV2_LRG299_Mul_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "epochs = 15##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[csv_logger, earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc']),min(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_IcpResNetV2_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_IcpResNetV2_LRG299_Mul_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using multiple models if more than 1 GPU\n",
    "import os\n",
    "\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_IcpResNetV2_LRG299_Mul_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_InpResNet_MulModels299_2408_01.csv')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_InpResNet_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 - InceptionResNetV2\n",
    "# load to multi gpu\n",
    "\n",
    "#use hdf5\n",
    "NUM_GPU = 4\n",
    "model_mul = multi_gpu_model(model_3, gpus=NUM_GPU)\n",
    "\n",
    "hdf5file= os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2.hdf5')\n",
    "model_mul.load_weights(hdf5file)\n",
    "\n",
    "f1_sgl = model_mul.layers[-2]\n",
    "f1_sgl.save(os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(os.path.join('checkpoints', 'Cifar10_IcpResNetV2_LRG299_Mul_STD_L2_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net 4 - SEResNext-50\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext50')\n",
    "\n",
    "f4_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# #ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(10, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_SEResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_4, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 1\n",
    "#MUL 1 - InceptionV3\n",
    "#Net 6\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Reshape, Bidirectional\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.applications.xception import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "f1_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299,3))  \n",
    "f1_x = f1_base.output\n",
    "f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,2048])(f1_x)  \n",
    "# f1_x = Bidirectional(LSTM(1024, \n",
    "#                                  return_sequences=False, \n",
    "# #                                  dropout=0.8\n",
    "#                                 ),\n",
    "#                             input_shape=[1,2048],\n",
    "#                             merge_mode='concat')(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "f1_x = Dense(100, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_InceptionV3_LRG299_Mul_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_InpResNet_MulModels299_2408_01.csv')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_InceptionV3_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net 5 - ResNext-50\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, SimpleRNN, Reshape, Concatenate,Bidirectional\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('resnext50')\n",
    "\n",
    "f5_base = senet(input_shape=(299,299,3), weights='imagenet', include_top=False)\n",
    "f5_x = GlobalAveragePooling2D()(f5_base.output)\n",
    "\n",
    "# #ADV Model\n",
    "# f2_x = Reshape([1,2048])(f2_x)  \n",
    "# f2_x = SimpleRNN(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,2048])(f2_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f5_x = GaussianNoise(0.1)(f5_x)\n",
    "\n",
    "f5_x = Dense(1024, activation='relu')(f5_x)\n",
    "f5_x = Dense(100, activation='softmax')(f5_x)\n",
    "model_5 = Model(inputs=[f5_base.input],outputs=[f5_x])\n",
    "\n",
    "print(model_5.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_5, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_5, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_tmp.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2.pkl')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change LR=1e-5\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v2.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v2.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_ResNext50_LRG299_Mul_STD_L2_v3.pkl')\n",
    "savecheckpoint = SaveCheckPoint(model_5, savedfilename)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','FashionMNIST_IcpResNetV2_LRG299_Mul.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred3_1 = np.load(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'))\n",
    "mean_pred3_2 = np.load(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3_v2.npy'))\n",
    "mean_pred3_3 = np.load(os.path.join('pred_npy','Cifar100_EfficientB0_299_STD_L3_v2.npy'))\n",
    "mean_pred3 = (mean_pred3_1+mean_pred3_2+mean_pred3_3)/3\n",
    "print(mean_pred3[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "        \n",
    "test_datagen_crop = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred3,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar100_MulModels299_AVG_Assembe_2208.csv')\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar100_MulModels299_AVG_Assembe_2208.csv /home/bribeiro/Phong/Nat19/Cifar100_MulModels299_AVG_Assembe_2208.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred3_1 = np.load(os.path.join('pred_npy','Cifar100_SEResNext101_LRG299_Mul.npy'))\n",
    "mean_pred3_2 = np.load(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3_v2.npy'))\n",
    "mean_pred3_3 = np.load(os.path.join('pred_npy','Cifar100_EfficientB0_299_STD_L3_v2.npy'))\n",
    "mean_pred3_4 = np.load(os.path.join('pred_npy','Cifar100_Xception_LRG299_Mul.npy'))\n",
    "\n",
    "mean_pred3 = (mean_pred3_1+mean_pred3_2+mean_pred3_3+mean_pred3_4)/4\n",
    "print(mean_pred3[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "        \n",
    "test_datagen_crop = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 299)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred3,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar100_MulModels299_AVG_Assembe_2308_v1.csv')\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar100_MulModels299_AVG_Assembe_2308_v1.csv /home/bribeiro/Phong/Nat19/Cifar100_MulModels299_AVG_Assembe_2308_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Xception_LRG501_Mul_Pretrained_STD_SGL.hdf5'))\n",
    "# # model_2.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Inception_LRG501_Mul_Pretrained_STD_SGL.hdf5'))\n",
    "# model_3.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_IcpResNetV2_LRG501_Mul_Pretrained_STD_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 models\n",
    "# 501\n",
    "# pre-trainned weight\n",
    "# get pretrained [-1] layer\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, LeakyReLU, Dropout\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "\n",
    "f1_mul_x = model_1.layers[-1].output \n",
    "f2_mul_x = model_2.layers[-1].output\n",
    "f3_mul_x = model_3.layers[-1].output\n",
    "\n",
    "x = concatenate([f1_mul_x, f2_mul_x, f3_mul_x])\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model_mul = Model(inputs=[model_1.get_input_at(0),model_2.get_input_at(0),model_3.get_input_at(0)],outputs=[x])\n",
    "\n",
    "print(model_mul.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mul.layers[:-4]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_mul.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators for three inputs\n",
    "def train_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator(    \n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,##\n",
    "    #     brightness_range=[0.5, 1.5],##\n",
    "        channel_shift_range=10,##\n",
    "        fill_mode='nearest')\n",
    "    \n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, seed=1, target_size = (299, 299))    \n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield [X1i[0], X1i[0], X1i[0]], X1i[1]\n",
    "        \n",
    "def valid_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator()\n",
    "\n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, seed=1, target_size = (299, 299))        \n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield [X1i[0], X1i[0], X1i[0]], X1i[1]    \n",
    "    \n",
    "def test_generator_three_img(X1, batch_size):\n",
    "    gen = ImageDataGenerator(\n",
    "#         preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    genX1 = gen.flow_from_directory(X1, batch_size=batch_size, shuffle=False, target_size = (299, 299))        \n",
    "    while True:\n",
    "        X1i_0, X1i_1 = next(genX1)\n",
    "        yield [X1i_0, X1i_0, X1i_0]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_STD.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train_resized_299',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('test_resized_299',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, savecheckpoint, earlystopping], \n",
    "    callbacks=[savecheckpoint, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cifar10_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "NUM_GPU = 4\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v1.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MULTI GPUS\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from math import ceil\n",
    "# import numpy as np\n",
    "\n",
    "# #Non-Crop-Official Test\n",
    "# def non_random_crop(img, random_crop_size):\n",
    "# #     # Note: image_data_format is 'channel_last'\n",
    "# #     assert img.shape[2] == 3\n",
    "# #     height, width = img.shape[0], img.shape[1]\n",
    "# #     dy, dx = random_crop_size\n",
    "# #     x = np.random.randint(0, width - dx + 1)\n",
    "# #     y = np.random.randint(0, height - dy + 1)\n",
    "# #     return img[y:(y+dy), x:(x+dx), :]\n",
    "#     return img\n",
    "\n",
    "# def non_crop_generator_three_models(batches, crop_length):\n",
    "#     \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "#     while True:\n",
    "#         batch_x, _ = next(batches)\n",
    "#         batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "#         for i in range(batch_x.shape[0]):\n",
    "#             batch_crops[i] = non_random_crop(batch_x[i], (crop_length, crop_length))\n",
    "#         yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "# gen = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "# #         preprocessing_function=preprocess_input\n",
    "# )\n",
    "\n",
    "# genX1 = gen.flow_from_directory('test_resized_299',\n",
    "#                                  target_size = (299, 299),\n",
    "#                                  batch_size = batch_size,\n",
    "#                                  class_mode = 'categorical',\n",
    "#                                  shuffle=False,\n",
    "#                                  seed=7,\n",
    "#                               )\n",
    "\n",
    "# #steps\n",
    "# step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "# #customized generator\n",
    "# test_crops = non_crop_generator_three_models(genX1, 299)\n",
    "\n",
    "# #number of crops\n",
    "# tta_steps = 1\n",
    "# predictions = []\n",
    "\n",
    "# for i in range(tta_steps):\n",
    "#     print('iteration = %d' %i)\n",
    "#     #reset index\n",
    "#     genX1.reset()\n",
    "    \n",
    "#     preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "#     predictions.append(preds)\n",
    "\n",
    "# mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "# labels = (train_set.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "# import pandas as pd\n",
    "# filenames=genX1.filenames\n",
    "# results=pd.DataFrame({\"id\":filenames,\n",
    "#                       \"predicted\":finalpre,\n",
    "#                       })\n",
    "# results.to_csv('Cifar10_MulModels299_STD_TTA1_0811_v6.csv')\n",
    "# results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MULTI GPUS\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from math import ceil\n",
    "# import numpy as np\n",
    "\n",
    "# #Crop-Official Test\n",
    "# def random_crop(img, random_crop_size):\n",
    "#     # Note: image_data_format is 'channel_last'\n",
    "#     assert img.shape[2] == 3\n",
    "#     height, width = img.shape[0], img.shape[1]\n",
    "#     dy, dx = random_crop_size\n",
    "#     x = np.random.randint(0, width - dx + 1)\n",
    "#     y = np.random.randint(0, height - dy + 1)\n",
    "#     return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "# def crop_generator_three_models(batches, crop_length):\n",
    "#     \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "#     while True:\n",
    "#         batch_x, _ = next(batches)\n",
    "#         batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "#         for i in range(batch_x.shape[0]):\n",
    "#             batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "#         yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "# gen = ImageDataGenerator(\n",
    "# #     rescale = 1./255,\n",
    "# #         preprocessing_function=preprocess_input\n",
    "# )\n",
    "\n",
    "# genX1 = gen.flow_from_directory('test_resized_299',\n",
    "#                                  target_size = (299, 299),\n",
    "#                                  batch_size = batch_size,\n",
    "#                                  class_mode = 'categorical',\n",
    "#                                  shuffle=False,\n",
    "#                                  seed=7,\n",
    "#                               )\n",
    "\n",
    "# #steps\n",
    "# step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "# #customized generator\n",
    "# test_crops = crop_generator_three_models(genX1, 299)\n",
    "\n",
    "# #number of crops\n",
    "# tta_steps = 1\n",
    "# predictions = []\n",
    "\n",
    "# for i in range(tta_steps):\n",
    "#     print('iteration = %d' %i)\n",
    "#     #reset index\n",
    "#     genX1.reset()\n",
    "    \n",
    "#     preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "#     predictions.append(preds)\n",
    "\n",
    "# mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "# labels = (train_set.class_indices)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "# import pandas as pd\n",
    "# filenames=genX1.filenames\n",
    "# results=pd.DataFrame({\"id\":filenames,\n",
    "#                       \"predicted\":finalpre,\n",
    "#                       })\n",
    "# results.to_csv('Cifar10_MulModels299_STD_TTA1_0811_v5.csv')\n",
    "# results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_MulModels299_STD_TTA1_0811_v6.csv /home/bribeiro/Phong/Nat19/Cifar10_MulModels299_STD_TTA1_0811_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 models\n",
    "# 501\n",
    "# pre-trainned weight\n",
    "# get pretrained [-1] layer\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, LeakyReLU, Dropout\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "\n",
    "f1_mul_x = model_1.layers[-1].output \n",
    "f2_mul_x = model_2.layers[-1].output\n",
    "f3_mul_x = model_3.layers[-1].output\n",
    "\n",
    "x = concatenate([f1_mul_x, f2_mul_x, f3_mul_x])\n",
    "\n",
    "x = Reshape([1,30])(x)  \n",
    "x = Bidirectional(LSTM(1024, \n",
    "                                 return_sequences=False, \n",
    "#                                  dropout=0.8\n",
    "                                ),\n",
    "                            input_shape=[1,30],\n",
    "                            merge_mode='concat')(x)\n",
    "\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model_mul = Model(inputs=[model_1.get_input_at(0),model_2.get_input_at(0),model_3.get_input_at(0)],outputs=[x])\n",
    "\n",
    "print(model_mul.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 120\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('fashion_mnist_train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('fashion_mnist_test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'FashionMNIST_LRG299_Mul_Pretrained_SeNet_Xcep_IcpRes_BiLSTM.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=False)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('fmnist_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('fmnist_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# else:\n",
    "#     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 20##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(training_set.n/training_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('fashion_mnist_train_resized_299',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('fashion_mnist_test_resized_299',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v1.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v1.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI GPUS\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator_three_models(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "    while True:\n",
    "        batch_x, _ = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "#         preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "genX1 = gen.flow_from_directory('test',\n",
    "                                 target_size = (541, 541),\n",
    "                                 batch_size = batch_size,\n",
    "                                 class_mode = 'categorical',\n",
    "                                 shuffle=False,\n",
    "                                 seed=7,\n",
    "                              )\n",
    "\n",
    "#steps\n",
    "step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "#customized generator\n",
    "test_crops = crop_generator_three_models(genX1, 501)\n",
    "\n",
    "#number of crops\n",
    "tta_steps = 7\n",
    "# predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print('iteration = %d' %i)\n",
    "    #reset index\n",
    "    genX1.reset()\n",
    "    \n",
    "    preds=model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v5.csv')\n",
    "results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v5.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# #use get_weights() command to get your model weights\n",
    "# weigh= model_mul.get_weights()\n",
    "\n",
    "# #now, use pickle to save your model weights, instead of .h5\n",
    "# #for heavy model architectures, .h5 file is unsupported.\n",
    "# pklfile= os.path.join('checkpoints', 'Cassava_NonGrp_S1_LRG501_Mul_Pretrained_STD_09076.pkl')\n",
    "\n",
    "# fpkl= open(pklfile, 'wb') #Python 3\n",
    "# pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "# fpkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "\n",
    "pklfile= os.path.join('checkpoints', 'Cassava_NonGrp_S1_LRG501_Mul_Pretrained_STD_09076.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "gpus_model_mul = multi_gpu_model(model_mul, gpus=NUM_GPU)\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "gpus_model_mul.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50##!!!\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v6.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v6.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.91, verbose=1)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.913, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=gpus_model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v8.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v8.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI GPUS\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator_three_models(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "     \n",
    "    while True:\n",
    "        batch_x, _ = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield [batch_crops, batch_crops, batch_crops]\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "#         preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "genX1 = gen.flow_from_directory('test',\n",
    "                                 target_size = (541, 541),\n",
    "                                 batch_size = batch_size,\n",
    "                                 class_mode = 'categorical',\n",
    "                                 shuffle=False,\n",
    "                                 seed=7,\n",
    "                              )\n",
    "\n",
    "#steps\n",
    "step_size_test_crop = ceil(genX1.n/genX1.batch_size)\n",
    "\n",
    "#customized generator\n",
    "test_crops = crop_generator_three_models(genX1, 501)\n",
    "\n",
    "#number of crops\n",
    "tta_steps = 5\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print('iteration = %d / %d' %(i+1,tta_steps))\n",
    "    #reset index\n",
    "    genX1.reset()\n",
    "    \n",
    "    preds=gpus_model_mul.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v10.csv')\n",
    "results.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v10.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v11.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.919, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('Mul-ResNext - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_generator\n",
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=gpus_model_mul.predict_generator(test_generator_three_img('test',batch_size), steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels501_2208_v12.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels501_2208_v12.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels501_2208_v12.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train after reload weight (val_acc: 0.9076)\n",
    "\n",
    "epochs = 40##!!!\n",
    "\n",
    "# lr = 1e-5\n",
    "# decay = lr/epochs\n",
    "lr = 1e-6\n",
    "decay = 0\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "gpus_model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.925, verbose=1)\n",
    "\n",
    "result = gpus_model_mul.fit_generator(\n",
    "    generator = train_generator_three_img('train',batch_size=batch_size), \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_generator_three_img('valid',batch_size=batch_size),\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping], \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seresnext50\n",
    "#Non-Groups\n",
    "#Split training and validation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 20\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG501_Mul_Pretrained_STD_L4.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8870, verbose=1)##!!!!!!\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping], \n",
    "    callbacks=[tb, csv_logger, earlystopping],\n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8898756673450369\n",
    "#0.8827708640911651\n",
    "max(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "# history = result.history\n",
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('SeNet50 - 501 - Noise model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('SeNet50 - 501 - Noise model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.save_weights(savedfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.save_weights(savedfilename)\n",
    "f2_sgl = model_mul.layers[-2]\n",
    "f2_sgl.save(os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG450_Mul_Pretrained_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (450, 450),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test',\n",
    "                                                 target_size = (450, 450),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels450_2108_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels450_2108_v1.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels450_2108_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_SEResNext50_LRG450_Mul_Pretrained_STD_L3_SGL.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test',\n",
    "                                                 target_size = (500, 500),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 450)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 3\n",
    "predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "#     if NUM_GPU != 1:\n",
    "#         preds=mul_model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "    preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cassava_NonGrp_MulModels450_2108_v3.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cassava_NonGrp_MulModels450_2108_v3.csv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_MulModels450_2108_v3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "nasnet, preprocess_input = Classifiers.get('senet154')\n",
    "\n",
    "f4_base = nasnet(input_shape=(501,501,3), weights=None, include_top=False)\n",
    "\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(5, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('Cassava_NonGrp_S1_SENet154_LRG501_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# restoredmodel= mymodel()\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "model_4.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_4.layers[:-4]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_4.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 80\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_SENet154_LRG501_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8850, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/qubvel/classification_models/releases/download/0.0.1/senet154_imagenet_1000_no_top.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv /home/bribeiro/Phong/Nat19/Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "nasnet, preprocess_input = Classifiers.get('nasnetlarge')\n",
    "\n",
    "f4_base = nasnet(input_shape=(501,501,3), weights=None, include_top=False)\n",
    "\n",
    "f4_x = GlobalAveragePooling2D()(f4_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f4_x = GaussianNoise(0.1)(f4_x)\n",
    "\n",
    "f4_x = Dense(2048, activation='relu')(f4_x)\n",
    "f4_x = Dense(5, activation='softmax')(f4_x)\n",
    "model_4 = Model(inputs=[f4_base.input],outputs=[f4_x])\n",
    "\n",
    "print(model_4.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load model weights\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "pklfile= os.path.join('Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.pkl')\n",
    "\n",
    "f= open(pklfile, 'rb')     #Python 3                 \n",
    "weigh= pickle.load(f);                \n",
    "f.close();\n",
    "\n",
    "# restoredmodel= mymodel()\n",
    "#use set_weights to load the modelweights into the model architecture\n",
    "model_4.set_weights(weigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 12\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('valid',\n",
    "                                                 target_size = (501, 501),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_NASNetLarge_LRG501_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.8850, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_4, gpus=NUM_GPU)\n",
    "\n",
    "# print('Loading pretrained weights')\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul.load_weights(savedfilename)\n",
    "# # else:\n",
    "# #     model.load_weights(savedfilename)\n",
    "\n",
    "epochs = 30##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 2 - Inception\n",
    "#501\n",
    "import keras\n",
    "\n",
    "# from keras_applications.resnext import ResNeXt101, preprocess_input\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from classification_models.senet import SEResNet101, preprocess_input\n",
    "# from classification_models.keras import Classifiers\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "# ResNext101, preprocess_input = Classifiers.get('resnext101')\n",
    "# NASNetLarge = preprocess_input = Classifiers.get('nasnetlarge')\n",
    "\n",
    "# SENet154, preprocess_input = Classifiers.get('senet154')\n",
    "\n",
    "f2_base = SEInceptionResNetV2(include_top=True,\n",
    "                        weights=None,\n",
    "                        input_tensor=None,\n",
    "                        input_shape=(501,501,3),\n",
    "                        pooling=None)\n",
    "\n",
    "# # f2_base = Classifiers.get('nasnetlarge')[0]((501, 501, 3), weights=None)\n",
    "# f2_base = SENet154((501, 501, 3), weights=None)\n",
    "# # f2_base = SeNet154((501,501,3), weights = 'imagenet', include_top=False) \n",
    "# # f2_base = ResNext101((501,501,3), weights = 'imagenet') \n",
    "# # # f2_base = NASNetLarge((501,501,3), weights = 'imagenet')\n",
    "\n",
    "# # # for layer in f3_base.layers:\n",
    "# # #     layer.trainable = False \n",
    "f2_x = f2_base.layers[-2].output\n",
    "# # # f2_x = GlobalAveragePooling2D()(f2_x)\n",
    "\n",
    "# # #Regularization with noise\n",
    "# f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f2_base = senet(input_shape=(501,501,3), weights='imagenet', include_top=False)\n",
    "f2_x = GlobalAveragePooling2D()(f2_base.output)\n",
    "\n",
    "# # #Regularization with noise\n",
    "f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_2 = Model(inputs=[f2_base.input],outputs=[f2_x])\n",
    "\n",
    "print(model_2.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_2.layers[:-3]:\n",
    "    layer.trainable=False\n",
    "# for layer in model.layers[87:]:\n",
    "#     layer.trainable=True)\n",
    "for i,layer in enumerate(model_2.layers):\n",
    "    print(i,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"Load data from file.\"\"\"\n",
    "    with open(os.path.join('cassava_data_senet.csv'), 'r') as fin:\n",
    "        reader = csv.reader(fin)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_extracted_sequence(sample):\n",
    "    \"\"\"Get the extracted features.\"\"\"\n",
    "    filename = sample[0] + '_' + sample[1] + '_' + sample[2]\n",
    "    path = os.path.join('sequences', filename + '.npy')\n",
    "    #print(path)\n",
    "    if os.path.isfile(path):\n",
    "        return np.load(path)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_classes():\n",
    "    \"\"\"Extract the classes from data\"\"\"\n",
    "    classes = []\n",
    "    for item in data:\n",
    "        if item[1] not in classes:\n",
    "            classes.append(item[1])\n",
    "\n",
    "    # Sort them.\n",
    "    classes = sorted(classes)\n",
    "\n",
    "    # Return.\n",
    "    return classes\n",
    "\n",
    "def get_class_one_hot(class_str):\n",
    "    \"\"\"Encode and one-hot classes for training.\n",
    "    Given a class as a string, return its number in the classes list. \"\"\"\n",
    "    # Encode\n",
    "    label_encoded = classes.index(class_str)\n",
    "\n",
    "    # One-hot\n",
    "    label_hot = to_categorical(label_encoded, len(classes))\n",
    "\n",
    "    assert len(label_hot) == len(classes)\n",
    "\n",
    "    return label_hot\n",
    "\n",
    "def get_all_sequences_in_memory(train_test):\n",
    "    \"\"\"\n",
    "    Load everything into memory\n",
    "    \"\"\"\n",
    "    # Get the right dataset.\n",
    "    train, test = split_train_test()\n",
    "    data = train if train_test == 'train' else test\n",
    "    \n",
    "    print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in data:\n",
    "        sequence = get_extracted_sequence(row)\n",
    "        # modify for single sequence\n",
    "        sequence = np.expand_dims(sequence, axis=0)\n",
    "\n",
    "        if sequence is None:\n",
    "            print(\"Can't find sequence?\")\n",
    "            raise\n",
    "\n",
    "        X.append(sequence)\n",
    "        y.append(get_class_one_hot(row[1]))\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def split_train_test():\n",
    "    \"\"\"Split the data into train and test sets.\"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    for item in data:\n",
    "        if item[0] == 'train':\n",
    "            train.append(item)\n",
    "        else:\n",
    "            test.append(item)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers\n",
    "from keras.models import Model\n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "senet, preprocess_input = Classifiers.get('seresnext101')\n",
    "\n",
    "f3_base = senet(input_shape=(501,501,3), weights='imagenet', include_top=False)\n",
    "f3_x = GlobalAveragePooling2D()(f3_base.output)\n",
    "\n",
    "# # # #Regularization with noise\n",
    "# f2_x = GaussianNoise(0.1)(f2_x)\n",
    "\n",
    "# f2_x = Dense(2048, activation='relu')(f2_x)\n",
    "# f2_x = Dense(5, activation='softmax')(f2_x)\n",
    "model_3 = Model(inputs=[f3_base.input],outputs=[f3_x])\n",
    "\n",
    "print(model_3.summary())\n",
    "# # print(f2_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as imgload\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "class Extractor_SeNet():\n",
    "    def __init__(self, weights=None):\n",
    "\n",
    "        # assign model_1 (Xception)\n",
    "        self.model = model_3\n",
    "            \n",
    "    def extract(self, image_path):\n",
    "        img = imgload.load_img(image_path, target_size=(501, 501)) #input size\n",
    "        #img = imgload.load_img(image_path, target_size=(224, 224)) #densenet, mobilenet\n",
    "        x = imgload.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = self.model.predict(x)\n",
    "\n",
    "#         if self.weights is None:\n",
    "#             # For imagenet/default network:\n",
    "#             features = features[0]\n",
    "#         else:\n",
    "#             # For loaded network:\n",
    "#             features = features[0]\n",
    "\n",
    "        return features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv sequences sequences_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# Get model\n",
    "model = Extractor_SeNet()\n",
    "\n",
    "# Multiple GPUs\n",
    "NUM_GPU = 4\n",
    "model.model = multi_gpu_model(model.model, gpus=NUM_GPU)\n",
    "\n",
    "# Load weights\n",
    "# model.model.load_weights(os.path.join('checkpoints', 'Cassava_NonGrp_S1_Xception_LRG501_Mul_Pretrained_STD.hdf5'))\n",
    "\n",
    "# Get the dataset.\n",
    "data = get_data()\n",
    "print(len(data))\n",
    "\n",
    "# Get the model.\n",
    "# model = Extractor_InceptionV3()\n",
    "\n",
    "# Loop through data.\n",
    "pbar = tqdm(total=len(data))\n",
    "for images in data:\n",
    "    feature_path = os.path.join('sequences', images[0] + '_' + images[1] + '_' + images[2])\n",
    "\n",
    "    # Skip if the file already existed.\n",
    "    if os.path.isfile(feature_path + '.npy'):\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(images[0], images[1], images[2])\n",
    "    feature = model.extract(image_path)\n",
    "\n",
    "    # Save the feature.\n",
    "    np.save(feature_path, feature)\n",
    "    \n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def get_extracted_sequences_one_model(dir1, sample):\n",
    "    \"\"\"Get the extracted features.\"\"\"\n",
    "    filename = sample[0] + '_' + sample[1] + '_' + sample[2]\n",
    "    path1 = os.path.join(dir1, filename + '.npy')\n",
    "    #print(path)\n",
    "    if os.path.isfile(path1):\n",
    "        return np.load(path1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_all_sequences_one_model_in_memory(dir1, train_test):\n",
    "    \"\"\"\n",
    "    Load everything into memory\n",
    "    \"\"\"\n",
    "    # Get the right dataset.\n",
    "    train, test = split_train_test()\n",
    "    data = train if train_test == 'train' else test\n",
    "    \n",
    "    print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for row in data:\n",
    "        sequence1 = get_extracted_sequences_one_model(dir1, row)\n",
    "        \n",
    "        # add two sequences\n",
    "#         sequence = np.concatenate(sequence1, axis=0)\n",
    "        # modify for single sequence\n",
    "        sequence = np.expand_dims(sequence1, axis=0)\n",
    "\n",
    "        if sequence is None:\n",
    "            print(\"Can't find sequence?\")\n",
    "            raise\n",
    "\n",
    "        X.append(sequence)\n",
    "        y.append(get_class_one_hot(row[1]))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, LeakyReLU\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "\n",
    "def base_line_one_model():\n",
    "    \"\"\"Build a simple model\"\"\"\n",
    "    # Model.\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(32, input_shape=(16,)))\n",
    "    model.add(Flatten(input_shape=(1,2048)))\n",
    "#     model.add(Dense(1024, activation='relu'))#inceptionv3\n",
    "#     model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senet_model = base_line_one_model()\n",
    "senet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset.\n",
    "data = get_data()\n",
    "print(len(data))\n",
    "\n",
    "# Get the classes.\n",
    "classes = get_classes()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 models\n",
    "#IcpResNet, Inception, Xception\n",
    "#501\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "import time, os\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cassava_NonGrp_S1_TL_SeNet501_Mul_Pretrained_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=False)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cassava_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cassava_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "early_stopper = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "\n",
    "\n",
    "X_train, y_train = get_all_sequences_one_model_in_memory('sequences','train')\n",
    "X_valid, y_valid = get_all_sequences_one_model_in_memory('sequences','valid')\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 60\n",
    "nb_epoch = 500\n",
    "\n",
    "lr = 1e-5\n",
    "decay = lr/nb_epoch\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    mul_model = multi_gpu_model(senet_model, gpus=NUM_GPU)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    mul_model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = mul_model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, csv_logger, checkpointer, early_stopper],\n",
    "            epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 40\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_2, gpus=NUM_GPU)\n",
    "\n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'bi-lstm'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_SEResNext101_LRG299_Mul_STD_tmp.pkl')\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.99, verbose=1)\n",
    "savecheckpoint = SaveCheckPoint(model_2, savedfilename)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "# number of steps each epoch\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, savecheckpoint],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
