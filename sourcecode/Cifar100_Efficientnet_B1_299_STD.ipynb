{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IBQ_eVTu8OnB",
    "outputId": "a0117324-8e60-4944-c431-14ed244b4f6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12713827169673366264\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13529270776642588732\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6914438814966743998\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10927236711\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 13453003620000530270\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10927236711\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 8596515843794656017\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10927236711\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 15203893527107740815\n",
      "physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10925244416\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 7885860961837948020\n",
      "physical_device_desc: \"device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LP5lidXD8ViI",
    "outputId": "2ff8199e-96f9-40cd-dd5b-e85cb49178c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rYOoAdFk8ma3",
    "outputId": "4e860915-8468-45db-fbcf-be0d20e5c2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datastorage/Phong/cifar100_png\n"
     ]
    }
   ],
   "source": [
    "cd /media/datastorage/Phong/cifar100_png/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mDdxdcwj8ozr",
    "outputId": "68605cb6-d5ad-42dd-ce42-3e58e2b7b5db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "313ttIKg8riI",
    "outputId": "32ea2f07-35d7-4504-ce4c-2d7aa40c84bb"
   },
   "outputs": [],
   "source": [
    "#Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get image parts\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "np.random.seed(42)\n",
    "rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "for i, rand_img in enumerate(rand_imgs):\n",
    "    train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "    j = i // 5\n",
    "    k = i % 5\n",
    "    axarr[j][k].imshow(imread(rand_img))\n",
    "    axarr[j][k].title.set_text(classname)\n",
    "    axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "UOyt3E-j8tJo",
    "outputId": "969c4599-bc6b-46f0-f648-d2cfca0450b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_gpu_model(model, gpus):\n",
    "    if isinstance(gpus, (list, tuple)):\n",
    "        num_gpus = len(gpus)\n",
    "        target_gpu_ids = gpus\n",
    "    else:\n",
    "        num_gpus = gpus\n",
    "        target_gpu_ids = range(num_gpus)\n",
    "\n",
    "    def get_slice(data, i, parts):\n",
    "        shape = tf.shape(data)\n",
    "        batch_size = shape[:1]\n",
    "        input_shape = shape[1:]\n",
    "        step = batch_size // parts\n",
    "        if i == num_gpus - 1:\n",
    "            size = batch_size - step * i\n",
    "        else:\n",
    "            size = step\n",
    "        size = tf.concat([size, input_shape], axis=0)\n",
    "        stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "        start = stride * i\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    all_outputs = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        all_outputs.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU,\n",
    "    # each getting a slice of the inputs.\n",
    "    for i, gpu_id in enumerate(target_gpu_ids):\n",
    "        with tf.device('/gpu:%d' % gpu_id):\n",
    "            with tf.name_scope('replica_%d' % gpu_id):\n",
    "                inputs = []\n",
    "                # Retrieve a slice of the input.\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_i = Lambda(get_slice,\n",
    "                                   output_shape=input_shape,\n",
    "                                   arguments={'i': i,\n",
    "                                              'parts': num_gpus})(x)\n",
    "                    inputs.append(slice_i)\n",
    "\n",
    "                # Apply model on slice\n",
    "                # (creating a model replica on the target device).\n",
    "                outputs = model(inputs)\n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "\n",
    "                # Save the outputs for merging back together later.\n",
    "                for o in range(len(outputs)):\n",
    "                    all_outputs[o].append(outputs[o])\n",
    "\n",
    "    # Merge outputs on CPU.\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for name, outputs in zip(model.output_names, all_outputs):\n",
    "            merged.append(concatenate(outputs,\n",
    "                                    axis=0, name=name))\n",
    "        return Model(model.inputs, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function.py:987: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 150, 150, 16) 144         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 150, 150, 16) 64          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 150, 150, 16) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 16)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 16)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 4)      68          block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 16)     80          block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 150, 150, 16) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 150, 150, 16) 256         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 150, 150, 16) 64          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 150, 150, 16) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 150, 150, 16) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 96) 1536        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 96)   864         block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 75, 75, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 75, 75, 144)  576         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 75, 75, 144)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 75, 75, 144)  576         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 75, 75, 144)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 144)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 75, 75, 144)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 75, 75, 24)   3456        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 75, 75, 24)   96          block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 75, 75, 24)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 75, 75, 24)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 144)  3456        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 144)  3600        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 38, 38, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 38, 38, 240)  960         block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 38, 38, 240)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 38, 38, 240)  6000        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 38, 38, 240)  960         block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 38, 38, 240)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 240)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 38, 38, 240)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 38, 38, 40)   9600        block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 38, 38, 40)   160         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 38, 38, 40)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 38, 38, 40)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 240)  9600        block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 240)  2160        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 19, 19, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 19, 19, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 19, 19, 480)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 19, 19, 480)  4320        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 19, 19, 480)  1920        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 19, 19, 480)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 480)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 19, 19, 480)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 19, 19, 80)   38400       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 19, 19, 80)   320         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 19, 19, 80)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 19, 19, 80)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 480)  38400       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 19, 19, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 19, 19, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 19, 19, 672)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 19, 19, 672)  16800       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 19, 19, 672)  2688        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 19, 19, 672)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 672)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 19, 19, 672)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 19, 19, 112)  75264       block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 19, 19, 112)  448         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 19, 19, 112)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 19, 19, 112)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 672)  75264       block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 672)  16800       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 672)  2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 672)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 672)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 192)  129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 192)  768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1152) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1152) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 192)  768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 10, 10, 192)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 192)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1152) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1152) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 192)  768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 10, 10, 192)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 192)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1152) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1152) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 192)  768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 10, 10, 192)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 192)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 10, 10, 1152) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 28800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 10, 10, 1152) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1152)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 10, 10, 1152) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 10, 10, 192)  221184      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 10, 10, 192)  768         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 10, 10, 192)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 10, 10, 192)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1152) 221184      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1152) 4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1152) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1152) 10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1152) 4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1152) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1152) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 320)  368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 320)  1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 10, 10, 1920) 614400      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 10, 10, 1920) 7680        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 10, 10, 1920) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 10, 10, 1920) 17280       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 10, 10, 1920) 7680        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 10, 10, 1920) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 1920)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 1920)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 80)     153680      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 1920)   155520      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 10, 10, 1920) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 10, 10, 320)  614400      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 10, 10, 320)  1280        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 10, 10, 320)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 10, 10, 320)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 1280) 409600      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 1280) 5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 1280) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1311744     gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          102500      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,989,476\n",
      "Trainable params: 7,927,428\n",
      "Non-trainable params: 62,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Flatten, GRU, Reshape\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "import efficientnet.keras as efn\n",
    "f1_base = efn.EfficientNetB1(include_top=False, weights='imagenet', \n",
    "                input_shape=(299, 299, 3), \n",
    "                pooling='avg')\n",
    "\n",
    "# f1_base = Xception(weights='imagenet', include_top=False, input_shape=(450,450,3))\n",
    "# f1_base = EfficientNetB4((224,224,3), classes=1000, include_top=False, weights='imagenet')\n",
    "f1_x = f1_base.output\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1792])(f1_x)  \n",
    "# f1_x = GRU(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1792])(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "f1_x = Dense(100, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1E7n8ds9Mmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FXZBAIXAElcd",
    "outputId": "0d8aaee3-0db2-4b08-c426-d26e581d2c10"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "19V0B0rIEgso",
    "outputId": "78573b3b-934c-45ae-9c10-ccb28e635e0e"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1JMB1lsREbAE",
    "outputId": "1cad26f1-9c6f-4801-bb78-84f43a11e0c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2suPqhuJDOLn",
    "outputId": "d0b80840-ba14-4470-cb33-c850af69491d"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6SqCtLbgSoQ-",
    "outputId": "2a7c1ac8-a9b2-44c2-c368-91125b14a983"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUUPvXA2S7ev"
   },
   "outputs": [],
   "source": [
    "%cp gdrive/My\\ Drive/cifar_train.zip cifar_train.zip \n",
    "%cp gdrive/My\\ Drive/cifar_test.zip cifar_test.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UsII2atxTYdG",
    "outputId": "a1c0b166-9ed8-4005-faa8-d2932fa8de5a"
   },
   "outputs": [],
   "source": [
    "!unzip cifar_train.zip\n",
    "!unzip cifar_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BL0e6CLIFwxN",
    "outputId": "960af38c-994c-41b2-9f00-a95d1d56ce6c"
   },
   "outputs": [],
   "source": [
    "# #Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib.image import imread\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # get image parts\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "# sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "# np.random.seed(42)\n",
    "# rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "# fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "# for i, rand_img in enumerate(rand_imgs):\n",
    "#     train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "#     j = i // 5\n",
    "#     k = i % 5\n",
    "#     axarr[j][k].imshow(imread(rand_img))\n",
    "#     axarr[j][k].title.set_text(classname)\n",
    "#     axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1wZ0ODjKlX"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7tCxvDxjNU9"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy\n",
    "\n",
    "# def img_square(im_pth='', desired_size=224):\n",
    "#     im = Image.open(im_pth)\n",
    "#     old_size = im.size  # (width, height) format\n",
    "\n",
    "#     ratio = float(desired_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "#     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "#     return new_im\n",
    "    \n",
    "# path = 'train/0/twinjet_s_001442.png'\n",
    "\n",
    "# orig_arr = img_square(path, 399)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# orig_arr = orig_arr.convert('RGB')\n",
    "# orig_arr.save('test.jpg')\n",
    "\n",
    "# from IPython.display import Image \n",
    "# Image(filename='test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgOQh92Ar10r"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "def convert_img_square(im_pth='', dest_path='', desired_size=224):\n",
    "#     print(im_pth)\n",
    "    \n",
    "    im = Image.open(im_pth)\n",
    "    old_size = im.size  # (width, height) format\n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "#     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "    new_im = im.resize(new_size)\n",
    "    \n",
    "    new_im = new_im.convert('RGB')\n",
    "    \n",
    "    new_im.save(dest_path)\n",
    "\n",
    "    return True\n",
    "    \n",
    "# path = 'train/0/twinjet_s_001442.png'\n",
    "# dest_path = 't1/test4.jpg'\n",
    "\n",
    "# orig_arr = convert_img_square(path, dest_path, 499)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# # orig_arr = orig_arr.convert('RGB')\n",
    "# # orig_arr.save('t1/test2.jpg')\n",
    "\n",
    "# from IPython.display import Image \n",
    "# Image(filename='t1/test4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dj-itflssqh"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwbSVOPnorCq"
   },
   "outputs": [],
   "source": [
    "%rm -r train_resized\n",
    "%mkdir train_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "cyl_Xjunolpe",
    "outputId": "0ca332e8-f4f4-4903-c7f3-68c5e41ff860"
   },
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['train']\n",
    "# dest_folder = 'train_resized_345'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 345)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "zPyjRcTfytFG",
    "outputId": "2de3a5b1-a9f6-4103-fb2b-631c9e505281"
   },
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['test']\n",
    "# dest_folder = 'test_resized_345'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 345)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emlc7dUpq9C1"
   },
   "outputs": [],
   "source": [
    "path = 'train_resized/0/twinjet_s_001442.png'\n",
    "# dest_path = 't1/test4.jpg'\n",
    "\n",
    "# orig_arr = convert_img_square(path, dest_path, 499)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# # orig_arr = orig_arr.convert('RGB')\n",
    "# # orig_arr.save('t1/test2.jpg')\n",
    "\n",
    "from IPython.display import Image \n",
    "Image(filename=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_sKj8LQqr-g"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image = mpimg.imread(path)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgL7cGRAqy7p"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtFSHddZq16W"
   },
   "outputs": [],
   "source": [
    "!zip -r train_resized_299.zip train_resized\n",
    "!zip -r test_resized_299.zip test_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGOfqcePBqpH"
   },
   "outputs": [],
   "source": [
    "%cp train_resized_299.zip gdrive/My\\ Drive/cifar_train_resized_299.zip\n",
    "%cp test_resized_299.zip gdrive/My\\ Drive/cifar_test_resized_299.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SjTDA8VC5Ah"
   },
   "outputs": [],
   "source": [
    "cd gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILRxLOABDF7u"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "8pDocSJKCtV7",
    "outputId": "a56f8b2d-8684-4f05-e17f-16a84fdd6b3b"
   },
   "outputs": [],
   "source": [
    "# !pip install keras_efficientnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WJiLtHmPZ2Ts",
    "outputId": "2e15b430-2dfa-42b8-bc91-6418e714bf62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cdFkG0pEacF1",
    "outputId": "6682d252-6c53-4324-a2bf-83d285c6ff27"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41MCKnMGanT1"
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVSEeQWrbWvn"
   },
   "outputs": [],
   "source": [
    "mkdir cifar100_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RM7cE3Skbpw9"
   },
   "outputs": [],
   "source": [
    "mkdir cifar100_output/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "P1hxliT6aR_a",
    "outputId": "a359bc33-6afa-4da1-a5fe-13aab3996ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 100 classes.\n",
      "Found 10000 images belonging to 100 classes.\n",
      "Epoch 1/40\n",
      "391/391 [==============================] - 938s 2s/step - loss: 2.8001 - acc: 0.3325 - val_loss: 1.1850 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66310, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 2/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 1.4736 - acc: 0.5836 - val_loss: 0.8256 - val_acc: 0.7499\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66310 to 0.74990, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 3/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 1.2078 - acc: 0.6508 - val_loss: 0.7138 - val_acc: 0.7817\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.74990 to 0.78170, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 4/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 1.0657 - acc: 0.6876 - val_loss: 0.6528 - val_acc: 0.7992\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78170 to 0.79920, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 5/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.9679 - acc: 0.7123 - val_loss: 0.6112 - val_acc: 0.8142\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.79920 to 0.81420, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 6/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.8797 - acc: 0.7355 - val_loss: 0.5697 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.81420 to 0.82570, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 7/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.8216 - acc: 0.7538 - val_loss: 0.5603 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.82570 to 0.82790, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 8/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.7799 - acc: 0.7652 - val_loss: 0.5443 - val_acc: 0.8362\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.82790 to 0.83620, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 9/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.7348 - acc: 0.7774 - val_loss: 0.5398 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.83620\n",
      "Epoch 10/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.6859 - acc: 0.7913 - val_loss: 0.5221 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.83620 to 0.84030, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 11/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.6450 - acc: 0.8036 - val_loss: 0.5240 - val_acc: 0.8433\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.84030 to 0.84330, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 12/40\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.6120 - acc: 0.8116 - val_loss: 0.5128 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.84330 to 0.84490, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 13/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.5885 - acc: 0.8172 - val_loss: 0.5143 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.84490\n",
      "Epoch 14/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.5623 - acc: 0.8267 - val_loss: 0.5186 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.84490\n",
      "Epoch 15/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.5323 - acc: 0.8361 - val_loss: 0.5105 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.84490 to 0.84830, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 16/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.4994 - acc: 0.8453 - val_loss: 0.5158 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.84830\n",
      "Epoch 17/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.4764 - acc: 0.8506 - val_loss: 0.5160 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84830\n",
      "Epoch 18/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.4642 - acc: 0.8551 - val_loss: 0.5184 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84830\n",
      "Epoch 19/40\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.4458 - acc: 0.8605 - val_loss: 0.5208 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.84830 to 0.85020, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 20/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.4260 - acc: 0.8655 - val_loss: 0.5213 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.85020\n",
      "Epoch 21/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.4042 - acc: 0.8714 - val_loss: 0.5242 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.85020\n",
      "Epoch 22/40\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.3869 - acc: 0.8788 - val_loss: 0.5379 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.85020\n",
      "Epoch 23/40\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.3704 - acc: 0.8840 - val_loss: 0.5262 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.85020 to 0.85280, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 24/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.3608 - acc: 0.8861 - val_loss: 0.5257 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.85280 to 0.85480, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 25/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.3516 - acc: 0.8889 - val_loss: 0.5510 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.85480\n",
      "Epoch 26/40\n",
      "391/391 [==============================] - 875s 2s/step - loss: 0.3329 - acc: 0.8947 - val_loss: 0.5397 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85480\n",
      "Epoch 27/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.3211 - acc: 0.8959 - val_loss: 0.5507 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85480\n",
      "Epoch 28/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.3127 - acc: 0.9009 - val_loss: 0.5633 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.85480\n",
      "Epoch 29/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.2989 - acc: 0.9063 - val_loss: 0.5698 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.85480\n",
      "Epoch 30/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2923 - acc: 0.9072 - val_loss: 0.5846 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.85480\n",
      "Epoch 31/40\n",
      "391/391 [==============================] - 875s 2s/step - loss: 0.2852 - acc: 0.9090 - val_loss: 0.5829 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.85480\n",
      "Epoch 32/40\n",
      "391/391 [==============================] - 875s 2s/step - loss: 0.2704 - acc: 0.9148 - val_loss: 0.5776 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.85480\n",
      "Epoch 33/40\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.2556 - acc: 0.9191 - val_loss: 0.5737 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.85480 to 0.85650, saving model to checkpoints/Cifar100_Eff_B1_299_STD.hdf5\n",
      "Epoch 34/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2525 - acc: 0.9187 - val_loss: 0.5928 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.85650\n",
      "Epoch 35/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2529 - acc: 0.9198 - val_loss: 0.5990 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85650\n",
      "Epoch 36/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2392 - acc: 0.9237 - val_loss: 0.6057 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85650\n",
      "Epoch 37/40\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2382 - acc: 0.9238 - val_loss: 0.5936 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.85650\n",
      "Epoch 38/40\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.2290 - acc: 0.9279 - val_loss: 0.6333 - val_acc: 0.8495\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.85650\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 880s 2s/step - loss: 0.2209 - acc: 0.9286 - val_loss: 0.6060 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.85650\n",
      "Epoch 40/40\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.2203 - acc: 0.9291 - val_loss: 0.6274 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85650\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 128\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints','Cifar100_Eff_B1_299_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "else:\n",
    "    model_mul = model_1\n",
    "    \n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer, csv_logger],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B1_299_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 96\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints','tmp_Cifar100_Eff_B3_299_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar100_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar100_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "else:\n",
    "    model_mul = model_1\n",
    "    \n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set.n/train_set.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer, csv_logger],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "9it_mwRMLe-e",
    "outputId": "793a2e4b-544c-485f-b030-a2460c523a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 [==============================] - 942s 2s/step - loss: 0.2248 - acc: 0.9294 - val_loss: 0.5492 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86320, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L2.hdf5\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.2181 - acc: 0.9313 - val_loss: 0.5486 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.86320\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.2104 - acc: 0.9349 - val_loss: 0.5516 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.86320\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.2091 - acc: 0.9333 - val_loss: 0.5548 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86320\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.2018 - acc: 0.9373 - val_loss: 0.5501 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86320 to 0.86330, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L2.hdf5\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - 876s 2s/step - loss: 0.1959 - acc: 0.9389 - val_loss: 0.5517 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.86330\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1995 - acc: 0.9354 - val_loss: 0.5516 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86330\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.1960 - acc: 0.9389 - val_loss: 0.5519 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86330\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1847 - acc: 0.9413 - val_loss: 0.5529 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.86330 to 0.86360, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L2.hdf5\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.1858 - acc: 0.9423 - val_loss: 0.5526 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.86360\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1851 - acc: 0.9412 - val_loss: 0.5527 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.86360\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1829 - acc: 0.9425 - val_loss: 0.5511 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.86360 to 0.86390, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L2.hdf5\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.1812 - acc: 0.9427 - val_loss: 0.5525 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.86390 to 0.86490, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L2.hdf5\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.1836 - acc: 0.9422 - val_loss: 0.5557 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.86490\n",
      "Epoch 15/15\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.1788 - acc: 0.9447 - val_loss: 0.5536 - val_acc: 0.8628\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86490\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B1_299_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZBm5kY_TxMv"
   },
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B1_299_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 [==============================] - 945s 2s/step - loss: 0.1850 - acc: 0.9424 - val_loss: 0.5527 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86470, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L3.hdf5\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.1781 - acc: 0.9437 - val_loss: 0.5519 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86470 to 0.86490, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L3.hdf5\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.1783 - acc: 0.9435 - val_loss: 0.5507 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.86490\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1764 - acc: 0.9442 - val_loss: 0.5510 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86490\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1753 - acc: 0.9453 - val_loss: 0.5512 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.86490\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1766 - acc: 0.9444 - val_loss: 0.5530 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86490 to 0.86570, saving model to checkpoints/Cifar100_Eff_B1_299_STD_L3.hdf5\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1765 - acc: 0.9445 - val_loss: 0.5527 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86570\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1753 - acc: 0.9455 - val_loss: 0.5527 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86570\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1769 - acc: 0.9445 - val_loss: 0.5517 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.86570\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - 877s 2s/step - loss: 0.1741 - acc: 0.9460 - val_loss: 0.5521 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.86570\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - 879s 2s/step - loss: 0.1749 - acc: 0.9459 - val_loss: 0.5519 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.86570\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1794 - acc: 0.9431 - val_loss: 0.5509 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.86570\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1790 - acc: 0.9448 - val_loss: 0.5530 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.86570\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1797 - acc: 0.9442 - val_loss: 0.5513 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.86570\n",
      "Epoch 15/15\n",
      "391/391 [==============================] - 878s 2s/step - loss: 0.1763 - acc: 0.9450 - val_loss: 0.5530 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86570\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B1_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B1_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 100 classes.\n",
      "Found 10000 images belonging to 100 classes.\n",
      "278/278 [==============================] - 62s 225ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple/0001.png</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple/0002.png</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple/0003.png</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple/0004.png</td>\n",
       "      <td>pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple/0005.png</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name predicted1\n",
       "0  apple/0001.png      apple\n",
       "1  apple/0002.png      apple\n",
       "2  apple/0003.png      apple\n",
       "3  apple/0004.png       pear\n",
       "4  apple/0005.png      apple"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Eff_B1_299_0309_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_1511_v1.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_1511_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Eff_B1_299_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 72\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_345',\n",
    "                                                 target_size = (370, 370),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 345)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 4\n",
    "# predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_Eff_B5_345_STD_tta_7.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_STD_tta_7.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_STD_tta_7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_Eff_B5_345_L2_TTA3.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Eff_B7_299_2208_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3_v2.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_efficientnet_B5_345_T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
