{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IBQ_eVTu8OnB",
    "outputId": "a0117324-8e60-4944-c431-14ed244b4f6e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LP5lidXD8ViI",
    "outputId": "2ff8199e-96f9-40cd-dd5b-e85cb49178c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rYOoAdFk8ma3",
    "outputId": "4e860915-8468-45db-fbcf-be0d20e5c2df"
   },
   "outputs": [],
   "source": [
    "cd /media/datastorage/Phong/cifar10/cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mDdxdcwj8ozr",
    "outputId": "68605cb6-d5ad-42dd-ce42-3e58e2b7b5db"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "313ttIKg8riI",
    "outputId": "32ea2f07-35d7-4504-ce4c-2d7aa40c84bb"
   },
   "outputs": [],
   "source": [
    "#Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get image parts\n",
    "def get_image_parts(image_path):\n",
    "    \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "    parts = image_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "    \n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "np.random.seed(42)\n",
    "rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "for i, rand_img in enumerate(rand_imgs):\n",
    "    train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "    j = i // 5\n",
    "    k = i % 5\n",
    "    axarr[j][k].imshow(imread(rand_img))\n",
    "    axarr[j][k].title.set_text(classname)\n",
    "    axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "UOyt3E-j8tJo",
    "outputId": "969c4599-bc6b-46f0-f648-d2cfca0450b0"
   },
   "outputs": [],
   "source": [
    "## fix for multi_gpu_model prediction time longer\n",
    "from keras.layers import Lambda, concatenate\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_gpu_model(model, gpus):\n",
    "    if isinstance(gpus, (list, tuple)):\n",
    "        num_gpus = len(gpus)\n",
    "        target_gpu_ids = gpus\n",
    "    else:\n",
    "        num_gpus = gpus\n",
    "        target_gpu_ids = range(num_gpus)\n",
    "\n",
    "    def get_slice(data, i, parts):\n",
    "        shape = tf.shape(data)\n",
    "        batch_size = shape[:1]\n",
    "        input_shape = shape[1:]\n",
    "        step = batch_size // parts\n",
    "        if i == num_gpus - 1:\n",
    "            size = batch_size - step * i\n",
    "        else:\n",
    "            size = step\n",
    "        size = tf.concat([size, input_shape], axis=0)\n",
    "        stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "        start = stride * i\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    all_outputs = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        all_outputs.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU,\n",
    "    # each getting a slice of the inputs.\n",
    "    for i, gpu_id in enumerate(target_gpu_ids):\n",
    "        with tf.device('/gpu:%d' % gpu_id):\n",
    "            with tf.name_scope('replica_%d' % gpu_id):\n",
    "                inputs = []\n",
    "                # Retrieve a slice of the input.\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_i = Lambda(get_slice,\n",
    "                                   output_shape=input_shape,\n",
    "                                   arguments={'i': i,\n",
    "                                              'parts': num_gpus})(x)\n",
    "                    inputs.append(slice_i)\n",
    "\n",
    "                # Apply model on slice\n",
    "                # (creating a model replica on the target device).\n",
    "                outputs = model(inputs)\n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "\n",
    "                # Save the outputs for merging back together later.\n",
    "                for o in range(len(outputs)):\n",
    "                    all_outputs[o].append(outputs[o])\n",
    "\n",
    "    # Merge outputs on CPU.\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for name, outputs in zip(model.output_names, all_outputs):\n",
    "            merged.append(concatenate(outputs,\n",
    "                                    axis=0, name=name))\n",
    "        return Model(model.inputs, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#Stop training on val_acc\n",
    "class EarlyStoppingByAccVal(Callback):\n",
    "    def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Save large model using pickle formate instead of h5            \n",
    "class SaveCheckPoint(Callback):\n",
    "    def __init__(self, model, dest_folder):\n",
    "        super(Callback, self).__init__()\n",
    "        self.model = model\n",
    "        self.dest_folder = dest_folder\n",
    "        \n",
    "        #initiate\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs['val_acc']\n",
    "        val_loss = logs['val_loss']\n",
    "\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            \n",
    "            # Save weights in pickle format instead of h5\n",
    "            print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "            weigh= self.model.get_weights()\n",
    "\n",
    "            #now, use pickle to save your model weights, instead of .h5\n",
    "            #for heavy model architectures, .h5 file is unsupported.\n",
    "            fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "            pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "            fpkl.close()\n",
    "            \n",
    "#             model.save('tmp.h5')\n",
    "        elif val_acc == self.best_val_acc:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss=val_loss\n",
    "                \n",
    "                # Save weights in pickle format instead of h5\n",
    "                print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "                weigh= self.model.get_weights()\n",
    "\n",
    "                #now, use pickle to save your model weights, instead of .h5\n",
    "                #for heavy model architectures, .h5 file is unsupported.\n",
    "                fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "                pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "                fpkl.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUL 1 - Inception - ST\n",
    "\n",
    "# from keras.applications import InceptionV3\n",
    "# from keras.applications import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Embedding, LSTM, Flatten, GRU, Reshape\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "import efficientnet.keras as efn\n",
    "f1_base = efn.EfficientNetB4(include_top=False, weights='imagenet', \n",
    "                input_shape=(299, 299, 3), \n",
    "                pooling='avg')\n",
    "\n",
    "# f1_base = Xception(weights='imagenet', include_top=False, input_shape=(450,450,3))\n",
    "# f1_base = EfficientNetB4((224,224,3), classes=1000, include_top=False, weights='imagenet')\n",
    "f1_x = f1_base.output\n",
    "# f1_x = GlobalAveragePooling2D()(f1_x)\n",
    "# f1_x = Flatten()(f1_x)\n",
    "\n",
    "# f1_x = Reshape([1,1792])(f1_x)  \n",
    "# f1_x = GRU(2048, \n",
    "#             return_sequences=False,                       \n",
    "# #             dropout=0.8                                     \n",
    "#             input_shape=[1,1792])(f1_x)\n",
    "\n",
    "#Regularization with noise\n",
    "f1_x = GaussianNoise(0.1)(f1_x)\n",
    "\n",
    "f1_x = Dense(1024, activation='relu')(f1_x)\n",
    "f1_x = Dense(10, activation='softmax')(f1_x)\n",
    "model_1 = Model(inputs=[f1_base.input],outputs=[f1_x])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1E7n8ds9Mmh"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# make_cifar10.py: Create training data from raw CIFAR-10 batches.\n",
    "# \"\"\"\n",
    "\n",
    "# # import cPickle as pkl\n",
    "# import pickle as pkl\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from skimage.io import imsave\n",
    "\n",
    "\n",
    "# PIXELS_DIR = \"pixel_data\"\n",
    "# LABEL_FILE = \"labels.txt\"\n",
    "\n",
    "\n",
    "# def unpack_file(fname):\n",
    "#     \"\"\"\n",
    "#         Unpacks a CIFAR-10 file.\n",
    "#     \"\"\"\n",
    "\n",
    "#     with open(fname, \"r\") as f:\n",
    "#         result = pkl.load(f)\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def save_as_image(img_flat, fname):\n",
    "#     \"\"\"\n",
    "#         Saves a data blob as an image file.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # consecutive 1024 entries store color channels of 32x32 image \n",
    "#     img_R = img_flat[0:1024].reshape((32, 32))\n",
    "#     img_G = img_flat[1024:2048].reshape((32, 32))\n",
    "#     img_B = img_flat[2048:3072].reshape((32, 32))\n",
    "#     img = np.dstack((img_R, img_G, img_B))\n",
    "\n",
    "#     imsave(os.path.join(PIXELS_DIR, fname), img)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#         Entry point.\n",
    "#     \"\"\"\n",
    "\n",
    "#     labels = {}\n",
    "\n",
    "#     # use \"data_batch_*\" for just the training set\n",
    "#     for fname in glob.glob(\"*_batch*\"):\n",
    "#         print(fname)\n",
    "#         data = unpack_file(fname)\n",
    "\n",
    "# #         for i in range(10000):\n",
    "# #             img_flat = data[\"data\"][i]\n",
    "# #             fname = data[\"filenames\"][i]\n",
    "# #             label = data[\"labels\"][i]\n",
    "\n",
    "# #             # save the image and store the label\n",
    "# #             save_as_image(img_flat, fname)\n",
    "# #             labels[fname] = label\n",
    "\n",
    "# #     # write out labels file\n",
    "# #     with open(LABEL_FILE, \"w\") as f:\n",
    "# #         for (fname, label) in labels.iteritems():\n",
    "# #             f.write(\"{0} {1}\\n\".format(fname, label))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FXZBAIXAElcd",
    "outputId": "0d8aaee3-0db2-4b08-c426-d26e581d2c10"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "19V0B0rIEgso",
    "outputId": "78573b3b-934c-45ae-9c10-ccb28e635e0e"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1JMB1lsREbAE",
    "outputId": "1cad26f1-9c6f-4801-bb78-84f43a11e0c7"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import timeit\n",
    "# import matplotlib.pyplot as plt\n",
    "# from six.moves import cPickle as pickle\n",
    "# import os\n",
    "# import platform\n",
    "# from subprocess import check_output\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# img_rows, img_cols = 32, 32\n",
    "# input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "# def load_pickle(f):\n",
    "#     version = platform.python_version_tuple()\n",
    "#     if version[0] == '2':\n",
    "#         return  pickle.load(f)\n",
    "#     elif version[0] == '3':\n",
    "#         return  pickle.load(f, encoding='latin1')\n",
    "#     raise ValueError(\"invalid python version: {}\".format(version))\n",
    "\n",
    "# def load_CIFAR_batch(filename):\n",
    "#     \"\"\" load single batch of cifar \"\"\"\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         datadict = load_pickle(f)\n",
    "#         X = datadict['data']\n",
    "#         Y = datadict['labels']\n",
    "#         X = X.reshape(10000,3072)\n",
    "#         Y = np.array(Y)\n",
    "#         return X, Y\n",
    "\n",
    "# def load_CIFAR10(ROOT):\n",
    "#     \"\"\" load all of cifar \"\"\"\n",
    "#     xs = []\n",
    "#     ys = []\n",
    "#     for b in range(1,6):\n",
    "#         f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "#         X, Y = load_CIFAR_batch(f)\n",
    "#         xs.append(X)\n",
    "#         ys.append(Y)\n",
    "#     Xtr = np.concatenate(xs)\n",
    "#     Ytr = np.concatenate(ys)\n",
    "#     del X, Y\n",
    "#     Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "#     return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "# def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "#     # Load the raw CIFAR-10 data\n",
    "#     cifar10_dir = 'cifar-10-batches-py/'\n",
    "#     X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "#     # Subsample the data\n",
    "#     mask = range(num_training, num_training + num_validation)\n",
    "#     X_val = X_train[mask]\n",
    "#     y_val = y_train[mask]\n",
    "#     mask = range(num_training)\n",
    "#     X_train = X_train[mask]\n",
    "#     y_train = y_train[mask]\n",
    "#     mask = range(num_test)\n",
    "#     X_test = X_test[mask]\n",
    "#     y_test = y_test[mask]\n",
    "\n",
    "#     x_train = X_train.astype('float32')\n",
    "#     x_test = X_test.astype('float32')\n",
    "\n",
    "#     x_train /= 255\n",
    "#     x_test /= 255\n",
    "\n",
    "#     return x_train, y_train, X_val, y_val, x_test, y_test\n",
    "\n",
    "# # Invoke the above function to get our data.\n",
    "# x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR10_data()\n",
    "\n",
    "\n",
    "# print('Train data shape: ', x_train.shape)\n",
    "# print('Train labels shape: ', y_train.shape)\n",
    "# print('Validation data shape: ', x_val.shape)\n",
    "# print('Validation labels shape: ', y_val.shape)\n",
    "# print('Test data shape: ', x_test.shape)\n",
    "# print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2suPqhuJDOLn",
    "outputId": "d0b80840-ba14-4470-cb33-c850af69491d"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6SqCtLbgSoQ-",
    "outputId": "2a7c1ac8-a9b2-44c2-c368-91125b14a983"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUUPvXA2S7ev"
   },
   "outputs": [],
   "source": [
    "%cp gdrive/My\\ Drive/cifar_train.zip cifar_train.zip \n",
    "%cp gdrive/My\\ Drive/cifar_test.zip cifar_test.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UsII2atxTYdG",
    "outputId": "a1c0b166-9ed8-4005-faa8-d2932fa8de5a"
   },
   "outputs": [],
   "source": [
    "!unzip cifar_train.zip\n",
    "!unzip cifar_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BL0e6CLIFwxN",
    "outputId": "960af38c-994c-41b2-9f00-a95d1d56ce6c"
   },
   "outputs": [],
   "source": [
    "# #Images/n02105855-Shetland_sheepdog/n02105855_9415.jpg\n",
    "\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib.image import imread\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # get image parts\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "    \n",
    "    \n",
    "# sample_images = list(glob.glob(os.path.join('train/', '*/*'), recursive=True))\n",
    "# np.random.seed(42)\n",
    "# rand_imgs = np.random.choice(sample_images, size=5*5)\n",
    "# fig, axarr = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "# for i, rand_img in enumerate(rand_imgs):\n",
    "#     train_or_test, classname, filename_no_ext, filename = get_image_parts(rand_img)\n",
    "    \n",
    "#     j = i // 5\n",
    "#     k = i % 5\n",
    "#     axarr[j][k].imshow(imread(rand_img))\n",
    "#     axarr[j][k].title.set_text(classname)\n",
    "#     axarr[j][k].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1wZ0ODjKlX"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7tCxvDxjNU9"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy\n",
    "\n",
    "# def img_square(im_pth='', desired_size=224):\n",
    "#     im = Image.open(im_pth)\n",
    "#     old_size = im.size  # (width, height) format\n",
    "\n",
    "#     ratio = float(desired_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "#     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "#     return new_im\n",
    "    \n",
    "# path = 'train/0/twinjet_s_001442.png'\n",
    "\n",
    "# orig_arr = img_square(path, 399)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# orig_arr = orig_arr.convert('RGB')\n",
    "# orig_arr.save('test.jpg')\n",
    "\n",
    "# from IPython.display import Image \n",
    "# Image(filename='test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgOQh92Ar10r"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy\n",
    "\n",
    "# def convert_img_square(im_pth='', dest_path='', desired_size=224):\n",
    "# #     print(im_pth)\n",
    "    \n",
    "#     im = Image.open(im_pth)\n",
    "#     old_size = im.size  # (width, height) format\n",
    "\n",
    "#     ratio = float(desired_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "# #     new_im = im.resize(new_size, Image.ANTIALIAS)\n",
    "#     new_im = im.resize(new_size)\n",
    "    \n",
    "#     new_im = new_im.convert('RGB')\n",
    "    \n",
    "#     new_im.save(dest_path)\n",
    "\n",
    "#     return True\n",
    "    \n",
    "# # path = 'train/0/twinjet_s_001442.png'\n",
    "# # dest_path = 't1/test4.jpg'\n",
    "\n",
    "# # orig_arr = convert_img_square(path, dest_path, 499)   \n",
    "\n",
    "# # #convert to RGB and Save\n",
    "# # # orig_arr = orig_arr.convert('RGB')\n",
    "# # # orig_arr.save('t1/test2.jpg')\n",
    "\n",
    "# # from IPython.display import Image \n",
    "# # Image(filename='t1/test4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dj-itflssqh"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwbSVOPnorCq"
   },
   "outputs": [],
   "source": [
    "%rm -r train_resized\n",
    "%mkdir train_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "cyl_Xjunolpe",
    "outputId": "0ca332e8-f4f4-4903-c7f3-68c5e41ff860"
   },
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['train']\n",
    "# dest_folder = 'train_resized_345'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 345)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "zPyjRcTfytFG",
    "outputId": "2de3a5b1-a9f6-4103-fb2b-631c9e505281"
   },
   "outputs": [],
   "source": [
    "# ####=======================\n",
    "# import glob\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# #move class folder from classname_# to classname/#\n",
    "\n",
    "# def get_image_parts(image_path):\n",
    "#     \"\"\"Given a full path to an image, return its parts.\"\"\"\n",
    "#     parts = image_path.split(os.path.sep)\n",
    "#     #print(parts)\n",
    "#     filename = parts[2]\n",
    "#     filename_no_ext = filename.split('.')[0]\n",
    "#     classname = parts[1]\n",
    "#     train_or_test = parts[0]\n",
    "    \n",
    "#     return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "# move_folders = ['test']\n",
    "# dest_folder = 'test_resized_345'\n",
    "# data_file = []\n",
    "\n",
    "# # look for all images in sub-folders\n",
    "# for folder in move_folders:\n",
    "#     class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "#     print('folder %s' %class_folders)\n",
    "    \n",
    "# #     for sub_folder in class_folders:\n",
    "# #         sub_class_folders = glob.glob(os.path.join(sub_folder, '*'))    \n",
    "# #         print('sub folder %s' %sub_class_folders)\n",
    "        \n",
    "#     for iid_class in class_folders:\n",
    "#         print(iid_class)\n",
    "        \n",
    "#         class_files = glob.glob(os.path.join(iid_class, '*.png'))\n",
    "        \n",
    "# #         #Determize Set# (No Suffle)\n",
    "#         set = len(class_files)\n",
    "#         inner = range(0*set, 1*set) #all\n",
    "\n",
    "#         print('moving %d files' %(len(inner)))\n",
    "\n",
    "# #         random_list = random.sample(range(len(class_files)), int(len(class_files)/5)) #1/5 dataset\n",
    "# #         for idx in range(len(random_list)):\n",
    "\n",
    "#         for idx in range(len(inner)):\n",
    "#             src = class_files[inner[idx]]\n",
    "\n",
    "#             train_or_test, classname, filename_no_ext, filename = get_image_parts(src)\n",
    "#             dst = os.path.join(dest_folder, classname, filename)\n",
    "\n",
    "#             # image directory\n",
    "#             img_directory = os.path.join(dest_folder, classname)\n",
    "\n",
    "#             # create folder if not existed\n",
    "#             if not os.path.exists(img_directory):\n",
    "#                 os.makedirs(img_directory)\n",
    "                \n",
    "#             # convert image\n",
    "#             convert_img_square(src, dst, 345)\n",
    "# #             #moving file\n",
    "# #             shutil.move(src, dst)\n",
    "# # #                 shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emlc7dUpq9C1"
   },
   "outputs": [],
   "source": [
    "path = 'train_resized/0/twinjet_s_001442.png'\n",
    "# dest_path = 't1/test4.jpg'\n",
    "\n",
    "# orig_arr = convert_img_square(path, dest_path, 499)   \n",
    "\n",
    "# #convert to RGB and Save\n",
    "# # orig_arr = orig_arr.convert('RGB')\n",
    "# # orig_arr.save('t1/test2.jpg')\n",
    "\n",
    "from IPython.display import Image \n",
    "Image(filename=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_sKj8LQqr-g"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image = mpimg.imread(path)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgL7cGRAqy7p"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtFSHddZq16W"
   },
   "outputs": [],
   "source": [
    "!zip -r train_resized_299.zip train_resized\n",
    "!zip -r test_resized_299.zip test_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGOfqcePBqpH"
   },
   "outputs": [],
   "source": [
    "%cp train_resized_299.zip gdrive/My\\ Drive/cifar_train_resized_299.zip\n",
    "%cp test_resized_299.zip gdrive/My\\ Drive/cifar_test_resized_299.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SjTDA8VC5Ah"
   },
   "outputs": [],
   "source": [
    "cd gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILRxLOABDF7u"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "8pDocSJKCtV7",
    "outputId": "a56f8b2d-8684-4f05-e17f-16a84fdd6b3b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WJiLtHmPZ2Ts",
    "outputId": "2e15b430-2dfa-42b8-bc91-6418e714bf62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cdFkG0pEacF1",
    "outputId": "6682d252-6c53-4324-a2bf-83d285c6ff27"
   },
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41MCKnMGanT1"
   },
   "outputs": [],
   "source": [
    "mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVSEeQWrbWvn"
   },
   "outputs": [],
   "source": [
    "# ## fix for multi_gpu_model prediction time longer\n",
    "# from keras.layers import Lambda, concatenate\n",
    "# from keras import Model\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def multi_gpu_model(model, gpus):\n",
    "#     if isinstance(gpus, (list, tuple)):\n",
    "#         num_gpus = len(gpus)\n",
    "#         target_gpu_ids = gpus\n",
    "#     else:\n",
    "#         num_gpus = gpus\n",
    "#         target_gpu_ids = range(num_gpus)\n",
    "\n",
    "#     def get_slice(data, i, parts):\n",
    "#         shape = tf.shape(data)\n",
    "#         batch_size = shape[:1]\n",
    "#         input_shape = shape[1:]\n",
    "#         step = batch_size // parts\n",
    "#         if i == num_gpus - 1:\n",
    "#             size = batch_size - step * i\n",
    "#         else:\n",
    "#             size = step\n",
    "#         size = tf.concat([size, input_shape], axis=0)\n",
    "#         stride = tf.concat([step, input_shape * 0], axis=0)\n",
    "#         start = stride * i\n",
    "#         return tf.slice(data, start, size)\n",
    "\n",
    "#     all_outputs = []\n",
    "#     for i in range(len(model.outputs)):\n",
    "#         all_outputs.append([])\n",
    "\n",
    "#     # Place a copy of the model on each GPU,\n",
    "#     # each getting a slice of the inputs.\n",
    "#     for i, gpu_id in enumerate(target_gpu_ids):\n",
    "#         with tf.device('/gpu:%d' % gpu_id):\n",
    "#             with tf.name_scope('replica_%d' % gpu_id):\n",
    "#                 inputs = []\n",
    "#                 # Retrieve a slice of the input.\n",
    "#                 for x in model.inputs:\n",
    "#                     input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "#                     slice_i = Lambda(get_slice,\n",
    "#                                    output_shape=input_shape,\n",
    "#                                    arguments={'i': i,\n",
    "#                                               'parts': num_gpus})(x)\n",
    "#                     inputs.append(slice_i)\n",
    "\n",
    "#                 # Apply model on slice\n",
    "#                 # (creating a model replica on the target device).\n",
    "#                 outputs = model(inputs)\n",
    "#                 if not isinstance(outputs, list):\n",
    "#                     outputs = [outputs]\n",
    "\n",
    "#                 # Save the outputs for merging back together later.\n",
    "#                 for o in range(len(outputs)):\n",
    "#                     all_outputs[o].append(outputs[o])\n",
    "\n",
    "#     # Merge outputs on CPU.\n",
    "#     with tf.device('/cpu:0'):\n",
    "#         merged = []\n",
    "#         for name, outputs in zip(model.output_names, all_outputs):\n",
    "#             merged.append(concatenate(outputs,\n",
    "#                                     axis=0, name=name))\n",
    "#         return Model(model.inputs, merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RM7cE3Skbpw9"
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import Callback\n",
    "# import pickle\n",
    "# import sys\n",
    "\n",
    "# #Stop training on val_acc\n",
    "# class EarlyStoppingByAccVal(Callback):\n",
    "#     def __init__(self, monitor='val_acc', value=0.00001, verbose=0):\n",
    "#         super(Callback, self).__init__()\n",
    "#         self.monitor = monitor\n",
    "#         self.value = value\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         current = logs.get(self.monitor)\n",
    "#         if current is None:\n",
    "#             warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "#         if current >= self.value:\n",
    "#             if self.verbose > 0:\n",
    "#                 print(\"Epoch %05d: early stopping\" % epoch)\n",
    "#             self.model.stop_training = True\n",
    "\n",
    "# #Save large model using pickle formate instead of h5            \n",
    "# class SaveCheckPoint(Callback):\n",
    "#     def __init__(self, model, dest_folder):\n",
    "#         super(Callback, self).__init__()\n",
    "#         self.model = model\n",
    "#         self.dest_folder = dest_folder\n",
    "        \n",
    "#         #initiate\n",
    "#         self.best_val_acc = 0\n",
    "#         self.best_val_loss = sys.maxsize #get max value\n",
    "          \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_acc = logs['val_acc']\n",
    "#         val_loss = logs['val_loss']\n",
    "\n",
    "#         if val_acc > self.best_val_acc:\n",
    "#             self.best_val_acc = val_acc\n",
    "            \n",
    "#             # Save weights in pickle format instead of h5\n",
    "#             print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "#             weigh= self.model.get_weights()\n",
    "\n",
    "#             #now, use pickle to save your model weights, instead of .h5\n",
    "#             #for heavy model architectures, .h5 file is unsupported.\n",
    "#             fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "#             pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "#             fpkl.close()\n",
    "            \n",
    "# #             model.save('tmp.h5')\n",
    "#         elif val_acc == self.best_val_acc:\n",
    "#             if val_loss < self.best_val_loss:\n",
    "#                 self.best_val_loss=val_loss\n",
    "                \n",
    "#                 # Save weights in pickle format instead of h5\n",
    "#                 print('\\nSaving val_acc %f at %s' %(self.best_val_acc, self.dest_folder))\n",
    "#                 weigh= self.model.get_weights()\n",
    "\n",
    "#                 #now, use pickle to save your model weights, instead of .h5\n",
    "#                 #for heavy model architectures, .h5 file is unsupported.\n",
    "#                 fpkl= open(self.dest_folder, 'wb') #Python 3\n",
    "#                 pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "#                 fpkl.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# class CutMixImageDataGenerator():\n",
    "#     def __init__(self, generator1, generator2, img_size, batch_size):\n",
    "#         self.batch_index = 0\n",
    "#         self.samples = generator1.samples\n",
    "#         self.class_indices = generator1.class_indices\n",
    "#         self.generator1 = generator1\n",
    "#         self.generator2 = generator2\n",
    "#         self.img_size = img_size\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def reset_index(self):  # Ordering Reset (If Shuffle is True, Shuffle Again)\n",
    "#         self.generator1._set_index_array()\n",
    "#         self.generator2._set_index_array()\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.batch_index = 0\n",
    "#         self.generator1.reset()\n",
    "#         self.generator2.reset()\n",
    "#         self.reset_index()\n",
    "\n",
    "#     def get_steps_per_epoch(self):\n",
    "#         quotient, remainder = divmod(self.samples, self.batch_size)\n",
    "#         return (quotient + 1) if remainder else quotient\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         self.get_steps_per_epoch()\n",
    "\n",
    "#     def __next__(self):\n",
    "#         if self.batch_index == 0: self.reset()\n",
    "\n",
    "#         crt_idx = self.batch_index * self.batch_size\n",
    "#         if self.samples > crt_idx + self.batch_size:\n",
    "#             self.batch_index += 1\n",
    "#         else:  # If current index over number of samples\n",
    "#             self.batch_index = 0\n",
    "\n",
    "#         reshape_size = self.batch_size\n",
    "#         last_step_start_idx = (self.get_steps_per_epoch()-1) * self.batch_size\n",
    "#         if crt_idx == last_step_start_idx:\n",
    "#             reshape_size = self.samples - last_step_start_idx\n",
    "            \n",
    "#         X_1, y_1 = self.generator1.next()\n",
    "#         X_2, y_2 = self.generator2.next()\n",
    "        \n",
    "#         cut_ratio = np.random.beta(a=1, b=1, size=reshape_size)\n",
    "#         cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n",
    "#         label_ratio = cut_ratio.reshape(reshape_size, 1)\n",
    "#         cut_img = X_2\n",
    "\n",
    "#         X = X_1\n",
    "#         for i in range(reshape_size):\n",
    "#             cut_size = int((self.img_size-1) * cut_ratio[i])\n",
    "#             y1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             x1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "#             y2 = y1 + cut_size\n",
    "#             x2 = x1 + cut_size\n",
    "#             cut_arr = cut_img[i][y1:y2, x1:x2]\n",
    "#             cutmix_img = X_1[i]\n",
    "#             cutmix_img[y1:y2, x1:x2] = cut_arr\n",
    "#             X[i] = cutmix_img\n",
    "            \n",
    "#         # X = seq.augment_images(X)  # Sequential of imgaug\n",
    "#         y = y_1 * (1 - (label_ratio ** 2)) + y_2 * (label_ratio ** 2)\n",
    "#         return X, y\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         while True:\n",
    "#             yield next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "P1hxliT6aR_a",
    "outputId": "a359bc33-6afa-4da1-a5fe-13aab3996ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Epoch 1/40\n",
      "1042/1042 [==============================] - 1008s 967ms/step - loss: 0.8769 - acc: 0.6984 - val_loss: 0.2154 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92960, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 2/40\n",
      "1042/1042 [==============================] - 927s 890ms/step - loss: 0.4915 - acc: 0.8303 - val_loss: 0.1452 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92960 to 0.95150, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 3/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.3936 - acc: 0.8653 - val_loss: 0.1333 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95150 to 0.95690, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 4/40\n",
      "1042/1042 [==============================] - 927s 890ms/step - loss: 0.3334 - acc: 0.8855 - val_loss: 0.1242 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95690 to 0.96110, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 5/40\n",
      "1042/1042 [==============================] - 930s 893ms/step - loss: 0.2921 - acc: 0.8993 - val_loss: 0.1036 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96110 to 0.96580, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 6/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.2613 - acc: 0.9090 - val_loss: 0.1108 - val_acc: 0.9642\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.96580\n",
      "Epoch 7/40\n",
      "1042/1042 [==============================] - 929s 892ms/step - loss: 0.2431 - acc: 0.9157 - val_loss: 0.0967 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.96580 to 0.96650, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 8/40\n",
      "1042/1042 [==============================] - 930s 893ms/step - loss: 0.2202 - acc: 0.9235 - val_loss: 0.0985 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96650 to 0.96800, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 9/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.2056 - acc: 0.9292 - val_loss: 0.0987 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96800 to 0.96870, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 10/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.1909 - acc: 0.9343 - val_loss: 0.0922 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96870 to 0.97140, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 11/40\n",
      "1042/1042 [==============================] - 931s 894ms/step - loss: 0.1764 - acc: 0.9386 - val_loss: 0.0994 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97140\n",
      "Epoch 12/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.1740 - acc: 0.9407 - val_loss: 0.1014 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97140\n",
      "Epoch 13/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.1606 - acc: 0.9439 - val_loss: 0.1029 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97140\n",
      "Epoch 14/40\n",
      "1042/1042 [==============================] - 927s 890ms/step - loss: 0.1489 - acc: 0.9477 - val_loss: 0.0961 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.97140 to 0.97240, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 15/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.1414 - acc: 0.9512 - val_loss: 0.0951 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97240\n",
      "Epoch 16/40\n",
      "1042/1042 [==============================] - 926s 888ms/step - loss: 0.1331 - acc: 0.9548 - val_loss: 0.0937 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.97240\n",
      "Epoch 17/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.1307 - acc: 0.9549 - val_loss: 0.0990 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97240\n",
      "Epoch 18/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.1243 - acc: 0.9574 - val_loss: 0.1123 - val_acc: 0.9666\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97240\n",
      "Epoch 19/40\n",
      "1042/1042 [==============================] - 927s 889ms/step - loss: 0.1244 - acc: 0.9572 - val_loss: 0.0947 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.97240 to 0.97350, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 20/40\n",
      "1042/1042 [==============================] - 928s 891ms/step - loss: 0.1175 - acc: 0.9585 - val_loss: 0.0972 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97350\n",
      "Epoch 21/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.1121 - acc: 0.9608 - val_loss: 0.0943 - val_acc: 0.9723\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97350\n",
      "Epoch 22/40\n",
      "1042/1042 [==============================] - 925s 888ms/step - loss: 0.1074 - acc: 0.9631 - val_loss: 0.1052 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97350\n",
      "Epoch 23/40\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.1067 - acc: 0.9632 - val_loss: 0.1035 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97350\n",
      "Epoch 24/40\n",
      "1042/1042 [==============================] - 929s 891ms/step - loss: 0.1014 - acc: 0.9646 - val_loss: 0.1019 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97350 to 0.97360, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 25/40\n",
      "1042/1042 [==============================] - 926s 888ms/step - loss: 0.1001 - acc: 0.9655 - val_loss: 0.1008 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97360 to 0.97490, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD.hdf5\n",
      "Epoch 26/40\n",
      "1042/1042 [==============================] - 930s 893ms/step - loss: 0.0973 - acc: 0.9671 - val_loss: 0.1069 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97490\n",
      "Epoch 27/40\n",
      "1042/1042 [==============================] - 929s 892ms/step - loss: 0.0944 - acc: 0.9672 - val_loss: 0.1078 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97490\n",
      "Epoch 28/40\n",
      "1042/1042 [==============================] - 927s 889ms/step - loss: 0.0884 - acc: 0.9699 - val_loss: 0.0941 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97490\n",
      "Epoch 29/40\n",
      "1042/1042 [==============================] - 927s 890ms/step - loss: 0.0888 - acc: 0.9696 - val_loss: 0.1295 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97490\n",
      "Epoch 30/40\n",
      "1042/1042 [==============================] - 926s 888ms/step - loss: 0.0879 - acc: 0.9701 - val_loss: 0.1091 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97490\n",
      "Epoch 31/40\n",
      "1042/1042 [==============================] - 930s 893ms/step - loss: 0.0812 - acc: 0.9716 - val_loss: 0.1091 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97490\n",
      "Epoch 32/40\n",
      "1042/1042 [==============================] - 930s 892ms/step - loss: 0.0828 - acc: 0.9721 - val_loss: 0.1145 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97490\n",
      "Epoch 33/40\n",
      "1042/1042 [==============================] - 927s 889ms/step - loss: 0.0795 - acc: 0.9727 - val_loss: 0.1166 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97490\n",
      "Epoch 34/40\n",
      "1042/1042 [==============================] - 927s 890ms/step - loss: 0.0782 - acc: 0.9727 - val_loss: 0.1075 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.97490\n",
      "Epoch 35/40\n",
      "1042/1042 [==============================] - 929s 891ms/step - loss: 0.0726 - acc: 0.9752 - val_loss: 0.1092 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.97500\n",
      "Epoch 37/40\n",
      " 134/1042 [==>...........................] - ETA: 12:01 - loss: 0.0749 - acc: 0.9737"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-df568beb8ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     verbose=1) \n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "train_datagen_1 = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # preprocessing_function=get_random_eraser()\n",
    "    # preprocessing_function=get_cutout_v2()\n",
    ")\n",
    "\n",
    "# train_datagen_2 = ImageDataGenerator(\n",
    "#     # rescale = 1./255,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     shear_range=0.3,\n",
    "#     zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,##\n",
    "# #     brightness_range=[0.5, 1.5],##\n",
    "#     channel_shift_range=10,##\n",
    "#     fill_mode='nearest',\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     # preprocessing_function=get_random_eraser()\n",
    "#     # preprocessing_function=get_cutout_v2()\n",
    "# )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "NUM_GPU = 4\n",
    "batch_size = 48\n",
    "\n",
    "#\n",
    "train_set_1 = train_datagen_1.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "# #\n",
    "# train_set_2 = train_datagen_2.flow_from_directory('train_resized_299',\n",
    "#                                                  target_size = (299, 299),\n",
    "#                                                  batch_size = batch_size,\n",
    "#                                                  class_mode = 'categorical',\n",
    "#                                                  shuffle=True,\n",
    "#                                                  seed=7,\n",
    "# #                                                  subset=\"training\"\n",
    "#                                               )\n",
    "\n",
    "# # Train Generator (CutMix)\n",
    "# train_set_collage = CutMixImageDataGenerator(\n",
    "#     generator1=train_set_1,\n",
    "#     generator2=train_set_2,\n",
    "#     img_size=299,\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "model_txt = 'st'\n",
    "# Helper: Save the model.\n",
    "savedfilename = os.path.join('checkpoints','Cifar10_EfficientNetB4_299_STD.hdf5')\n",
    "\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir=os.path.join('cifar10_output', 'logs', model_txt))\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('cifar10_output', 'logs', model_txt + '-' + 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "earlystopping = EarlyStoppingByAccVal(monitor='val_acc', value=0.9900, verbose=1)\n",
    "\n",
    "#Using multiple models if more than 1 GPU\n",
    "if NUM_GPU != 1:\n",
    "    model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "else:\n",
    "    model_mul = model_1\n",
    "    \n",
    "epochs = 40##!!!\n",
    "lr = 1e-4\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "step_size_train=ceil(train_set_1.n/train_set_1.batch_size)\n",
    "step_size_valid=ceil(valid_set.n/valid_set.batch_size)\n",
    "# step_size_test=ceil(testing_set.n//testing_set.batch_size)\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB4_299_STD.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "9it_mwRMLe-e",
    "outputId": "793a2e4b-544c-485f-b030-a2460c523a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042/1042 [==============================] - 1025s 983ms/step - loss: 0.0645 - acc: 0.9776 - val_loss: 0.0954 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97680, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD_L2.hdf5\n",
      "Epoch 2/15\n",
      "1042/1042 [==============================] - 926s 889ms/step - loss: 0.0575 - acc: 0.9800 - val_loss: 0.0965 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97680\n",
      "Epoch 3/15\n",
      "1042/1042 [==============================] - 927s 889ms/step - loss: 0.0526 - acc: 0.9830 - val_loss: 0.0959 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97680\n",
      "Epoch 4/15\n",
      "1042/1042 [==============================] - 925s 887ms/step - loss: 0.0476 - acc: 0.9832 - val_loss: 0.0992 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97680\n",
      "Epoch 5/15\n",
      " 770/1042 [=====================>........] - ETA: 3:47 - loss: 0.0479 - acc: 0.9836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042/1042 [==============================] - 924s 886ms/step - loss: 0.0395 - acc: 0.9860 - val_loss: 0.1004 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97850\n",
      "Epoch 13/15\n",
      "1042/1042 [==============================] - 925s 888ms/step - loss: 0.0423 - acc: 0.9853 - val_loss: 0.0989 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97850\n",
      "Epoch 14/15\n",
      "1042/1042 [==============================] - 924s 886ms/step - loss: 0.0399 - acc: 0.9867 - val_loss: 0.1007 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.97850\n",
      "Epoch 15/15\n",
      "1042/1042 [==============================] - 924s 886ms/step - loss: 0.0349 - acc: 0.9885 - val_loss: 0.0965 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97850\n"
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB4_299_STD_L2.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-5\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB4_299_STD_L2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1042/1042 [==============================] - 1027s 985ms/step - loss: 0.0392 - acc: 0.9859 - val_loss: 0.0968 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97830, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD_L3.hdf5\n",
      "Epoch 2/15\n",
      "1042/1042 [==============================] - 918s 881ms/step - loss: 0.0411 - acc: 0.9865 - val_loss: 0.0967 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.97830\n",
      "Epoch 3/15\n",
      "1042/1042 [==============================] - 920s 883ms/step - loss: 0.0415 - acc: 0.9856 - val_loss: 0.0975 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97830\n",
      "Epoch 4/15\n",
      "1042/1042 [==============================] - 922s 885ms/step - loss: 0.0414 - acc: 0.9857 - val_loss: 0.0967 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97830\n",
      "Epoch 5/15\n",
      "1042/1042 [==============================] - 921s 884ms/step - loss: 0.0421 - acc: 0.9857 - val_loss: 0.0962 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97830\n",
      "Epoch 6/15\n",
      "1042/1042 [==============================] - 922s 885ms/step - loss: 0.0407 - acc: 0.9865 - val_loss: 0.0953 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97830\n",
      "Epoch 7/15\n",
      "1042/1042 [==============================] - 920s 883ms/step - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0951 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97830\n",
      "Epoch 8/15\n",
      "1042/1042 [==============================] - 921s 884ms/step - loss: 0.0407 - acc: 0.9861 - val_loss: 0.0958 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97830 to 0.97850, saving model to checkpoints/Cifar10_EfficientNetB4_299_STD_L3.hdf5\n",
      "Epoch 9/15\n",
      "1042/1042 [==============================] - 920s 883ms/step - loss: 0.0390 - acc: 0.9864 - val_loss: 0.0973 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97850\n",
      "Epoch 10/15\n",
      "1042/1042 [==============================] - 920s 883ms/step - loss: 0.0387 - acc: 0.9874 - val_loss: 0.0953 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97850\n",
      "Epoch 11/15\n",
      "  16/1042 [..............................] - ETA: 11:23 - loss: 0.0575 - acc: 0.9779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2dc3c48119d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#     callbacks=[tb, csv_logger, checkpointer, earlystopping],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     verbose=1) \n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar10_EfficientNetB4_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set_1, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZBm5kY_TxMv"
   },
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar10_EfficientNetB4_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "250/250 [==============================] - 81s 322ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>predicted1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/aeroplane_s_000002.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/aeroplane_s_000040.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/aeroplane_s_000045.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0/aeroplane_s_000063.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0/airbus_s_000009.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name predicted1\n",
       "0  0/aeroplane_s_000002.png          0\n",
       "1  0/aeroplane_s_000040.png          0\n",
       "2  0/aeroplane_s_000045.png          0\n",
       "3  0/aeroplane_s_000063.png          0\n",
       "4     0/airbus_s_000009.png          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar10_EfficientB4_299_STD_2808.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_1511_v1.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_1511_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_EfficientB4_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 72\n",
    "\n",
    "#Crop-Official Test\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Generate random crops from the image batches\"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "test_datagen_crop = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "testing_set_crop = test_datagen_crop.flow_from_directory('test_resized_345',\n",
    "                                                 target_size = (370, 370),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "#customized generator\n",
    "test_crops = crop_generator(testing_set_crop, 345)\n",
    "\n",
    "step_size_test_crop = ceil(testing_set_crop.n/testing_set_crop.batch_size)\n",
    "\n",
    "tta_steps = 4\n",
    "# predictions = []\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    testing_set_crop.reset()\n",
    "    if NUM_GPU != 1:\n",
    "        preds=model_mul.predict_generator(test_crops, \n",
    "                                           steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "#                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "                                           verbose=1)    \n",
    "#     else:\n",
    "#         preds=model.predict_generator(test_crops, \n",
    "#                                            steps = step_size_test_crop,\n",
    "#                                            max_queue_size=16,\n",
    "# #                                                use_multiprocessing=True,\n",
    "#                                            workers=1,\n",
    "#                                            verbose=1)  \n",
    "#     preds=model_2.predict_generator(test_crops,steps = step_size_test_crop,verbose=1)  \n",
    "    predictions.append(preds)\n",
    "\n",
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "predicted_class_indices_mean=np.argmax(mean_pred,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "finalpre = [labels[k] for k in predicted_class_indices_mean]\n",
    "\n",
    "import pandas as pd\n",
    "filenames=testing_set_crop.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"predicted\":finalpre,\n",
    "                      })\n",
    "results.to_csv('Cifar10_Eff_B5_345_STD_tta_7.csv')\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp Cifar10_Eff_B5_345_STD_tta_7.csv /home/bribeiro/Phong/Nat19/Cifar10_Eff_B5_345_STD_tta_7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar10_Eff_B5_345_L2_TTA3.npy'), mean_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Groups\n",
    "#Split training and validation\n",
    "#Using Expert Data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "import time, os\n",
    "from math import ceil\n",
    "import multiprocessing\n",
    "\n",
    "savedfilename = os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5')\n",
    "checkpointer = ModelCheckpoint(savedfilename,\n",
    "                          monitor='val_acc', verbose=1, \n",
    "                          save_best_only=True, mode='max',save_weights_only=True)########\n",
    "\n",
    "epochs = 15##!!!\n",
    "lr = 1e-6\n",
    "decay = lr/epochs\n",
    "optimizer = Adam(lr=lr, decay=decay)\n",
    "\n",
    "model_mul.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "result = model_mul.fit_generator(\n",
    "    generator = train_set, \n",
    "    steps_per_epoch = step_size_train,\n",
    "    validation_data = valid_set,\n",
    "    validation_steps = step_size_valid,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystopping, checkpointer],\n",
    "#     callbacks=[tb, csv_logger, checkpointer, earlystopping],        \n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using multiple models if more than 1 GPU\n",
    "# NUM_GPU = 4\n",
    "# if NUM_GPU != 1:\n",
    "#     model_mul = multi_gpu_model(model_1, gpus=NUM_GPU)\n",
    "\n",
    "model_mul.load_weights(os.path.join('checkpoints', 'Cifar100_Eff_B7_299_STD_L3.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time, os\n",
    "from math import ceil\n",
    "\n",
    "# PREDICT ON OFFICIAL TEST\n",
    "train_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,##\n",
    "#     brightness_range=[0.5, 1.5],##\n",
    "    channel_shift_range=10,##\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(\n",
    "#     rescale = 1./255,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('train_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory('test_resized_299',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 seed=7,\n",
    "#                                                  subset=\"validation\"\n",
    "                                             )\n",
    "\n",
    "if NUM_GPU != 1:\n",
    "    predict1=model_mul.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "# else:\n",
    "#     predict1=model.predict_generator(test_set1, steps = ceil(test_set1.n/test_set1.batch_size),verbose=1)\n",
    "    \n",
    "predicted_class_indices=np.argmax(predict1,axis=1)\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions1 = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filenames=test_set1.filenames\n",
    "results=pd.DataFrame({\"file_name\":filenames,\n",
    "                      \"predicted1\":predictions1,\n",
    "                      })\n",
    "results.to_csv('Cifar100_Eff_B0_299_1108_v1.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('pred_npy','Cifar100_Eff_B7_299_STD_L3.npy'), predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10_efficientnet_B5_345_T2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
